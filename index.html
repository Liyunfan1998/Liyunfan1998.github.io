<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    

    <!--Author-->
    
        <meta name="author" content="Yunfan Li">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Hexo"/>
    

    <!--Open Graph Description-->
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="Hexo"/>

    <!--Type page-->
    
        <meta property="og:type" content="website" />
    

    <!--Page Cover-->
    

    
        <meta name="twitter:card" content="summary" />
    
    
    

    <!-- Title -->
    
    <title>Hexo</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.2/css/bootstrap.min.css" integrity="sha384-y3tfxAZXuh4HwSYylfB+J125MxIs6mR5FOHamPBG064zB+AFeWH94NdvaCBm8qnd" crossorigin="anonymous">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/style.css">


    <!-- Google Analytics -->
    


<meta name="generator" content="Hexo 4.2.0"></head>


<body>

<div class="bg-gradient"></div>
<div class="bg-pattern"></div>

<!-- Menu -->
<!--Menu Links and Overlay-->
<div class="menu-bg">
    <div class="menu-container">
        <ul>
            
            <li class="menu-item">
                <a href="/archives">
                    Home
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/archives">
                    Archives
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/about.html">
                    About
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/tags">
                    Tags
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/categories">
                    Categories
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/contact.html">
                    Contact
                </a>
            </li>
            
        </ul>
    </div>
</div>

<!--Hamburger Icon-->
<nav>
    <a href="#menu"></a>
</nav>

<div class="container">

    <!-- Main Content -->
    <div class="row">
    <div class="col-sm-12">

        <!--Title and Logo-->
        <header>
    <div class="logo">
        <a href="/"><i class="logo-icon fa fa-cube" aria-hidden="true"></i></a>
        
            <h1 id="main-title" class="title">Hexo</h1>
        
    </div>
</header>

        <section class="main">
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/08/AlexNet%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/">
                AlexNet详细解读
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="AlexNet详细解读"><a href="#AlexNet详细解读" class="headerlink" title="AlexNet详细解读"></a>AlexNet详细解读</h1><p>  之前在自学计算机视觉与深度学习方向的论文，今天给大家带来的是很经典的一篇文章 ：《ImageNet Classification with Deep Convolutional Neural Networks》。纯粹是自学之后，自己的一点知识总结，如果有什么不对的地方欢迎大家指正。AlexNet的篇文章当中，我们可以主要从五个大方面去讲：ReLU，LPN，Overlapping Pooling，总体架构，减少过度拟合。重点介绍总体结构和减少过度拟合。</p>
<h2 id="1-ReLU-Nonlinearity"><a href="#1-ReLU-Nonlinearity" class="headerlink" title="1. ReLU Nonlinearity"></a>1. ReLU Nonlinearity</h2><p>一般神经元的激活函数会选择sigmoid函数或者tanh函数，然而Alex发现在训练时间的梯度衰减方面，这些非线性饱和函数要比非线性非饱和函数慢很多。在AlexNet中用的非线性非饱和函数是f=max(0,x)，即ReLU。实验结果表明，要将深度网络训练至training error rate达到25%的话，ReLU只需5个epochs的迭代，但tanh单元需要35个epochs的迭代，用ReLU比tanh快6倍。</p>
<h2 id="2-双GPU并行运行"><a href="#2-双GPU并行运行" class="headerlink" title="2. 双GPU并行运行"></a>2. 双GPU并行运行</h2><p>为提高运行速度和提高网络运行规模，作者采用双GPU的设计模式。并且规定GPU只能在特定的层进行通信交流。其实就是每一个GPU负责一半的运算处理。作者的实验数据表示，two-GPU方案会比只用one-GPU跑半个上面大小网络的方案，在准确度上提高了1.7%的top-1和1.2%的top-5。值得注意的是，虽然one-GPU网络规模只有two-GPU的一半，但其实这两个网络其实并非等价的。</p>
<h2 id="3-LRN局部响应归一化"><a href="#3-LRN局部响应归一化" class="headerlink" title="3. LRN局部响应归一化"></a>3. LRN局部响应归一化</h2><p><img src="https://img-blog.csdn.net/20180518200153219" alt="img"></p>
<p>ReLU本来是不需要对输入进行标准化，但本文发现进行局部标准化能提高性能。</p>
<p>其中a代表在feature map中第i个卷积核(x,y)坐标经过了ReLU激活函数的输出，n表示相邻的几个卷积核。N表示这一层总的卷积核数量。k, n, α和β是hyper-parameters，他们的值是在验证集上实验得到的，其中k = 2，n = 5，α = 0.0001，β = 0.75。</p>
<p>这种归一化操作实现了某种形式的横向抑制，这也是受真实神经元的某种行为启发。</p>
<p>卷积核矩阵的排序是随机任意，并且在训练之前就已经决定好顺序。这种LPN形成了一种横向抑制机制。</p>
<h2 id="4-Overlapping-Pooling"><a href="#4-Overlapping-Pooling" class="headerlink" title="4. Overlapping Pooling"></a>4. Overlapping Pooling</h2><p>池层是相同卷积核领域周围神经元的输出。池层被认为是由空间距离s个像素的池单元网格的组成。也可以理解成以大小为步长对前面卷积层的结果进行分块，对块大小为的卷积映射结果做总结，这时有。然而，Alex说还有的情况，也就是带交叠的Pooling，顾名思义这指Pooling单元在总结提取特征的时候，其输入会受到相邻pooling单元的输入影响，也就是提取出来的结果可能是有重复的(对max pooling而言)。而且，实验表示使用 带交叠的Pooling的效果比的传统要好，在top-1和top-5上分别提高了0.4%和0.3%，在训练阶段有避免过拟合的作用。</p>
<h2 id="5-总体结构"><a href="#5-总体结构" class="headerlink" title="5. 总体结构"></a>5. 总体结构</h2><p>如果说前面的ReLU、LRN、Overlapping Pooling是铺垫的话，那么它们一定是为这部分服务的。</p>
<p>因为这才是全文的重点！！！理解这里才是把握住这篇的论文的精华！</p>
<p><img src="https://img-blog.csdn.net/20180518202244353" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/20190222100954397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h4Ym95NjE=,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/1689929-063fb60285b6ed42.png?imageMogr2/auto-orient/strip%7CimageView2/2" alt="img"></p>
<p>首先总体概述下：</p>
<p>  AlexNet为8层结构，其中前5层为卷积层，后面3层为全连接层；学习参数有6千万个，神经元有650,000个<br>  AlexNet在两个GPU上运行；<br>  AlexNet在第2,4,5层均是前一层自己GPU内连接，第3层是与前面两层全连接，全连接是2个GPU全连接；<br>  RPN层第1,2个卷积层后；<br>  Max pooling层在RPN层以及第5个卷积层后。<br>  ReLU在每个卷积层以及全连接层后。<br>  卷积核大小数量：</p>
<p>conv1:96 11<em>11</em>3(个数/长/宽/深度)</p>
<p>conv2:256 5<em>5</em>48</p>
<p>conv3:384 3<em>3</em>256</p>
<p>conv4: 384 3<em>3</em>192</p>
<p>conv5: 256 3<em>3</em>192</p>
<p>ReLU、双GPU运算：提高训练速度。（应用于所有卷积层和全连接层）</p>
<p>重叠pool池化层：提高精度，不容易产生过度拟合。（应用在第一层，第二层，第五层后面）</p>
<p>局部响应归一化层(LRN)：提高精度。（应用在第一层和第二层后面）</p>
<p>Dropout：减少过度拟合。（应用在前两个全连接层）<br>第1层分析：</p>
<p><img src="https://img-blog.csdn.net/20180518203413676" alt="img"><br>第一层输入数据为原始图像的227<em>227</em>3的图像（最开始是224<em>224</em>3，为后续处理方便必须进行调整）,这个图像被11<em>11</em>3（3代表深度，例如RGB的3通道）的卷积核进行卷积运算，卷积核对原始图像的每次卷积都会生成一个新的像素。卷积核的步长为4个像素，朝着横向和纵向这两个方向进行卷积。由此，会生成新的像素；（227-11）/4+1=55个像素(227个像素减去11，正好是54，即生成54个像素，再加上被减去的11也对应生成一个像素)，由于第一层有96个卷积核，所以就会形成55<em>55</em>96个像素层，系统是采用双GPU处理，因此分为2组数据：55<em>55</em>48的像素层数据。</p>
<p>重叠pool池化层：这些像素层还需要经过pool运算（池化运算）的处理，池化运算的尺度由预先设定为3<em>3，运算的步长为2，则池化后的图像的尺寸为：（55-3）/2+1=27。即经过池化处理过的规模为27</em>27*96.</p>
<p>局部响应归一化层(LRN)：最后经过局部响应归一化处理，归一化运算的尺度为5<em>5；第一层卷积层结束后形成的图像层的规模为27</em>27*96.分别由96个卷积核对应生成，这96层数据氛围2组，每组48个像素层，每组在独立的GPU下运算。<br>第2层分析：</p>
<p><img src="https://img-blog.csdn.net/20180518221411890" alt="img"><br>第二层输入数据为第一层输出的27<em>27</em>96的像素层（为方便后续处理，这对每幅像素层进行像素填充），分为2组像素数据，两组像素数据分别在两个不同的GPU中进行运算。每组像素数据被5<em>5</em>48的卷积核进行卷积运算，同理按照第一层的方式进行：（27-5+2<em>2）/1+1=27个像素，一共有256个卷积核，这样也就有了27</em>27*128两组像素层。</p>
<p>重叠pool池化层：同样经过池化运算，池化后的图像尺寸为（27-3）/2+1=13，即池化后像素的规模为2组13<em>13</em>128的像素层。</p>
<p>局部响应归一化层(LRN)：最后经过归一化处理，分别对应2组128个卷积核所运算形成。每组在一个GPU上进行运算。即共256个卷积核，共2个GPU进行运算。<br>第3层分析</p>
<p><img src="https://img-blog.csdn.net/20180518223031687" alt="img"><br>第三层输入数据为第二层输出的两组13<em>13</em>128的像素层（为方便后续处理，这对每幅像素层进行像素填充），分为2组像素数据，两组像素数据分别在两个不同的GPU中进行运算。每组像素数据被3<em>3</em>128的卷积核（两组，一共也就有3<em>3</em>256）进行卷积运算，同理按照第一层的方式进行：（13-3+1<em>2）/1+1=13个像素，一共有384个卷积核，这样也就有了13</em>13*192两组像素层。<br>第4层分析:</p>
<p><img src="https://img-blog.csdn.net/20180518223330629" alt="img"></p>
<p>第四层输入数据为第三层输出的两组13<em>13</em>192的像素层（为方便后续处理，这对每幅像素层进行像素填充），分为2组像素数据，两组像素数据分别在两个不同的GPU中进行运算。每组像素数据被3<em>3</em>192的卷积核进行卷积运算，同理按照第一层的方式进行：（13-3+1<em>2）/1+1=13个像素，一共有384个卷积核，这样也就有了13</em>13*192两组像素层。<br>第5层分析：</p>
<p><img src="https://img-blog.csdn.net/20180518223635261" alt="img"></p>
<p>第五层输入数据为第四层输出的两组13<em>13</em>192的像素层（为方便后续处理，这对每幅像素层进行像素填充），分为2组像素数据，两组像素数据分别在两个不同的GPU中进行运算。每组像素数据被3<em>3</em>192的卷积核进行卷积运算，同理按照第一层的方式进行：（13-3+1<em>2）/1+1=13个像素，一共有256个卷积核，这样也就有了13</em>13*128两组像素层。</p>
<p>重叠pool池化层：进过池化运算，池化后像素的尺寸为（13-3）/2+1=6，即池化后像素的规模变成了两组6<em>6</em>128的像素层，共6<em>6</em>256规模的像素层。<br>第6层分析：</p>
<p><img src="https://img-blog.csdn.net/20180518223855977" alt="img"><br>第6层输入数据的尺寸是6<em>6</em>256，采用6<em>6</em>256尺寸的滤波器对第六层的输入数据进行卷积运算；每个6<em>6</em>256尺寸的滤波器对第六层的输入数据进行卷积运算生成一个运算结果，通过一个神经元输出这个运算结果；共有4096个6<em>6</em>256尺寸的滤波器对输入数据进行卷积，通过4096个神经元的输出运算结果；然后通过ReLU激活函数以及dropout运算输出4096个本层的输出结果值。</p>
<p>很明显在第6层中，采用的滤波器的尺寸（6<em>6</em>256）和待处理的feature map的尺寸（6<em>6</em>256）相同，即滤波器中的每个系数只与feature map中的一个像素值相乘；而采用的滤波器的尺寸和待处理的feature map的尺寸不相同，每个滤波器的系数都会与多个feature map中像素相乘。因此第6层被称为全连接层。<br>第7层分析：</p>
<p><img src="https://img-blog.csdn.net/20180519092620718" alt="img"><br>第6层输出的4096个数据与第7层的4096个神经元进行全连接，然后经由ReLU和Dropout进行处理后生成4096个数据。<br>第8层分析：</p>
<p><img src="https://img-blog.csdn.net/20180519092826659" alt="img"></p>
<p>第7层输入的4096个数据与第8层的1000个神经元进行全连接，经过训练后输出被训练的数值。</p>
<h2 id="6-减少过度拟合"><a href="#6-减少过度拟合" class="headerlink" title="6. 减少过度拟合"></a>6. 减少过度拟合</h2><h3 id="6-1-数据增益"><a href="#6-1-数据增益" class="headerlink" title="6.1 数据增益"></a>6.1 数据增益</h3><p>增强图片数据集最简单和最常用的方法是在不改变图片核心元素（即不改变图片的分类）的前提下对图片进行一定的变换，比如在垂直和水平方向进行一定的唯一，翻转等。</p>
<p>AlexNet用到的第一种数据增益的方法：是原图片大小为256<em>256中随机的提取224</em>224的图片，以及他们水平方向的映像。</p>
<p>第二种数据增益的方法就是在图像中每个像素的R、G、B值上分别加上一个数，用到 方法为PCA。对于图像每个像素，增加以下量 ：</p>
<p><img src="https://img-blog.csdn.net/20180519094519363" alt="img"><br>p是主成分，lamda是特征值，alpha是N(0，0.1)高斯分布中采样得到的随机值。此方案名义上得到自然图像的重要特性，也就是说，目标是不随着光照强度和颜色而改变的。此方法降低top-1错误率1%。<br>6.2 Dropout</p>
<p>结合多个模型的预测值是减少错误的有效方法，但是对于训练时间用好几天的大型神经网络太耗费时间。Dropout是有效的模型集成学习方法，具有0.5的概率讲隐藏神经元设置输出为0。运用了这种机制的神经元不会干扰前向传递也不影响后续操作。因此当有输入的时候，神经网络采样不用的结构，但是这些结构都共享一个权重。这就减少了神经元适应的复杂性。测试时，用0.5的概率随机失活神经元。dropout减少了过拟合，也使收敛迭代次数增加一倍。</p>
<h2 id="7-学习细节"><a href="#7-学习细节" class="headerlink" title="7. 学习细节"></a>7. 学习细节</h2><p>AlexNet训练采用的是随机梯度下降 (stochastic gradient descent)，每批图像大小为128，动力为0.9，权重衰减为0.005,（Alexnet认为权重衰减非常重要，但是没有讲为什么）</p>
<p>对于权重值的更新规则如下：</p>
<p><img src="https://img-blog.csdn.net/2018051909591899" alt="img"><br>其中i是迭代指数，v是动力变量，ε是学习率，是目标关于w、对求值的导数在第i批样例上的平均值。我们用一个均值为0、标准差为0.01的高斯分布初始化了每一层的权重。我们用常数1初始化了第二、第四和第五个卷积层以及全连接隐层的神经元偏差。该初始化通过提供带正输入的ReLU来加速学习的初级阶段。我们在其余层用常数0初始化神经元偏差。<br>  对于所有层都使用了相等的学习率，这是在整个训练过程中手动调整的。我们遵循的启发式是，当验证误差率在当前学习率下不再提高时，就将学习率除以10。学习率初始化为0.01，在终止前降低三次。作者训练该网络时大致将这120万张图像的训练集循环了90次，在两个NVIDIA GTX 580 3GB GPU上花了五到六天。</p>
<h2 id="8-实验结果"><a href="#8-实验结果" class="headerlink" title="8. 实验结果"></a>8. 实验结果</h2><p>ILSVRC2010比赛冠军方法是Sparse coding,这之后(AlexNet前)报道最好方法是SIFT+FVs。CNN方法横空出世，远超传统方法。</p>
<p><img src="https://img-blog.csdn.net/20180519100236278" alt="img"></p>
<p>ILSVRC-2012，Alex参加比赛，获得冠军，远超第二名SIFT+FVs。</p>
<p><img src="https://img-blog.csdn.net/20180519100534494" alt="img"><br>定量分析：</p>
<p><img src="https://img-blog.csdn.net/20180519100835132" alt="img"><br>图3显示了卷积层学到的有频率和方向选择性的卷积核，和颜色斑点(color blob)。GPU 1 (color-agnostic)和GPU 2(color-specific)学习到的卷积核并不一样。不一样的原因是3.5中的受限连接(restricted connectivity)。</p>
<p>图4显示，即使目标偏离中心，也可以被识别出来，比如mite。top-5预测结果是reasonable的，比如leopard的预测的可能结果是其他类型的猫科动物。但是也存在对intended focus的模糊问题，就是网络不知道我们到底想识别图片中的什么物体，比如cherry,分类结果是dalmatian,网络显然关注的是dog。</p>
<p>网络最后4096-d隐藏层产生的是feature activations是另一个重要指标。如果两张图像产生欧氏距离相近的feature activation vectors,那么网络的higher levels就认为他们是相似的。使用此度量，可以实现较好的图像检索。<br>通过欧氏距离计算两个4096维度效率太低，可以使用自动编码压缩向量成二进制码。这比直接在原始像素上使用自动编码效果更好。因为在raw pixels上使用quto-encoder，没用到标签数据，只是检索有相似边缘模式(similar patterns of edges)的图像,却不管他们语义(semantically)上是否相似。</p>
<h2 id="9-探讨"><a href="#9-探讨" class="headerlink" title="9.探讨"></a>9.探讨</h2><p>深度很重要，去掉任一层，性能都会降低。</p>
<p>为了简化实验，没有使用非监督预训练。但是当有足够计算能力扩大网络结构，而没增加相应数据时，非监督预训练可能会有所帮助。</p>
<p>虽然通过增大网络结构和增加训练时长可以改善网络，但是我们与达到人类视觉系统的时空推理能力(infero-temporal pathway of the human visual system)还相距甚远。所以，最终希望能将CNN用到视频序列分析中，视频相对静态图像有很多有用的时间结构信息。</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/08/%E5%8D%B7%E7%A9%8D%E4%B8%AD%E7%9A%84stride%E5%92%8Cpadding/">
                卷積中的stride和padding
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="卷積神經網路-Convolutional-neural-network-CNN-卷積計算中的步伐-stride-和填充-padding"><a href="#卷積神經網路-Convolutional-neural-network-CNN-卷積計算中的步伐-stride-和填充-padding" class="headerlink" title="卷積神經網路(Convolutional neural network, CNN):卷積計算中的步伐(stride)和填充(padding)"></a>卷積神經網路(Convolutional neural network, CNN):卷積計算中的步伐(stride)和填充(padding)</h1><hr>
<p><strong>卷積神經網路(Convolutional neural network, CNN)其他相關連結我也一起列上來*<br>*</strong>NN-2–1 <a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-卷積運算-池化運算-856330c2b703" target="_blank" rel="noopener">卷積神經網路(Convolutional neural network, CNN) — 卷積運算、池化運算</a><br>NN-2–2<a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-cnn運算流程-ecaec240a631" target="_blank" rel="noopener"> 卷積神經網路(Convolutional neural network, CNN) — CNN運算流程</a><br>NN-2–3 <a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-卷積計算的倒傳遞推導與稀疏矩陣觀點來看卷積計算-e82ac16e510f" target="_blank" rel="noopener">卷積神經網路(Convolutional neural network, CNN):卷積計算的倒傳遞推導與稀疏矩陣觀點來看卷積計算</a><br>NN-2–4 <a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-卷積計算中的步伐-stride-和填充-padding-94449e638e82" target="_blank" rel="noopener">卷積神經網路(Convolutional neural network, CNN):卷積計算中的步伐(stride)和填充(padding)</a><br>NN-2–5 <a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-1-1卷積計算在做什麼-7d7ebfe34b8" target="_blank" rel="noopener">卷積神經網路(Convolutional neural network, CNN): 1×1卷積計算在做什麼</a></p>
<hr>
<p><img src="https://miro.medium.com/max/60/1*hjn1l4rN8jwS3vD5pTvUwQ.png?q=20" alt="img"></p>
<p><img src="https://miro.medium.com/max/1278/1*hjn1l4rN8jwS3vD5pTvUwQ.png" alt="img"></p>
<p>一般看到的卷積介紹，大概就像上圖，圖會因為你的kernel map大小做完卷積後變的更小，實際上卷積怎麼執行可以參考我之前寫的:<br><a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-卷積運算-池化運算-856330c2b703" target="_blank" rel="noopener">卷積神經網路(Convolutional neural network, CNN) — 卷積運算、池化運算</a></p>
<p>Note: <strong>(2019/01/15增加)</strong>一般卷積網路過程中，除了Input image不稱為Feature map外，中間產生的圖我們都稱之為Feature map，原因很簡單就是這些中間產生的圖都是為了「描繪出該任務所應該產生對應的特徵資料」，這也呼應Yann LeCun, Yoshua Bengio &amp; Geoffrey Hinton寫的<a href="https://www.nature.com/articles/nature14539" target="_blank" rel="noopener">Deep Learning</a>第一句話寫的「Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction」，深度學習過程就是在學資料的特性，所以中間出來的結果都是特徵資料，在影像因為是2D，所以用Feature map來稱呼。</p>
<p>所以一個卷積計算基本上有幾個部份:</p>
<p>\1. 輸入的圖: 假設大小是W × W。<br>\2. Filter (kernel map)大小是 ks × ks<br>\3. Stride: kernel map在移動時的步伐長度 S<br>\4. 輸出的圖大小為 new_height × new_width</p>
<p>上圖的例子<br>\1. 輸入的圖: W × W =10 × 10。<br>\2. Filter (kernel map): ks × ks=3 × 3<br>\3. Stride: S=1<br>\4. 輸出的圖大小為 new_height × new_width = 8 × 8</p>
<blockquote>
<p>上圖的範例產生了2個問題<br>\1. 是不是卷積計算後，卷積後的圖是不是就一定只能變小?<br>\2. 卷積計算是不是一次只能移動一格?</p>
</blockquote>
<p>所以如果你有玩過deep learning的API，卷積計算部份除了基本的input和filter (kernel map)通常還有兩個參數可以調(strides, padding)，這邊舉<a href="https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/conv2d" target="_blank" rel="noopener">tensorflow</a>的例子:<br>tf.nn.conv2d(input, filter, <strong><em>strides\</em></strong>, <strong><em>padding\</em></strong>, use_cudnn_on_gpu=None, data_format=None, name=None)</p>
<p><strong><em>strides\</em></strong>和 <strong><em>padding\</em></strong>這兩個參數就是在解決上面說的兩個問題。</p>
<hr>
<h2 id="是不是卷積計算後，卷積後的圖是不是就一定只能變小"><a href="#是不是卷積計算後，卷積後的圖是不是就一定只能變小" class="headerlink" title="是不是卷積計算後，卷積後的圖是不是就一定只能變小?"></a><strong>是不是卷積計算後，卷積後的圖是不是就一定只能變小?</strong></h2><p><strong>ANS: 用zero padding</strong></p>
<p>這個手法就是看你會消失多少的大小，在輸入的圖部份就給你加上0元素進去，這個手法稱為zero padding，實際作法如下圖。</p>
<p><img src="https://miro.medium.com/max/60/1*9kqLUr7bMEYryGNtAHyL8A.png?q=20" alt="img"></p>
<p><img src="https://miro.medium.com/max/2000/1*9kqLUr7bMEYryGNtAHyL8A.png" alt="img"></p>
<p>此刻的卷積計算如下，這樣卷積後的圖就不會變小了。</p>
<p><img src="https://miro.medium.com/max/60/1*GwxhjA7-FLIRrtl__RkRgg.png?q=20" alt="img"></p>
<p><img src="https://miro.medium.com/max/1522/1*GwxhjA7-FLIRrtl__RkRgg.png" alt="img"></p>
<p>上圖舉的例子是kernel map是3x3，假設kernel map為5x5，此刻在輸入的圖上下左右行和列都各加2行和2列的0，讓圖變成14x14，就可以了。</p>
<hr>
<h2 id="卷積計算是不是一次只能移動一格"><a href="#卷積計算是不是一次只能移動一格" class="headerlink" title="卷積計算是不是一次只能移動一格?"></a><strong>卷積計算是不是一次只能移動一格?</strong></h2><p><strong>ANS: 當然不是，也可以2格3格，但此時卷積後的圖就會變的更小。</strong></p>
<p><img src="https://miro.medium.com/max/60/1*Hy3dNn5siu4_q7jE7yO9eA.png?q=20" alt="img"></p>
<p><img src="https://miro.medium.com/max/1638/1*Hy3dNn5siu4_q7jE7yO9eA.png" alt="img"></p>
<p>在tensorflow，padding那邊給了兩個選項「padding = ‘VALID’」和「padding = ‘SAME’」</p>
<p><strong>padding = ‘VALID’ 等於最一開始敘述的卷積計算，圖根據filter大小和stride大小而變小。</strong></p>
<p>公式如下: new_height = new_width = (W — F + 1) / S （结果向上取整數，假設算出來結果是4.5，取5）</p>
<p>剛剛的例子<br>filter 3x3, stride=1, 卷積後的大小: (10–3+1)/1=8<br>filter 3x3, stride=2, 卷積後的大小: (10–3+1)/2=4</p>
<p><strong>padding = ‘SAME’，會用zero-padding的手法，讓輸入的圖不會受到kernel map的大小影響。</strong></p>
<p>new_height = new_width = W / S （结果向上取整數）</p>
<blockquote>
<p>剛剛的例子，filter 3x3, stride=2, 卷積後的大小: 10/2=5 (這邊我沒有做這張圖，可以自己想像一下，做法如下所述)<br>這邊的作法會先補zero-padding的0元素，然後在作stride=2的卷積，所以實際上是最(10+2)*(10+2)的圖做padding = ‘VALID’的事情，(12–3+1)/2=5。</p>
</blockquote>
<hr>
<h2 id="Padding補充說明-2019-01-15增加此內容"><a href="#Padding補充說明-2019-01-15增加此內容" class="headerlink" title="Padding補充說明 (2019/01/15增加此內容)"></a>Padding補充說明 (2019/01/15增加此內容)</h2><p>上面介紹的公式是針對tensorflow內建的function功能(「padding = ‘VALID’」和「padding = ‘SAME’」)，並不是一般算卷積後算新的feature map長寬的公式。</p>
<p>一般卷積後算新的feature map長寬的公式如下:</p>
<p><img src="https://miro.medium.com/max/60/1*NnC2iZDC0f8NlovHr9gwkg.png?q=20" alt="img"></p>
<p><img src="https://miro.medium.com/max/1238/1*NnC2iZDC0f8NlovHr9gwkg.png" alt="img"></p>
<p>floor(1.1)=1, floor(1.6)=1</p>
<p>這邊跟前面差別在這邊多了一個pad參數。</p>
<p>對應到caffe prototxt卷積的參數會這麼寫，如下(其他模組應該是一樣可以設pad參數)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">convolution_param &#123;</span><br><span class="line"> num_output: 32</span><br><span class="line"> pad: 1</span><br><span class="line"> kernel_size: 3</span><br><span class="line"> stride: 2</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>這代表卷積層filter數設定為32，filter的kernel size是3，步伐stride是2，pad是1。pad=1，表示圖外圈額外加1圈0，假設pad=2，圖外圈額外加2圈0，以此類推。<br>所以kernel size是3的時候，你希望卷積後圖的寬高不要變，pad就要設定為1<br>假設kernel size是5的時候，你希望卷積後圖的寬高不要變，pad就要設定為2<br>假設kernel size是7的時候，你希望卷積後圖的寬高不要變，pad就要設定為3</p>
<p>Note: 因為一般大多只會用到卷積後，Feature map寬高會依據kernel size縮小一點(「padding = ‘VALID’」)或Feature map寬高不變(「padding = ‘SAME’」)，鮮少搞一些特殊的功能，比如1×1卷積還要加pad=1，這樣出來的圖會比原本大一圈，而且這一圈還全為0。<br>而且一般卷積網路都是希望卷積後圖越來越小(整體MACC計算量才會小)，除了segmentation和一些multi-scale object detection等才會用到deconv.或是一些upsample的方法把feature map放大。<br>Tensorflow是提供簡單的api，你就不需要自己去算pad要設多少，直接下strin即可(如下說明)，多方便阿。<br><code>**padding**</code>: A <code>string</code> from: <code>&quot;SAME&quot;, &quot;VALID&quot;</code>. The type of padding algorithm to use.</p>
<h4 id="456"><a href="#456" class="headerlink" title="456"></a>456</h4>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/08/Why%20does%20overlapped%20pooling%20help%20reduce%20overfitting%20in%20conv%20nets/">
                Why does overlapped pooling help reduce overfitting in conv nets
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="Why-does-overlapped-pooling-help-reduce-overfitting-in-conv-nets"><a href="#Why-does-overlapped-pooling-help-reduce-overfitting-in-conv-nets" class="headerlink" title="Why does overlapped pooling help reduce overfitting in conv nets?"></a><a href="https://stats.stackexchange.com/questions/283261/why-does-overlapped-pooling-help-reduce-overfitting-in-conv-nets" target="_blank" rel="noopener">Why does overlapped pooling help reduce overfitting in conv nets?</a></h1><p>I am going to answer this with the pooling example given above with some modifications. Let us say we have three <code>1D</code> features as given below.</p>
<p>[0 0 5 0 0 6 0 0 3 0 0 4 0 0]</p>
<p>[0 0 0 5 0 6 0 0 0 3 0 4 0 0]</p>
<p>[0 0 5 0 0 6 0 0 3 0 4 0 0 0]</p>
<p>When pooled using <code>z=2</code> and <code>s=2</code>, all 3 features lead to the same result as obtained above, that is</p>
<p>[0, 5, 6, 0, 3, 4, 0]</p>
<p>However when we use <code>z=3</code> and <code>s=2</code>, we get the following results respectively</p>
<p>[5, 5, 6, 3, 3, 4, 0]</p>
<p>[0, 5, 6, 0, 3, 4, 0]</p>
<p>[5, 5, 6, 3, 4, 4, 0]</p>
<p>Therefore, with overlapping pooling, we get three different results as opposed to one result when do not use overlapping. This is due to information loss when <code>z=s</code> which in this case leads to <strong>reduction</strong> in the amount of data available to train the network, i.e from 3 examples to 1 example. The shrinkage in the data size makes the training model overfit.</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/08/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5summary/">
                对称矩阵summary
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h2 id="机器学习-线性代数基础-5-1-最重要的矩阵：对称矩阵"><a href="#机器学习-线性代数基础-5-1-最重要的矩阵：对称矩阵" class="headerlink" title="机器学习 线性代数基础 | 5.1 最重要的矩阵：对称矩阵"></a>机器学习 线性代数基础 | 5.1 最重要的矩阵：对称矩阵</h2><h3 id="5-1-最重要的矩阵：对称矩阵"><a href="#5-1-最重要的矩阵：对称矩阵" class="headerlink" title="5.1  最重要的矩阵：对称矩阵"></a><strong>5.1  最重要的矩阵：对称矩阵</strong></h3><p>在对数据进行降维与压缩的运算处理过程中，有一类矩阵扮演了极其重要的角色，那就是对称矩阵。在线性代数的理论与实践中，我们将对称矩阵称之为“最重要的”矩阵丝毫不显夸张。</p>
<p>对称矩阵除了“自身与转置后的结果相等”这个最浅显、基本的性质外，还拥有许多重要的高级特性。在对角化的运算讨论中，我们会发现实数对称矩阵一定能够对角化，并且能够得到一组标准正交的特征向量。同时，任意一个矩阵A同他自身的转置矩阵<img src="./pics/640-20200308114054559.png" alt="img">)相乘都能得到一个对称矩阵，我们在本小节中就将重点关注<img src="./pics/640-20200308114054525.png" alt="img">这类对称矩阵并细致的讨论他的特征值所具有的重要性质，这些基础知识将会为后续的高级主题打下坚实的基础，希望大家不要错过。</p>
<h3 id="5-1-1-对称矩阵基本特性回顾"><a href="#5-1-1-对称矩阵基本特性回顾" class="headerlink" title="5.1.1 对称矩阵基本特性回顾"></a><strong>5.1.1 对称矩阵基本特性回顾</strong></h3><p>首先，我们简要的回顾一下在之前的章节中所介绍过的关于对称矩阵的一些重要基本特性：</p>
<p>如果一个矩阵<strong><em>S\</em></strong>的所有数据项都满足<img src="pics/00831rSTgy1gcmdogc0l1j30290100gb.jpg" alt="img">)的相等关系，那么这个矩阵就被称作是一个对称矩阵。通俗的说，一个对称矩阵通过转置操作得到的结果仍然是他自身，即满足：<img src="./pics/640-20200308114054634.png" alt="img">的运算要求。我们从这里面还可以推断出对阵矩阵<strong><em>S\</em></strong>所蕴含的一个前提条件：他必须是一个方阵。</p>
<p>我们还讲过，有一种获取对称矩阵的简单方法：一个矩阵乘以自己的转置矩阵，即<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">，其所得到的运算结果必然是一个对称矩阵，关于这个结论的证明方法也非常简单，我们简单看一下：</p>
<p><img src="./pics/640-20200308114054518.png" alt="img"></p>
<p>这个等式满足关于矩阵对称的基本定义。</p>
<h3 id="5-1-2-实对称矩阵一定可以对角化"><a href="#5-1-2-实对称矩阵一定可以对角化" class="headerlink" title="5.1.2 实对称矩阵一定可以对角化"></a><strong>5.1.2 实对称矩阵一定可以对角化</strong></h3><p>我们在这里只讨论实数范围内的对称矩阵问题。</p>
<p>在上一章的内容里我们讲过，对于一个任意的方阵，如果他的特征值两两不同，那么特征值所对应的特征向量彼此之间满足线性无关，这个方阵可以被对角化。如果方阵有相同的特征值，他很可能存在线性相关的特征向量，那么如果发生了这种情况，该方阵就不能够被对角化了。</p>
<p>但是，这种情况在对称矩阵身上是不会发生的。请大家牢牢记住：对于任意一个实数对称矩阵而言，他都一定可以被对角化。换句话说，对于一个对称矩阵，无论他的特征值是否重复，他的特征向量都一定满足线性无关。</p>
<p>在这里，具体的证明过程我们不展开，大家有兴趣可以查阅相关的资料。</p>
<h3 id="5-1-3-特征向量标准正交"><a href="#5-1-3-特征向量标准正交" class="headerlink" title="5.1.3 特征向量标准正交"></a><strong>5.1.3 特征向量标准正交</strong></h3><p>任意一个实对称矩阵都可以获得一组标准正交的特征向量。这可以说是对称矩阵里我认为最好的一个性质了，在这里我们用一个简单的方法来描述一下这个性质以及他的推导证明过程。</p>
<p>首先，实对称矩阵<strong><em>S\</em></strong>一定能够被对角化，可以被写成<img src="pics/00831rSTgy1gcmdpfcpkzj303400r0k4.jpg" alt="img">)的形式，其中对角矩阵<img src="./pics/640-20200308114054570.png" alt="img">的各元素一定均由实数构成，并且最为关键的一点是任何一个对称矩阵分解得到的特征向量矩阵都可以是标准正交矩阵。</p>
<p>为什么这么说呢，我们可以简单的看一个等式推导过程：</p>
<p>首先对矩阵<strong><em>S\</em></strong>进行矩阵分解，得到：<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcgVflSTtES2ykOQlJrnVrBlC1wicJwJvtL2icFw9wTqATkeOiaqp6VO9TQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)。由于矩阵<strong><em>S\</em></strong>是一个对称矩阵，满足<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcku45axLrw3RqbBGj7p4Sklv5zVdpUZducSF1clbQWjV6vM5kibMHwng/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的关系，于是有：</p>
<p><img src="./pics/640-20200308114054580.png" alt="img">。</p>
<p>那么，想要使得上面的等式相等，我们就需要满足对应位置上的元素相等，即：<img src="./pics/640-20200308114054619.png" alt="img">)，对此我们再进一步，就可以将其整理成<img src="./pics/640-20200308114054594.png" alt="img">)的漂亮形式。这恰恰说明了，我们此时获取的特征向量之间是满足标准正交关系的，我们可以将<strong><em>X\</em></strong>换记作正交矩阵的符号<strong><em>Q\</em></strong>，同时结合<img src="./pics/640-20200308114054611.png" alt="img">)这个基本特性，我们就可以把实对称矩阵的对角化过程变换成更好的形式，写作：<img src="./pics/640-20200308114054622.png" alt="img">。</p>
<h3 id="5-1-4-对称矩阵的分解形式"><a href="#5-1-4-对称矩阵的分解形式" class="headerlink" title="5.1.4 对称矩阵的分解形式"></a><strong>5.1.4 对称矩阵的分解形式</strong></h3><p>将对称矩阵<strong><em>S\</em></strong>分解成标准正交的特征向量只是其中的一种形式而已，由定义式<img src="./pics/640-20200308114054647.png" alt="img">我们可以得知，显然，特征向量是一个方向上的向量集合，不一定非得满足长度为1的要求，但是我们仍然可以通过直觉感受到一个事实，那就是一旦把特征向量都设置为单位向量，那么会在实践的过程中收获很多简化和美好。这个在后面的几节内容里，我们会不断的感受到由此带来的巨大好处。</p>
<p>此时，我们知道了对称矩阵<strong><em>S\</em></strong>一定可以得到由一组标准正交特征向量所构成的特征矩阵<strong><em>Q\</em></strong>。即，矩阵<strong><em>Q\</em></strong>可以表示成：<img src="./pics/640-20200308114054672.png" alt="img">的形式， 我们进一步将等式<img src="./pics/640-20200308114054717.png" alt="img">)进行展开，可以得到<img src="./pics/640-20200308114054672-3638854.png" alt="img">的完整相乘形式。</p>
<p>这个式子是非常重要的，接下来我们进一步将其做展开运算，将矩阵<strong><em>S\</em></strong>写成一组矩阵相加的形式，你就会发现他的精彩之处：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcIicn5aDl8aIcicXx3GmjsUdVsMU17nuy7VibWQwMRChia7T5icG5s428ywA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">。</p>
<p>在这一组标准正交向量当中，每一个<img src="./pics/640-20200308114054679.png" alt="img">相乘所得到的结果项都是一个秩为1并且与矩阵<strong><em>S\</em></strong>维数相等的方阵。同时他还满足方阵与方阵之间相乘的结果为0这个性质，也可以广义的理解为方阵之间满足“正交”。</p>
<p>最终，任意一个n阶对称矩阵<strong><em>S\</em></strong>都可以分解成n个秩1方阵乘以各自权重系数<img src="./pics/640-20200308114054752.png" alt="img">然后相加的结果。</p>
<h3 id="5-1-5-与的秩"><a href="#5-1-5-与的秩" class="headerlink" title="5.1.5 )与的秩"></a><strong>5.1.5 <img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)与<img src="./pics/640-20200308114054807.png" alt="img">的秩</strong></h3><p>在本书前面的章节中，我们介绍过这样一个结论，对于任意一个m×n形状的矩阵<strong><em>A\</em></strong>，他的列向量中线性无关向量的个数等于其行向量中线性无关向量的个数。</p>
<p>换句话说，也就是任意矩阵的行秩等于列秩，即满足：<img src="./pics/640-20200308114054733.png" alt="img">。这个结论可以从线性方程组消元化简的角度去思考，这样大家就会很容易明白了。</p>
<p>我们再看看矩阵<strong><em>A\</em></strong>和<img src="./pics/640-20200308114054749.png" alt="img">的秩之间的关系：</p>
<p>我们从零空间的角度入手去理解这个问题。即，如果方程<strong><em>Ax=0\</em></strong>和方程<img src="./pics/640-20200308114054804.png" alt="img">)是同解方程，那么他们就拥有相同的零空间，由于<strong><em>A\</em></strong>和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">这两个矩阵的列的个数相等，都为 n，因此，就可以推断出他们的列空间的维数相同，均为：<strong><em>n***</em></strong>−N(A)***，换句话说，也就能够推出二者的秩相等。</p>
<p>好的，那就让我们按照这个思路来推进：</p>
<p>首先，如果满足方程<strong><em>Ax=0\</em></strong>成立，方程两边同时乘以转置矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJclDFCYpPPQ3aOcCwEUarLP1zr9gDw0AmJCx8DnMDmPhrnjakbRjZmew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)，很明显，等式<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJce8ZA2jrNnvjXVwL1jIZEmZuicG8bFA3lDFcn6fWPZ3HtMj8thic78yfg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)同样能够成立。因此，我们可以说如果<strong><em>x\</em></strong>是方程<strong><em>Ax=0\</em></strong>的解，则能够推得出<strong><em>x\</em></strong>也一定是方程<img src="./pics/640-20200308114054765.png" alt="img">的解。</p>
<p>那么反过来呢，如果方程<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcY6ujibyA4J1pRMTkZ3G5iboRe1F2sDOpjgOY62eaZricJPHgWdu8K84xg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)成立，我们将方程两边同时乘以向量<img src="./pics/640-20200308114054775.png" alt="img">)，即方程<img src="./pics/640-20200308114054790.png" alt="img">)当然也一定能够成立，我们对这个等式稍微整理一下，就可以得到<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcM8OiaD6C5ESaG3OMR4jHUTWLGdkibkn38R7sY2wQFyQVgDd85vcZvT2A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)这个更加简洁的形式，从中可以看出一定能够满足<strong><em>Ax=0\</em></strong>成立。此时，我们可以说如果<strong><em>x\</em></strong>是方程<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcY6ujibyA4J1pRMTkZ3G5iboRe1F2sDOpjgOY62eaZricJPHgWdu8K84xg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的解，那么他一定也是方程<strong><em>Ax=0\</em></strong>的解。</p>
<p>于是，这个问题我们就说清楚了：方程<strong><img src="./pics/640-20200308114054817.png" alt="img"></strong>和方程<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJce8ZA2jrNnvjXVwL1jIZEmZuicG8bFA3lDFcn6fWPZ3HtMj8thic78yfg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)是一对同解的方程，矩阵<strong><em>A\</em></strong>和矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)这两个矩阵拥有相同的零空间，因此我们就解释清楚了矩阵<strong><em>A\</em></strong>和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">秩相等的问题。</p>
<p>那么同样的，我们由此不难发现也一定有矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJclDFCYpPPQ3aOcCwEUarLP1zr9gDw0AmJCx8DnMDmPhrnjakbRjZmew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的秩相等。那么这下好了，在<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcp02jRb44qpVmWLe2xdmcsHpSnMASoB0OcwibSF07f1pYSuBGOicCNXWQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">这个相等关系的纽带连接下，我们就有了以下这个结论：</p>
<p><img src="./pics/640-20200308114054843.png" alt="img"></p>
<p>从等式中可以看出，他们的秩都是相等的。</p>
<h3 id="5-1-6-对称矩阵的正定性描述"><a href="#5-1-6-对称矩阵的正定性描述" class="headerlink" title="5.1.6 对称矩阵的正定性描述"></a><strong>5.1.6</strong> <strong><img src="./pics/640-20200308114054862.png" alt="img">对称矩阵的正定性描述</strong></h3><p>最后，我们来聚焦一下对称矩阵特征值的问题，我们先介绍一组概念：如果一个矩阵的所有特征值都为正，我们称他是“正定的”矩阵，如果均为非负（即，最小的特征值为0），相当于结论上稍稍弱了一些，我们称之为“半正定的”矩阵，如果他含有负的特征值，那么显然，他是非正定的。</p>
<p>那么换句话说，对于一个对称矩阵而言，从特征值的正负性角度来看的话，他一定是正定、半正定或非正定的其中一种。</p>
<p>就正定性而言，一般的对称矩阵其实没有太多的特殊性，但是由任意矩阵<strong><em>A\</em></strong>乘以他的转置矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJclDFCYpPPQ3aOcCwEUarLP1zr9gDw0AmJCx8DnMDmPhrnjakbRjZmew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)得到的对称矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">，则具备非常好的特殊性质。即，他的特征值一定是非负的，换句话说，他至少是半正定的。</p>
<p>我们简单的说明一下为什么。</p>
<p>我们还是从特征向量的定义式子<img src="./pics/640-20200308114054884.png" alt="img">)入手进行分析，我们将等式两边同时乘以向量<img src="./pics/640-20200308114054964.png" alt="img">)，得到<img src="./pics/640-20200308114054893.png" alt="img">)这个新等式，由于特征向量必须非零，所以必然存在有<img src="./pics/640-20200308114054982.png" alt="img">)的不等关系。换句话说，此时等式<img src="./pics/640-20200308114054906.png" alt="img">)左侧的正负性就决定了右侧<img src="./pics/640-20200308114054922.png" alt="img">的正负性。</p>
<p>那么问题就来了，如果要满足正定性（或半正定性）的要求，那么就一定要满足所有的<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)都为正（或非负）的要求，等价于<img src="./pics/640-20200308114054981.png" alt="img">)的计算结果恒为正（或非负），这在<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcjhCQv699nEYqG44B4VdoAU7TLed5GMALZrPDoCJvbjWbvltKykicl7A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的条件下能够保证成立么？我们将其代入到等式中发现，这个是可以保证成立的：</p>
<p><img src="./pics/640-20200308114054933.png" alt="img">，</p>
<p>此时，如果矩阵<strong><em>A\</em></strong>的各列满足线性无关，由于向量<strong><em>x\</em></strong>是非零的，因此就能够保证所有的<strong><em>Ax***</em></strong>≠0***都成立，那么就有<img src="./pics/640-20200308114054948.png" alt="img">)恒成立。此时，对称矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)所有的特征值都满足<img src="./pics/640-20200308114055045.png" alt="img">，因此矩阵是正定的。</p>
<p>如果矩阵<strong><em>A\</em></strong>的各列线性相关，那么也就是说有x≠0而<strong><em>Ax=0\</em></strong>的情况存在，此时就只能保证<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcibgic2DWqRPVbR5Za6Eb2PBND3LENoDoiauoARYMicJ3aZmhH4M1dgxGBg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)（存在等于零的可能性），对称矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)就存在值为0的特征值<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">。因此，此时的矩阵是半正定的。</p>
<p>那么此时就可以继续挖掘出结论：实对称矩阵中非零特征值的个数等于该矩阵的秩。这个结论非常明显：因为矩阵<strong><em>A\</em></strong>与相似对角化后的矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcFPgH3uA0h6V41ujDm4EJjXUcCXicneKCwqOwDEvicIxxlxQIqzQ0ODJA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)拥有相同的特征值，同时由于相似性可知：这两个矩阵的秩相等。而<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcFPgH3uA0h6V41ujDm4EJjXUcCXicneKCwqOwDEvicIxxlxQIqzQ0ODJA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">最容易看出非零特征值的个数和秩的相等关系，从而结论得证。</p>
<p>我们总结一下，对称矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的所有特征值都满足非负性，特别的，如果矩阵<strong><em>A\</em></strong>的列向量满足线性无关，则该矩阵是一个正定矩阵，其特征值均为正。</p>
<h3 id="5-1-7-与的特征值"><a href="#5-1-7-与的特征值" class="headerlink" title="5.1.7 )与的特征值"></a><strong>5.1.7 <img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJchJt4fLISBkOfHRgMia7okcSjkrvXME32jxXkwUm5nHkZPmQWbSEHfibg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)与<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的特征值</strong></h3><p>最后，我们来看看<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)这两个对称矩阵的特征值满足什么样的关系。我告诉大家，这个问题的结论非常完美：<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">拥有完全一样的非零特征值。</p>
<p>我们从两个方向入手进行证明：说明如果<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)是矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值，那么他也是矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJchJt4fLISBkOfHRgMia7okcSjkrvXME32jxXkwUm5nHkZPmQWbSEHfibg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值；反过来，如果<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)是矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值，那么他同样也是矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的特征值。</p>
<p>我们假设矩阵<strong><em>A\</em></strong>的维度是m×n，矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的一个非零特征值是<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)，对应的特征向量是<strong><em>x\</em></strong>，那么依据定义有：<img src="./pics/640-20200308114055217.png" alt="img">)，我们将等式两边同时乘以矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJclDFCYpPPQ3aOcCwEUarLP1zr9gDw0AmJCx8DnMDmPhrnjakbRjZmew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)，即满足：<img src="./pics/640-20200308114055172.png" alt="img">)的相等关系，我们稍作整理就可以得到一个漂亮的等式：<img src="./pics/640-20200308114055198.png" alt="img">)，于是我们看出，矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值仍然是<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)，对应的特征向量为<img src="./pics/640-20200308114055256.png" alt="img">。</p>
<p>那么反过来呢，证明过程也是非常简单的，已知矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和对应的特征向量<strong><em>y\</em></strong>，依据定义有：<img src="./pics/640-20200308114055221.png" alt="img">)满足等式成立，两边同时乘以矩阵<strong><em>A\</em></strong>，可以得到：<img src="./pics/640-20200308114055261.png" alt="img">)的相等关系，也是对其稍作整理，就有：<img src="./pics/640-20200308114055304.png" alt="img">)，这个过程同样说明了，如果<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)是<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值，那么他也一定是<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的特征值。</p>
<p>这里，我们就给大家解释清了：<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">这两个对称矩阵拥有完全相同的非负特征值。</p>
<h3 id="5-1-8-对称矩阵的性质总结"><a href="#5-1-8-对称矩阵的性质总结" class="headerlink" title="5.1.8 对称矩阵的性质总结"></a><strong>5.1.8 对称矩阵的性质总结</strong></h3><p>在这一节里，我们讲解了对称矩阵的诸多重要性质和漂亮结论。他们不是零散的概念，而是可以构成一个知识网络。我在本节的最后给大家串联一下这些知识点，大家共同思考一下里面的内在关联：</p>
<p>对于任意的一个m×n形状的矩阵A，有如下性质：</p>
<p>● 矩阵A和转置矩阵<img src="./pics/640-20200308114055284.jpeg" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJclDFCYpPPQ3aOcCwEUarLP1zr9gDw0AmJCx8DnMDmPhrnjakbRjZmew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)相乘的结果<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">都是对称矩阵；</p>
<p>● 矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">都能够被对角化，且都可以通过矩阵分解，获得一组标准正交的特征向量；</p>
<p>● 矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJchJt4fLISBkOfHRgMia7okcSjkrvXME32jxXkwUm5nHkZPmQWbSEHfibg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)分别是n阶和m阶的方阵，一般情况下他们的维度都是不等的，但是他们的秩却一定满足相等关系，即满足：<img src="./pics/640-20200308114055425.png" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的相等关系；</p>
<p>● 对于矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">而言，他的特征值一定都是非负的，特别的，如果矩阵A的列向量满足线性无关，那么他的特征值全部为正，即为正定矩阵；</p>
<p>● 矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">拥有完全相同的非零特征值，非零特征值的个数与矩阵A的秩相等。</p>
<p>熟悉、掌握这五个重要结论，将会为本章后面几节的内容扫清最大的数学障碍，帮助大家更好的掌握相关的高级内容。</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/07/%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/">
                二叉树遍历
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-07</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="二叉树遍历（前序、中序、后序、层次遍历、深度优先、广度优先）"><a href="#二叉树遍历（前序、中序、后序、层次遍历、深度优先、广度优先）" class="headerlink" title="二叉树遍历（前序、中序、后序、层次遍历、深度优先、广度优先）"></a>二叉树遍历（前序、中序、后序、层次遍历、深度优先、广度优先）</h1><p>二叉树是一种非常重要的数据结构，很多其它数据结构都是基于二叉树的基础演变而来的。对于二叉树，有深度遍历和广度遍历，深度遍历有前序、中序以及后序三种遍历方法，广度遍历即我们平常所说的层次遍历。因为树的定义本身就是递归定义，因此采用递归的方法去实现树的三种遍历不仅容易理解而且代码很简洁，而对于广度遍历来说，需要其他数据结构的支撑，比如堆了。所以，对于一段代码来说，可读性有时候要比代码本身的效率要重要的多。</p>
<p>四种主要的遍历思想为：</p>
<p>前序遍历：根结点 —&gt; 左子树 —&gt; 右子树</p>
<p>中序遍历：左子树—&gt; 根结点 —&gt; 右子树</p>
<p>后序遍历：左子树 —&gt; 右子树 —&gt; 根结点</p>
<p>层次遍历：只需按层次遍历即可</p>
<p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gclqutmnqsj30bo0afwfg.jpg" alt="二叉树"></p>
<p>前序遍历：1  2  4  5  7  8  3  6 </p>
<p>中序遍历：4  2  7  5  8  1  3  6</p>
<p>后序遍历：4  7  8  5  2  6  3  1</p>
<p>层次遍历：1  2  3  4  5  6  7  8</p>
<h3 id="一、前序遍历"><a href="#一、前序遍历" class="headerlink" title="一、前序遍历"></a>一、前序遍历</h3><p>1）根据上文提到的遍历思路：根结点 —&gt; 左子树 —&gt; 右子树，很容易写出递归版本：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preOrderTraverse1</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (root != null) &#123;</span><br><span class="line">			System.out.<span class="built_in">print</span>(root.val+<span class="string">"  "</span>);</span><br><span class="line">			preOrderTraverse1(root.left);</span><br><span class="line">			preOrderTraverse1(root.right);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>



<p>2）现在讨论非递归的版本：<br>根据前序遍历的顺序，优先访问根结点，然后在访问左子树和右子树。所以，对于任意结点node，第一部分即直接访问之，之后在判断左子树是否为空，不为空时即重复上面的步骤，直到其为空。若为空，则需要访问右子树。注意，在访问过左孩子之后，需要反过来访问其右孩子，所以，需要栈这种数据结构的支持。对于任意一个结点node，具体步骤如下：</p>
<p>a)访问之，并把结点node入栈，当前结点置为左孩子；</p>
<p>b)判断结点node是否为空，若为空，则取出栈顶结点并出栈，将右孩子置为当前结点；否则重复a)步直到当前结点为空或者栈为空（可以发现栈中的结点就是为了访问右孩子才存储的）</p>
<p>代码如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preOrderTraverse2</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">		LinkedList&lt;TreeNode&gt; <span class="built_in">stack</span> = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">		TreeNode pNode = root;</span><br><span class="line">		<span class="keyword">while</span> (pNode != null || !<span class="built_in">stack</span>.isEmpty()) &#123;</span><br><span class="line">			<span class="keyword">if</span> (pNode != null) &#123;</span><br><span class="line">				System.out.<span class="built_in">print</span>(pNode.val+<span class="string">"  "</span>);</span><br><span class="line">				<span class="built_in">stack</span>.push(pNode);</span><br><span class="line">				pNode = pNode.left;</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123; <span class="comment">//pNode == null &amp;&amp; !stack.isEmpty()</span></span><br><span class="line">				TreeNode node = <span class="built_in">stack</span>.pop();</span><br><span class="line">				pNode = node.right;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>






<h3 id="二、中序遍历"><a href="#二、中序遍历" class="headerlink" title="二、中序遍历"></a>二、中序遍历</h3><p>1)根据上文提到的遍历思路：左子树 —&gt; 根结点 —&gt; 右子树，很容易写出递归版本：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inOrderTraverse1</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (root != null) &#123;</span><br><span class="line">			inOrderTraverse1(root.left);</span><br><span class="line">			System.out.<span class="built_in">print</span>(root.val+<span class="string">"  "</span>);</span><br><span class="line">			inOrderTraverse1(root.right);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>






<p>2）非递归实现，有了上面前序的解释，中序也就比较简单了，相同的道理。只不过访问的顺序移到出栈时。代码如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inOrderTraverse2</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">		LinkedList&lt;TreeNode&gt; <span class="built_in">stack</span> = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">		TreeNode pNode = root;</span><br><span class="line">		<span class="keyword">while</span> (pNode != null || !<span class="built_in">stack</span>.isEmpty()) &#123;</span><br><span class="line">			<span class="keyword">if</span> (pNode != null) &#123;</span><br><span class="line">				<span class="built_in">stack</span>.push(pNode);</span><br><span class="line">				pNode = pNode.left;</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123; <span class="comment">//pNode == null &amp;&amp; !stack.isEmpty()</span></span><br><span class="line">				TreeNode node = <span class="built_in">stack</span>.pop();</span><br><span class="line">				System.out.<span class="built_in">print</span>(node.val+<span class="string">"  "</span>);</span><br><span class="line">				pNode = node.right;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>





<h3 id="三、后序遍历"><a href="#三、后序遍历" class="headerlink" title="三、后序遍历"></a>三、后序遍历</h3><p>1）根据上文提到的遍历思路：左子树 —&gt; 右子树 —&gt; 根结点，很容易写出递归版本：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postOrderTraverse1</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (root != null) &#123;</span><br><span class="line">			postOrderTraverse1(root.left);</span><br><span class="line">			postOrderTraverse1(root.right);</span><br><span class="line">			System.out.<span class="built_in">print</span>(root.val+<span class="string">"  "</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>




<p>2）非递归的代码，暂且不写</p>
<h3 id="四、层次遍历"><a href="#四、层次遍历" class="headerlink" title="四、层次遍历"></a>四、层次遍历</h3><p>层次遍历的代码比较简单，只需要一个队列即可，先在队列中加入根结点。之后对于任意一个结点来说，在其出队列的时候，访问之。同时如果左孩子和右孩子有不为空的，入队列。代码如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">levelTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (root == null) &#123;</span><br><span class="line">			<span class="keyword">return</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		LinkedList&lt;TreeNode&gt; <span class="built_in">queue</span> = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">		<span class="built_in">queue</span>.offer(root);</span><br><span class="line">		<span class="keyword">while</span> (!<span class="built_in">queue</span>.isEmpty()) &#123;</span><br><span class="line">			TreeNode node = <span class="built_in">queue</span>.poll();</span><br><span class="line">			System.out.<span class="built_in">print</span>(node.val+<span class="string">"  "</span>);</span><br><span class="line">			<span class="keyword">if</span> (node.left != null) &#123;</span><br><span class="line">				<span class="built_in">queue</span>.offer(node.left);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> (node.right != null) &#123;</span><br><span class="line">				<span class="built_in">queue</span>.offer(node.right);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>



<h3 id="五、深度优先遍历"><a href="#五、深度优先遍历" class="headerlink" title="五、深度优先遍历"></a>五、深度优先遍历</h3><p>其实深度遍历就是上面的前序、中序和后序。但是为了保证与广度优先遍历相照应，也写在这。代码也比较好理解，其实就是前序遍历，代码如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">depthOrderTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">     <span class="keyword">if</span> (root == null) &#123;</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	LinkedList&lt;TreeNode&gt; <span class="built_in">stack</span> = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">	<span class="built_in">stack</span>.push(root);</span><br><span class="line">	<span class="keyword">while</span> (!<span class="built_in">stack</span>.isEmpty()) &#123;</span><br><span class="line">		TreeNode node = <span class="built_in">stack</span>.pop();</span><br><span class="line">		System.out.<span class="built_in">print</span>(node.val+<span class="string">"  "</span>);</span><br><span class="line">		<span class="keyword">if</span> (node.right != null) &#123;</span><br><span class="line">			<span class="built_in">stack</span>.push(node.right);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (node.left != null) &#123;</span><br><span class="line">			<span class="built_in">stack</span>.push(node.left);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/07/Gram%E7%9F%A9%E9%98%B5/">
                Gram矩阵
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-07</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <p>Gram Matrix实际上可看做是feature之间的偏心协方差矩阵（即没有减去均值的协方差矩阵），在feature map中，每一个数字都来自于一个特定滤波器在特定位置的卷积，因此每个数字就代表一个特征的强度，而Gram计算的实际上是两两特征之间的相关性，哪两个特征是同时出现的，哪两个是此消彼长的等等，同时，Gram的对角线元素，还体现了每个特征在图像中出现的量，因此，Gram有助于把握整个图像的大体风格。有了表示风格的Gram Matrix，要度量两个图像风格的差异，只需比较他们Gram Matrix的差异即可。</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/07/Jupyter%20Notebook%20%E5%9C%A8%20macOS%20%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%9A%84%E5%BF%AB%E6%8D%B7%E9%94%AE/">
                Jupyter Notebook 在 macOS 系统上的快捷键
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-07</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="Jupyter-Notebook-在-macOS-系统上的快捷键"><a href="#Jupyter-Notebook-在-macOS-系统上的快捷键" class="headerlink" title="Jupyter Notebook 在 macOS 系统上的快捷键"></a>Jupyter Notebook 在 macOS 系统上的快捷键</h1><p>通过 Anaconda 来管理 Python 的开发环境，其自带 <strong>Jupyter Notebook</strong> 。借此整理下 <strong>Jupyter Notebook</strong> 在 <strong>macOS 系统</strong>上常用的快捷键。</p>
<blockquote>
<p>Jupyter Notebook 有两种不同的键盘输入模式。「编辑模式」允许你在单元格中键入代码或文本，并由<strong>绿色单元格边框</strong>指示;「命令模式」将键盘绑定到Notebook命令，并由带有<strong>蓝色左边距的灰色单元格边框</strong>指示。</p>
</blockquote>
<h4 id="Mac-OS-X-修饰键"><a href="#Mac-OS-X-修饰键" class="headerlink" title="Mac OS X 修饰键"></a>Mac OS X 修饰键</h4><table>
<thead>
<tr>
<th>符号</th>
<th>修饰键</th>
<th></th>
<th>符号</th>
<th>修饰键</th>
</tr>
</thead>
<tbody><tr>
<td>⌘</td>
<td>Command</td>
<td></td>
<td>⇧</td>
<td>Shift</td>
</tr>
<tr>
<td>⌃</td>
<td>Control</td>
<td></td>
<td>↩</td>
<td>Return</td>
</tr>
<tr>
<td>⌥</td>
<td>Option</td>
<td></td>
<td>␣</td>
<td>Space</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>⇥</td>
<td>Tab</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>功能</th>
<th align="left">快捷键</th>
<th align="right">说明</th>
</tr>
</thead>
<tbody><tr>
<td>「命令模式」</td>
<td align="left">Esc</td>
<td align="right">蓝色的单元格</td>
</tr>
<tr>
<td>「编辑模式」</td>
<td align="left">Enter</td>
<td align="right">绿色的单元格</td>
</tr>
<tr>
<td>代码补全或缩进</td>
<td align="left">⇥</td>
<td align="right">「编辑模式」输入字母按 Tab 会补全，没有字母则缩进</td>
</tr>
<tr>
<td>向右缩进</td>
<td align="left">⌘ + ]</td>
<td align="right">「编辑模式」缩进</td>
</tr>
<tr>
<td>向左缩进</td>
<td align="left">⌘ + [</td>
<td align="right">「编辑模式」解除缩进</td>
</tr>
<tr>
<td>全选</td>
<td align="left">⌘ + A</td>
<td align="right">「编辑模式」</td>
</tr>
<tr>
<td>撤销</td>
<td align="left">⌘ + Z</td>
<td align="right">「编辑模式」</td>
</tr>
<tr>
<td>跳到本单元开头</td>
<td align="left">⌘ + ↑</td>
<td align="right">「编辑模式」</td>
</tr>
<tr>
<td>跳到本单元末尾</td>
<td align="left">⌘ + ↓</td>
<td align="right">「编辑模式」⌘ + End 同样的功能</td>
</tr>
<tr>
<td>跳到本行的最左边/开头</td>
<td align="left">⌘ + ←</td>
<td align="right">「编辑模式」</td>
</tr>
<tr>
<td>跳到本行的最右边/末尾</td>
<td align="left">⌘ + →️</td>
<td align="right">「编辑模式」</td>
</tr>
<tr>
<td>注释/撤销整行代码</td>
<td align="left">⌘ + /</td>
<td align="right">「编辑模式」</td>
</tr>
<tr>
<td>运行本单元，选择下行单元</td>
<td align="left">⇧ + ↩</td>
<td align="right">「编辑模式」、「命令模式」</td>
</tr>
<tr>
<td>运行本单元</td>
<td align="left">⌃ + ↩︎</td>
<td align="right">「编辑模式」、「命令模式」</td>
</tr>
<tr>
<td>运行本单元，插入下行新单元</td>
<td align="left">⌥ + ↩</td>
<td align="right">「编辑模式」、「命令模式」</td>
</tr>
<tr>
<td>选中上一个单元</td>
<td align="left">↑</td>
<td align="right">「命令模式」;「编辑模式」下可光标上移</td>
</tr>
<tr>
<td>选中下一个单元</td>
<td align="left">↓</td>
<td align="right">「命令模式」;「编辑模式」下可光标下移</td>
</tr>
<tr>
<td>删除选中单元</td>
<td align="left">D , D</td>
<td align="right">「命令模式」下连续按两个 D 字母键</td>
</tr>
<tr>
<td>撤销删除选中单元</td>
<td align="left">Z</td>
<td align="right">「命令模式」下按 Z 字母键</td>
</tr>
<tr>
<td>在本单元上方插入新单元</td>
<td align="left">A</td>
<td align="right">「命令模式」下按 A 字母键</td>
</tr>
<tr>
<td>在本单元下方插入新单元</td>
<td align="left">B</td>
<td align="right">「命令模式」下按 B 字母键</td>
</tr>
<tr>
<td>剪切单元格</td>
<td align="left">X</td>
<td align="right">「命令模式」下按 X 字母键</td>
</tr>
<tr>
<td>复制单元格</td>
<td align="left">C</td>
<td align="right">「命令模式」下按 C 字母键</td>
</tr>
<tr>
<td>粘贴单元格到上方</td>
<td align="left">⇧ + V</td>
<td align="right">「命令模式」</td>
</tr>
<tr>
<td>粘贴单元格到下方</td>
<td align="left">V</td>
<td align="right">「命令模式」下 V 字母键</td>
</tr>
<tr>
<td>更改单元格为Code</td>
<td align="left">Y</td>
<td align="right">「命令模式」下按 Y 字母键</td>
</tr>
<tr>
<td>更改单元格为Markdown</td>
<td align="left">M</td>
<td align="right">「命令模式」下按 M 字母键</td>
</tr>
<tr>
<td>更改单元格为Raw</td>
<td align="left">R</td>
<td align="right">「命令模式」下按 R 字母键</td>
</tr>
<tr>
<td>更改单元格为标题Heading1 - Heading6</td>
<td align="left">1 - 6</td>
<td align="right">「命令模式」下按1到6数字键*</td>
</tr>
<tr>
<td>合并选中的单元格</td>
<td align="left">⇧ + M</td>
<td align="right">「编辑模式」如果只有一个单元格被选中，则合并当前及以下单元格</td>
</tr>
<tr>
<td>保存当前Notebook</td>
<td align="left">⌘ + S</td>
<td align="right">「编辑模式」、「命令模式」或者「命令模式」下按 S 字母键</td>
</tr>
<tr>
<td>显示快捷键提示</td>
<td align="left">H</td>
<td align="right">「命令模式」下按 H 字母键，可自定义快捷键</td>
</tr>
<tr>
<td>中断Notebook内核</td>
<td align="left">I, I</td>
<td align="right">「命令模式」下连续按两个 I (interrupt) 字母键</td>
</tr>
<tr>
<td>重启Notebook内核</td>
<td align="left">0, 0</td>
<td align="right">「命令模式」下连续按两个0数字键</td>
</tr>
</tbody></table>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/05/multi-view%20learning/">
                multi-view learning
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-05</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="多视图学习（multi-view-learning）"><a href="#多视图学习（multi-view-learning）" class="headerlink" title="多视图学习（multi-view learning）"></a>多视图学习（multi-view learning）</h1><p><strong>概括：</strong>多视图学习就是360度，全方位无死角的欣赏（学习）然后得到最接近真实值的判定。</p>
<p>话说那么一天啊，一个人和一个蚂蚁在对话，他们看着一个米饭粒，人说，这个米饭粒胖嘟嘟的一定很香，蚂蚁说：你胡说，这米粒明明是长方形的，你干嘛说他胖嘟嘟的。然后他们就吵得面红耳赤，就去问上帝，这米究竟是什么样子的。上帝说：你们都没有错，人看到的是三维的世界，所以他们能看到立体的东西，而蚂蚁只能看到二维的，所以蚂蚁只能看到平面的。</p>
<p>从上面的小故事我们可以看出，多视图学习就是从多个角度去学习，然后数据进行预测提高准确性。</p>
<h1 id="一-半监督学习"><a href="#一-半监督学习" class="headerlink" title="一 半监督学习"></a>一 半监督学习</h1><p>半监督学习问题在真实世界中大量存在,以下列举几例:</p>
<p>在文本分类中,例如,垃圾邮件过滤问题,所有邮件都可以作为未标记数据,标记数据的获取要求用户标注哪些是垃圾邮件,哪些不是,如果使用传统的监督学习方法,需要用户标记上千个邮件作为样本,才能使训练的学习器有较好的过滤性能,而几乎没有用户愿意花如此多的时间标记邮件，在只有少量的用户标记邮件和大量的未标记邮件的情况下,使用半监督学习方法训练垃圾邮件过滤器可能是一个好的选择。在图像处理中,例如,计算机辅助医学图像分析问题,可以从医院获得大量的医学图像作为未标记数据,但如果要求医学专家把这些图像中的病灶都标识出来,往往是不现实的,一般只能对少量医学图像中的病灶进行标识,所以需要使用半监督学习方法来减少对标记数据的需求，在自然语言处理中,例如,句法分析问题,为了训练一个好的句法分析器需要构造句子/句法树,这是一项十分耗时的工作,构造几千个句法树可能要耗费一个语言学家几年的时间，而可以作为未标记数据使用的句子是普遍存在的,考虑未标记数据的半监督学习能解决语言学家的困难，上述实例表明,随着信息技术的飞速发展,我们面临的问题是,数据大量存在,但获取数据的标记却需要耗费大量的人力物力，传统的监督学习方法在标记数据较少的情况下很难获得好的预测性能”半监督学习正是为了解决这类问题而提出，在理论和实际中都具有重要意义。</p>
<h2 id="1-1多视图的半监督学习"><a href="#1-1多视图的半监督学习" class="headerlink" title="1.1多视图的半监督学习"></a>1.1多视图的半监督学习</h2><h3 id="1-1-1多视图数据"><a href="#1-1-1多视图数据" class="headerlink" title="1.1.1多视图数据"></a>1.1.1多视图数据</h3><p>在一些实际问题中，对于同一事物可以从多种不同的途径或不同的角度对其进行描述,这多种描述构成事物的多个视图(multi view)。本文用带下标的xi表示第i个数据点,用带上标的x(t)表示数据的第i个视图,则多视图数据可表示为xi={x1x2,…,xn}其中,表示视图的个数,多视图数据在真实世界中广泛存在,以下列举几例:在网页分类问题中,既可以根据网页本身包含的信息来对网页进行分类,也可以利用链接到该网页的超链接所包含的信息来进行分类,这样,网页数据就可以用两个视图表示,刻画网页本身包含信息的特征集构成第一个视图,刻画超链接所包含信息的特征集构成第二个视图,在电视片段的识别问题中,既可以根据视频中包含的信息来进行识别,也可以根据音频中包含的信息来进行识别,所以电视数据可以用视频和音频这两个视图表示”在自然语言理解问题中,同一语义对象,可以用不同的语言来表达,这些不同的语言描述就构成了此语义对象的不同视图表示,上述示例中,多视图用于表示数据的不同特征集,多视图还可以用于表示数据的不同来源;例如对于同一个数据源,用不同的采集装置进行采集,这多个采集结果构成了数据的不同视图;另外,多视图还可以用于表示数据间的不同关系;例如,学术论文的分类问题中,论文间既有参考文献的引用关系,也有作者的合作关系,可以把不同的关系用不同的视图来表示;有一些文献涉及多模态(multimodal)学习问题,但不同的文献中模态一词的含义不同”狭义的多模态是指人的不同感官,如视觉,听觉,嗅觉!触觉等;视觉所对应的图像或文字信息,和听觉所对应的声音信息,就构成多模态数据;广义的模态数据是指对于一个事物,通过不同的方法收集到的数据”例如在人脸识别中,可能收集到人脸的2D图像和3D形状模型,这就构成人脸数据的两个模态;在指纹识别中,用不同传感器采集的一个指纹的多种不同印痕,构成指纹数据的多个模态;对比多模态数据和多视图数据的概念可以看出,多视图的含义里包含了多模态,多视图可以表示更广泛的实际问题;</p>
<h3 id="1-3-2多视图数据的表示"><a href="#1-3-2多视图数据的表示" class="headerlink" title="1.3.2多视图数据的表示"></a>1.3.2多视图数据的表示</h3><p>数据的表示问题是机器学习的重点和难点问题之一，因为学习效果往往受到数据表示方法的影响。对于客观世界的对象,常常提取它的特征，然后用特征向量表示此对象，即xi={x1, x2… xn}了,其中n代表特征的个数。人们希望提取的特征体现了此对象的本质，从而能够用这些特征学习到目标概念。然而，对于一个学习问题，需要的最小特征集是不可知的，在缺乏先验信息的情况下,只能提取尽可能多的特征,提供给学习器,期望学习器能获得更好的预测性能”另外，数据收集技术的发展，使得人们可以通过更加复杂多样的手段对事物进行描述，这也导致数据的特征较多。这些描述对象的特征中，有些特征具有不同的属性，因此不适合使用同一种学习器进行学习。例如上述电视片段的识别问题中，电视片段具有视频和音频两部分特征，这两部分特征更适合分别用图像识别方法和声音识别方法来学习。如果使用单视图(即用所有特征组成一个特征向量，来表示电视片段，将无法选择一种既适合图像又适合声音的普适学习方法，在这种情况下，使用多视图的表示法较为适合，即把数据表示成多个特征集,然后在每个特征集上可以用不同的学习方法进行学习。</p>
<p>即使数据的特征能够使用同一种学习器进行学习,多视图学习也可能比单视图学习具有优势”例如上述网页分类问题中,网页本身所包含的信息和指向该网页的超链接所包含的信息均由单词构成,网页视图和超链接视图都可以表示成文本向量的形式,在这两个视图上可以用同一种学习器进行学习”然而,如果要把这两个视图合成一个视图,则得到的特征向量失去了原有的意义,而且可能增加了特征空间的维数,从而给学习带来不必要的困难”另外,数据的多视图表示方法还能够发挥各个视图的优势,利用未标记数据达到协同学习的目的,以改善学习性能,这一点接下来将具体介绍。</p>
<h3 id="1-3-3多视图的半监督学习"><a href="#1-3-3多视图的半监督学习" class="headerlink" title="1.3.3多视图的半监督学习"></a>1.3.3多视图的半监督学习</h3><p>在多视图的半监督学习中,一方面数据有多个视图,即x=xt,另一方面数据由标记数据集L和未标记数据集U组成,学习算法应考虑如何利用多个视图蕴含的信息和未标记数据蕴含的信息,来辅助传统的监督学习.在该领域具有代表性的算法有A.Blum和T.Mitchell提出的协同训练算法 (co一training)。该算法假设数据有两个视图，首先在两个视图上利用标记数据分别训练出一个分类器，然后，在协同训练过程中，每个分类器从未标记数据中挑选若干预测置信度较高的数据进行标记,并把标记后的数据加入另一个分类器的标记数据集中,以便对方利用这些新标记的数据进行更新，此过程不断迭代进行，直到达到某个停止条件。</p>
<p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gciccan4njj30hj08cab3.jpg" alt="img"></p>
<p>上图展示了协同训练算法的主要思想，图中,Cl和C2分别代表两个类别的数据,用两个不同的颜色表示,X(l)和X(2)代表数据的两个不同视图，在视图X(1)中，这两个类别的数据可以被分类器很好地区别开来,而在视图X(2)中,这两个类别的数据混合分布,很难训练得到好的分类器，在这种情况下，用视图X(l)训练的分类器可以把它对未标记数据的分类结果中比较置信那些的未标记数据,连同它对那些未标记数据的分类结果,一起提供给视图X(2)上的分类器，然后，用视图x(2)训练的分类器能够利用从视图X(l)上得到的信息，排除自身的不确定性,从而提高用视图X(2)训练的分类器性能，反之亦然，多视图学习正是利用数据在不同的视图学习的难易程度不同，来发挥视图之间的相互作用,，优势互补，协同学习。自从协同训练算法被提出以后,多视图的半监督学习得到研究者的重视，涌现出了一批相关工作，并取得了很多研究以根据音频中包含的信息来进行识别，所以电视数据可以用视频和音频这两个视图表示，在自然语言理解问题中，同一语义对象，可以用不同的语言来表达，这些不同的语言描述就构成了此语义对象的不同视图表示。上述示例中，多视图用于表示数据的不同特征集，多视图还可以用于表示数据的不同来源。例如对于同一个数据源，用不同的采集装置进行采集，这多个采集结果构成了数据的不同视图。另外，多视图还可以用于表示数据间的不同关系。例如，学术论文的分类问题中，论文间既有参考文献的引用关系,也有作者的合作关系，可以把不同的关系用不同的视图来表示，有一些文献涉及多模态(multimodal)学习问题，但不同的文献中模态一词的含义不同。狭义的多模态是指人的不同感官，如视觉，听觉，嗅觉，触觉等视觉所对应的图像或文字信息，和听觉所对应的声音信息，就构成多模态数据。广义的多模态数据是指对于一个事物，通过不同的方法收集到的数据。例如在人脸识别中，可能收集到人脸的3D图像和3D形状模型，这就构成人脸数据的两个模态。在指纹识别中，用不同传感器采集的一个指纹的多种不同印痕，构成指纹数据的多个模态。对比多模态数据和多视图数据的概念可以看出，多视图的含义里包含了多模态，多视图可以表示更广泛的实际问题。</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/01/%E7%AE%80%E5%8E%86/">
                简历
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-01</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="FDU-李云帆-Luke-Li"><a href="#FDU-李云帆-Luke-Li" class="headerlink" title="FDU 李云帆 [Luke Li]"></a>FDU 李云帆 [Luke Li]</h1><table>
<thead>
<tr>
<th>Skype</th>
<th>+86-15821154370</th>
</tr>
</thead>
<tbody><tr>
<td>Email</td>
<td><a href="mailto:16302010002@fudan.edu.cn">16302010002@fudan.edu.cn</a></td>
</tr>
<tr>
<td>Website</td>
<td><a href="http://liyunfan.fun/" target="_blank" rel="noopener">http://liyunfan.fun</a></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Fudan University 2016.09 - Expected 2021.05</th>
</tr>
</thead>
<tbody><tr>
<td>Software Engineering==transferred to Data Science in 2018</td>
</tr>
</tbody></table>
<h2 id="Educational-experience-and-honors"><a href="#Educational-experience-and-honors" class="headerlink" title="Educational experience and honors"></a>Educational experience and honors</h2><p><strong>TOEFL:112</strong>; <strong>GRE:326+3.5</strong> ; CET-6: 637</p>
<p><strong>GPA: 3.25/4.0</strong></p>
<p><strong>Second author</strong> of <a href="http://www.liyunfan.fun/%e2%9d%a4%ef%b8%8f%e6%96%87%e7%ab%a0%e5%8f%91%e8%a1%a8/Combined%20priority%20and%20path%20planning%20with%20a%20double-layer%20structure%20for%20multiple%20robots.pdf" target="_blank" rel="noopener">Combined priority and path planning with a double-layer structure for multiple robots</a></p>
<p><strong>2018 whole year,  Teaching Assistant</strong> for “ <strong>Introduction to computer systems</strong>“ (adaptation of CS213)</p>
<p><strong>Fall of 2018, Exchange experience</strong> at the *<em>University of California ,  Santa Cruz (UCSC) *</em></p>
<p><strong>2017.03 【Clover Software Development Innovation Competition】 Third Prize</strong></p>
<p><strong>2017.04 【* CTF Information Security Competition】 Star of the Future Award &amp; Third Prize</strong></p>
<p><strong>Member of ****** CTF team</strong> of Fudan University, 2017-2018</p>
<p><strong>2017.11, Third Prize - Fudan University Scholarship</strong></p>
<p>I was the Minister of Academics of the Students&#39; Union under department of Data Science since fall 2019.</p>
<h2 id="Intern-and-Research-Experience"><a href="#Intern-and-Research-Experience" class="headerlink" title="Intern and Research Experience"></a>Intern and Research Experience</h2><p>Fall 2020. <strong>Research intern</strong> at <a href="http://me.sjtu.edu.cn/teacher_directory1/caoqixin.html" target="_blank" rel="noopener">Prof. Qixin Cao</a>&#39;s <strong>RobotLab</strong>. <strong>Finished</strong> <a href="http://www.liyunfan.fun/%e2%9d%a4%ef%b8%8f%e6%96%87%e7%ab%a0%e5%8f%91%e8%a1%a8/Combined%20priority%20and%20path%20planning%20with%20a%20double-layer%20structure%20for%20multiple%20robots.pdf" target="_blank" rel="noopener"><strong>an article</strong></a> with Haili Wangon path planning for multi-robot scene <strong>as the second author</strong>. And is now in charge of <a href="http://www.liyunfan.fun/%e4%ba%a4%e9%80%9a%e5%a4%a7%e5%ad%a6%e6%99%ba%e8%83%bd%e6%9c%ba%e5%99%a8%e4%ba%ba%e5%ae%9e%e9%aa%8c%e5%ae%a4%e2%80%94%e2%80%94%e5%ba%b7%e5%a4%8d%e8%af%8a%e7%96%97%e5%bc%95%e5%af%bc%e4%b8%80%e4%bd%93%e5%8c%96%e7%b3%bb%e7%bb%9f/" target="_blank" rel="noopener">the smart-rehabilitation-system project</a>.</p>
<p>Spring 2019. <strong>Research intern</strong> at <a href="https://yangxu.info/" target="_blank" rel="noopener">Prof. Yang Xu</a>&#39;s <strong>Future Network Innovation Laboratory</strong>. Began to work on ways to model cache replacement algorithms to speed up simulations, to recognize request patterns and to find ways (mainly cache pollution attacks) to disrupt the locality of CDNs and corresponding countermeasures.</p>
<p>Fall 2017 and Spring 2018. <strong>Research intern</strong> at <strong>System Security Lab</strong> under supervision of <a href="https://yuanxzhang.github.io/" target="_blank" rel="noopener">Prof. Yuan Zhang</a> about the topic of Javascript RFCs through vulnerable WebView component in android systems.</p>
<p>Summer 2017. <strong>Backend engineer internship</strong> at ChenXi studio. I helped with the development of a web app for the school that involves generating and returning user-information-related-pictures, had 600+ users.</p>
<h2 id="Self-evaluation"><a href="#Self-evaluation" class="headerlink" title="Self-evaluation"></a>Self-evaluation</h2><p>Highly interest driven and self-motivating.</p>
<p>Strong learning abilities; strong sense of planning.</p>
<p>Pressure proof;highly resolved and self-disciplined; assiduous towards research.</p>
<h2 id="Skills-and-Interests"><a href="#Skills-and-Interests" class="headerlink" title="Skills and Interests"></a>Skills and Interests</h2><p>Self learned <a href="http://vision.stanford.edu/teaching/cs231n/" target="_blank" rel="noopener">CS231n</a>and <a href="https://www.bilibili.com/video/av62138405" target="_blank" rel="noopener">Pytorch tutorial</a></p>
<p>Excellent programing skills. Namely, proficiency in Java and Python; familiar with C++ and R, used JS and PHP before.</p>
<p>Currently interested in computer vision and robotics.</p>
<h2 id="In-school-project-experience"><a href="#In-school-project-experience" class="headerlink" title="In-school project experience"></a>In-school project experience</h2><h4 id="2016-012-Programming-A"><a href="#2016-012-Programming-A" class="headerlink" title="2016.012 Programming A"></a>2016.012 Programming A</h4><h6 id="Project-name-the-game-of-the-arena-chess"><a href="#Project-name-the-game-of-the-arena-chess" class="headerlink" title="Project name: the game of the arena chess"></a>Project name: the game of the arena chess</h6><p>100% completion, the realization of the JavaFX-based GUI, the corresponding user mouse and keyboard operation. </p>
<h4 id="2017-12-Object-Oriented-Design"><a href="#2017-12-Object-Oriented-Design" class="headerlink" title="2017.12 Object-Oriented Design"></a>2017.12 Object-Oriented Design</h4><h6 id="Project-name-2048-games"><a href="#Project-name-2048-games" class="headerlink" title="Project name: 2048 games"></a>Project name: 2048 games</h6><p>A C++ QT-based GUI2048 game, using depth search to achieve AI functionality. </p>
<h4 id="2017-06-Introduction-to-Web-Applications"><a href="#2017-06-Introduction-to-Web-Applications" class="headerlink" title="2017.06 Introduction to Web Applications"></a>2017.06 Introduction to Web Applications</h4><h6 id="Project-name-Image-sharing-website"><a href="#Project-name-Image-sharing-website" class="headerlink" title="Project name: Image sharing website"></a>Project name: Image sharing website</h6><p>A web interface. PHP + MySQL as backend, frontend HTML, CSS, JavaScript, user authentication with cookies, encryption using hashing with salt. </p>
<h4 id="2017-12-Data-Structure-and-Algorithm-Design"><a href="#2017-12-Data-Structure-and-Algorithm-Design" class="headerlink" title="2017.12 Data Structure and Algorithm Design"></a>2017.12 Data Structure and Algorithm Design</h4><h6 id="Project-name-Chess-AI"><a href="#Project-name-Chess-AI" class="headerlink" title="Project name: Chess AI"></a>Project name: Chess AI</h6><p>min-max search, alpha-beta pruning, search layer: 4.</p>
<h4 id="2017-12-Computer-System-Foundation-2"><a href="#2017-12-Computer-System-Foundation-2" class="headerlink" title="2017.12 Computer System Foundation (2)"></a>2017.12 Computer System Foundation (2)</h4><h6 id="Project-name-CLI-multi-threaded-chat-room"><a href="#Project-name-CLI-multi-threaded-chat-room" class="headerlink" title="Project name: CLI multi-threaded chat room"></a>Project name: CLI multi-threaded chat room</h6><p>thread pool monitoring message, specify ip+port to achieve message transmission.</p>
<h4 id="2018-06-Software-Engineering-Group-Work"><a href="#2018-06-Software-Engineering-Group-Work" class="headerlink" title="2018.06 Software Engineering (Group Work)"></a>2018.06 Software Engineering (Group Work)</h4><h6 id="Project-name-Calendar-Notepad"><a href="#Project-name-Calendar-Notepad" class="headerlink" title="Project name: Calendar Notepad"></a>Project name: Calendar Notepad</h6><p>This course focuses on design patterns and code refactoring. Responsible for backend development. </p>
<h4 id="2018-06-Computer-Graphics"><a href="#2018-06-Computer-Graphics" class="headerlink" title="2018.06 Computer Graphics"></a>2018.06 Computer Graphics</h4><h6 id="Project-name-WebGL-project"><a href="#Project-name-WebGL-project" class="headerlink" title="Project name: WebGL project"></a>Project name: WebGL project</h6><p>Draw a scene with WebGL, user keyboard event to achieve camera perspective change and omnidirectional movement, realize keyboard event control object visibility, realize keyboard event control transformation.</p>
<h4 id="2018-06-Neural-Network-and-Deep-Learning-Group-Work"><a href="#2018-06-Neural-Network-and-Deep-Learning-Group-Work" class="headerlink" title="2018.06 Neural Network and Deep Learning (Group Work)"></a>2018.06 Neural Network and Deep Learning (Group Work)</h4><h6 id="Project-name-Chinese-ancient-poetry-generation"><a href="#Project-name-Chinese-ancient-poetry-generation" class="headerlink" title="Project name: Chinese ancient poetry generation"></a>Project name: Chinese ancient poetry generation</h6><p>Based on TensorFlow framework, using LSTM.</p>
<h4 id="Fall-2018"><a href="#Fall-2018" class="headerlink" title="Fall 2018   /"></a>Fall 2018   /</h4><h6 id="exchanging-in-UCSC-no-projects"><a href="#exchanging-in-UCSC-no-projects" class="headerlink" title="exchanging in UCSC, no projects"></a>exchanging in UCSC, no projects</h6><h4 id="2019-06-Distributed-Systems"><a href="#2019-06-Distributed-Systems" class="headerlink" title="2019.06 Distributed Systems"></a>2019.06 Distributed Systems</h4><h6 id="Project-name-New-York-Taxi-Data-Analysis"><a href="#Project-name-New-York-Taxi-Data-Analysis" class="headerlink" title="Project name: New York Taxi Data Analysis"></a>Project name: New York Taxi Data Analysis</h6><p>Doing massive data analysis on Spark.</p>
<h4 id="2019-06-Advanced-Data-Science"><a href="#2019-06-Advanced-Data-Science" class="headerlink" title="2019.06 Advanced Data Science"></a>2019.06 Advanced Data Science</h4><h6 id="Project-name-Turkish-population-data-analysis"><a href="#Project-name-Turkish-population-data-analysis" class="headerlink" title="Project name: Turkish population data analysis"></a>Project name: Turkish population data analysis</h6><p>Doing massive data analysis on Spark. Machine learning algorithms applied.</p>
<h4 id="2019-06-Artificial-Intelligence-Group-Work"><a href="#2019-06-Artificial-Intelligence-Group-Work" class="headerlink" title="2019.06 Artificial Intelligence (Group Work)"></a>2019.06 Artificial Intelligence (Group Work)</h4><h6 id="Project-name-Gomoku-on-piskvorkGomoku-agent-implemented-with-MCTS"><a href="#Project-name-Gomoku-on-piskvorkGomoku-agent-implemented-with-MCTS" class="headerlink" title="Project name: Gomoku on piskvorkGomoku agent implemented with MCTS"></a>Project name: Gomoku on piskvorkGomoku agent implemented with MCTS</h6><p> ADP &amp; Threat-space search applied. </p>
<h4 id="2019-06-Social-Network-Mining-Group-Work"><a href="#2019-06-Social-Network-Mining-Group-Work" class="headerlink" title="2019.06 Social Network Mining (Group Work)"></a>2019.06 Social Network Mining (Group Work)</h4><h6 id="Project-name-Movie-recommendation-algorithms-for-users"><a href="#Project-name-Movie-recommendation-algorithms-for-users" class="headerlink" title="Project name: Movie recommendation algorithms for users"></a>Project name: Movie recommendation algorithms for users</h6><p>Using web crawlers to gather data (from <a href="https://www.douban.com/" target="_blank" rel="noopener">Douban</a>) and multiple recommendation algorithms to make reasonable choices of recommendation to users.</p>
<h4 id="2019-06-Statistical-machine-learning-Group-Work"><a href="#2019-06-Statistical-machine-learning-Group-Work" class="headerlink" title="2019.06 Statistical machine learning (Group Work)"></a>2019.06 Statistical machine learning (Group Work)</h4><h6 id="Project-name-Kaggle-Box-office-prediction"><a href="#Project-name-Kaggle-Box-office-prediction" class="headerlink" title="Project name: [Kaggle] Box office prediction"></a>Project name: [Kaggle] <a href="https://www.kaggle.com/c/tmdb-box-office-prediction/" target="_blank" rel="noopener">Box office prediction</a></h6><p>Using LightGBM for prediction. [Kaggle]Project name: Bilibili Data AnalysisUsing web crawlers to gather data (from <a href="https://bilibili.com/" target="_blank" rel="noopener">Bilibili</a>) for Data Analysis on video uploaders.</p>
<h4 id="2019-06-Financial-Time-Series-in-Data-Mining-Group-Work"><a href="#2019-06-Financial-Time-Series-in-Data-Mining-Group-Work" class="headerlink" title="2019.06 Financial Time Series in Data Mining (Group Work)"></a>2019.06 Financial Time Series in Data Mining (Group Work)</h4><h6 id="Project-name-Residential-electricity-usage-data-analysis"><a href="#Project-name-Residential-electricity-usage-data-analysis" class="headerlink" title="Project name: Residential electricity usage data analysis"></a>Project name: Residential electricity usage data analysis</h6><p>Using DTW for time series classification and LSTM for time series prediction. Data from Bureau of Shanghai Electric Power.</p>
<h6 id="Project-name-Time-series-analysis-on-search-engine-searches-for-keyword-quot-Big-Data-quot"><a href="#Project-name-Time-series-analysis-on-search-engine-searches-for-keyword-quot-Big-Data-quot" class="headerlink" title="Project name: Time series analysis on search engine searches for keyword &quot;Big Data&quot;"></a>Project name: Time series analysis on search engine searches for keyword &quot;Big Data&quot;</h6><p>Using web crawlers to gather data (from <a href="http://index.baidu.com/v2/index.html?from=pinzhuan#/" target="_blank" rel="noopener">Baidu Index</a>) to predict future market size of the &quot;Big Data&quot; industry. </p>
<h2 id="The-courses-that-I-have-finished-until-now"><a href="#The-courses-that-I-have-finished-until-now" class="headerlink" title="The courses that I have finished until now :"></a>The courses that I have finished until now :</h2><table>
<thead>
<tr>
<th><strong>Course Index</strong></th>
<th><strong>Course Name</strong></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Math and Physics</strong></td>
<td></td>
</tr>
<tr>
<td>MATH120021</td>
<td>Advanced Mathematics A I</td>
</tr>
<tr>
<td>MATH120022</td>
<td>Advanced Mathematics A II</td>
</tr>
<tr>
<td>SOFT130039</td>
<td>Discrete Math I</td>
</tr>
<tr>
<td>SOFT130040</td>
<td>Discrete Math II</td>
</tr>
<tr>
<td>SOFT130079</td>
<td>Linear Algebra</td>
</tr>
<tr>
<td>PHYS120013</td>
<td>College Physics B I</td>
</tr>
<tr>
<td>PHYS120014</td>
<td>College Physics B II</td>
</tr>
<tr>
<td>PHYS120015</td>
<td>Fundamental Physics Experiments</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>English</strong></td>
<td></td>
</tr>
<tr>
<td>ENGL110012</td>
<td>Audio-visual English</td>
</tr>
<tr>
<td>ENGL110061</td>
<td>Essay Writing</td>
</tr>
<tr>
<td>ENGL110066</td>
<td>English for Business Communication</td>
</tr>
<tr>
<td>ENGL110068</td>
<td>Advanced English</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Programing</strong></td>
<td></td>
</tr>
<tr>
<td>SOFT120001</td>
<td>Programming A (Java)</td>
</tr>
<tr>
<td>SOFT130002</td>
<td>Introduction to Web Applications (PHP+JS+HTML+CSS)</td>
</tr>
<tr>
<td>SOFT130004</td>
<td>Data Structure and Algorithm Design (Python)</td>
</tr>
<tr>
<td>SOFT130006</td>
<td>Software Engineering (Java)</td>
</tr>
<tr>
<td>SOFT130059</td>
<td>Object-Oriented Programming in C++</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Data Mining</strong></td>
<td></td>
</tr>
<tr>
<td>DATA130001</td>
<td>Financial Time Series in Data Mining</td>
</tr>
<tr>
<td>DATA130007</td>
<td>Social Network Mining</td>
</tr>
<tr>
<td>DATA130014</td>
<td>Advanced Data Science</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Machine Learning</strong></td>
<td></td>
</tr>
<tr>
<td>DATA130008</td>
<td>Artificial Intelligence</td>
</tr>
<tr>
<td>DATA130011</td>
<td>Neural Network and Deep Learning</td>
</tr>
<tr>
<td>DATA130003</td>
<td>Statistical machine learning</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Computer System</strong></td>
<td></td>
</tr>
<tr>
<td>SOFT130056</td>
<td>Introduction to Computer Systems I</td>
</tr>
<tr>
<td>SOFT130057</td>
<td>Introduction to Computer Systems II</td>
</tr>
<tr>
<td>DATA130020</td>
<td>Database and Implementation</td>
</tr>
<tr>
<td>DATA130015</td>
<td>Large-scale Distributed Systems</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th><strong>Statistics</strong></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>DATA130005</td>
<td>Statistics: Principles, Methods and R (I)</td>
</tr>
<tr>
<td>DATA130004</td>
<td>Computational Statistics</td>
</tr>
<tr>
<td>DATA130009</td>
<td>Statistics: Principles, Methods and R (II)</td>
</tr>
</tbody></table>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/02/29/6.style_GAN/">
                6.style_GAN
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-02-29</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="PyTorch入门与实战第六课"><a href="#PyTorch入门与实战第六课" class="headerlink" title="PyTorch入门与实战第六课"></a>PyTorch入门与实战第六课</h1><p>褚则伟 <a href="mailto:zeweichu@gmail.com">zeweichu@gmail.com</a></p>
<h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><ul>
<li>图片风格迁移 </li>
<li>用GAN生成MNIST</li>
<li>用DCGAN生成更复杂的图片</li>
</ul>
<h2 id="图片风格迁移-Neural-Style-Transfer"><a href="#图片风格迁移-Neural-Style-Transfer" class="headerlink" title="图片风格迁移 Neural Style Transfer"></a>图片风格迁移 Neural Style Transfer</h2><p><a href="https://arxiv.org/pdf/1508.06576.pdf" target="_blank" rel="noopener">A Neural Algorithm of Artistic Style</a><br>本文介绍了Neural Style Transfor模型</p>
<p><a href="https://arxiv.org/pdf/1701.01036.pdf" target="_blank" rel="noopener">Demystifying Neural Style Transfer</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image</span><span class="params">(image_path, transform=None, max_size=None, shape=None)</span>:</span></span><br><span class="line">    image = Image.open(image_path)</span><br><span class="line">    <span class="keyword">if</span> max_size:</span><br><span class="line">        scale = max_size / max(image.size)</span><br><span class="line">        size= np.array(image.size) * scale</span><br><span class="line">        image = image.resize(size.astype(int), Image.ANTIALIAS)</span><br><span class="line">         </span><br><span class="line">    <span class="keyword">if</span> shape:</span><br><span class="line">        image = image.resize(shape, Image.LANCZOS)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> transform:</span><br><span class="line">        image = transform(image).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> image.to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                        std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">]) <span class="comment"># 来自ImageNet的mean和variance</span></span><br><span class="line"></span><br><span class="line">content = load_image(<span class="string">"png/content.png"</span>, transform, max_size=<span class="number">400</span>)</span><br><span class="line">stype = load_image(<span class="string">"png/style.png"</span>, transform, shape=[content.size(<span class="number">2</span>), content.size(<span class="number">3</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># content = load_image("png/content.png", transforms.Compose([</span></span><br><span class="line"><span class="comment">#     transforms.ToTensor(),</span></span><br><span class="line"><span class="comment"># ]), max_size=400)</span></span><br><span class="line"><span class="comment"># style = load_image("png/style.png", transforms.Compose([</span></span><br><span class="line"><span class="comment">#     transforms.ToTensor(),</span></span><br><span class="line"><span class="comment"># ]), shape=[content.size(2), content.size(3)])</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stype.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([1, 3, 400, 272])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">unloader = transforms.ToPILImage()  <span class="comment"># reconvert into PIL image</span></span><br><span class="line"></span><br><span class="line">plt.ion()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span><span class="params">(tensor, title=None)</span>:</span></span><br><span class="line">    image = tensor.cpu().clone()  <span class="comment"># we clone the tensor to not do changes on it</span></span><br><span class="line">    image = image.squeeze(<span class="number">0</span>)      <span class="comment"># remove the fake batch dimension</span></span><br><span class="line">    image = unloader(image)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    plt.pause(<span class="number">0.001</span>) <span class="comment"># pause a bit so that plots are updated</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">imshow(style[<span class="number">0</span>], title=<span class="string">'Image'</span>)</span><br><span class="line"><span class="comment"># content.shape</span></span><br></pre></td></tr></table></figure>


<p><img src="output_7_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGGNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(VGGNet, self).__init__()</span><br><span class="line">        self.select = [<span class="string">'0'</span>, <span class="string">'5'</span>, <span class="string">'10'</span>, <span class="string">'19'</span>, <span class="string">'28'</span>]</span><br><span class="line">        self.vgg = models.vgg19(pretrained=<span class="literal">True</span>).features</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        features = []</span><br><span class="line">        <span class="keyword">for</span> name, layer <span class="keyword">in</span> self.vgg._modules.items():</span><br><span class="line">            x = layer(x)</span><br><span class="line">            <span class="keyword">if</span> name <span class="keyword">in</span> self.select:</span><br><span class="line">                features.append(x)</span><br><span class="line">        <span class="keyword">return</span> features</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">target = content.clone().requires_grad_(<span class="literal">True</span>)</span><br><span class="line">optimizer = torch.optim.Adam([target], lr=<span class="number">0.003</span>, betas=[<span class="number">0.5</span>, <span class="number">0.999</span>])</span><br><span class="line">vgg = VGGNet().to(device).eval()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">target_features = vgg(target)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">total_step = <span class="number">2000</span></span><br><span class="line">style_weight = <span class="number">100.</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(total_step):</span><br><span class="line">    target_features = vgg(target)</span><br><span class="line">    content_features = vgg(content)</span><br><span class="line">    style_features = vgg(style)</span><br><span class="line">    </span><br><span class="line">    style_loss = <span class="number">0</span></span><br><span class="line">    content_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> f1, f2, f3 <span class="keyword">in</span> zip(target_features, content_features, style_features):</span><br><span class="line">        content_loss += torch.mean((f1-f2)**<span class="number">2</span>)</span><br><span class="line">        _, c, h, w = f1.size()</span><br><span class="line">        f1 = f1.view(c, h*w)</span><br><span class="line">        f3 = f3.view(c, h*w)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算gram matrix</span></span><br><span class="line">        f1 = torch.mm(f1, f1.t())</span><br><span class="line">        f3 = torch.mm(f3, f3.t())</span><br><span class="line">        style_loss += torch.mean((f1-f3)**<span class="number">2</span>)/(c*h*w)</span><br><span class="line">        </span><br><span class="line">    loss = content_loss + style_weight * style_loss</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新target</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"Step [&#123;&#125;/&#123;&#125;], Content Loss: &#123;:.4f&#125;, Style Loss: &#123;:.4f&#125;"</span></span><br><span class="line">             .format(step, total_step, content_loss.item(), style_loss.item()))</span><br></pre></td></tr></table></figure>

<pre><code>Step [0/2000], Content Loss: 0.0000, Style Loss: 531.1730
Step [10/2000], Content Loss: 6.0654, Style Loss: 360.6187
Step [20/2000], Content Loss: 11.3430, Style Loss: 253.8006
Step [30/2000], Content Loss: 14.5195, Style Loss: 190.0798
Step [40/2000], Content Loss: 16.5578, Style Loss: 152.3939
Step [50/2000], Content Loss: 17.9683, Style Loss: 129.4922
Step [60/2000], Content Loss: 19.0225, Style Loss: 114.5218
Step [70/2000], Content Loss: 19.8584, Style Loss: 103.7824
Step [80/2000], Content Loss: 20.5509, Style Loss: 95.5047
Step [90/2000], Content Loss: 21.1601, Style Loss: 88.7919
Step [100/2000], Content Loss: 21.6844, Style Loss: 83.1393
Step [110/2000], Content Loss: 22.1447, Style Loss: 78.2809
Step [120/2000], Content Loss: 22.5605, Style Loss: 74.0401
Step [130/2000], Content Loss: 22.9415, Style Loss: 70.2842
Step [140/2000], Content Loss: 23.2941, Style Loss: 66.9353
Step [150/2000], Content Loss: 23.6130, Style Loss: 63.9158
Step [160/2000], Content Loss: 23.9114, Style Loss: 61.1637
Step [170/2000], Content Loss: 24.1892, Style Loss: 58.6509
Step [180/2000], Content Loss: 24.4448, Style Loss: 56.3407
Step [190/2000], Content Loss: 24.6883, Style Loss: 54.1998
Step [200/2000], Content Loss: 24.9212, Style Loss: 52.2185
Step [210/2000], Content Loss: 25.1355, Style Loss: 50.3827
Step [220/2000], Content Loss: 25.3350, Style Loss: 48.6758
Step [230/2000], Content Loss: 25.5269, Style Loss: 47.0833
Step [240/2000], Content Loss: 25.7123, Style Loss: 45.5909
Step [250/2000], Content Loss: 25.8884, Style Loss: 44.1901
Step [260/2000], Content Loss: 26.0555, Style Loss: 42.8741
Step [270/2000], Content Loss: 26.2152, Style Loss: 41.6320
Step [280/2000], Content Loss: 26.3691, Style Loss: 40.4600
Step [290/2000], Content Loss: 26.5208, Style Loss: 39.3519
Step [300/2000], Content Loss: 26.6641, Style Loss: 38.3040
Step [310/2000], Content Loss: 26.8034, Style Loss: 37.3103
Step [320/2000], Content Loss: 26.9339, Style Loss: 36.3693
Step [330/2000], Content Loss: 27.0649, Style Loss: 35.4760
Step [340/2000], Content Loss: 27.1923, Style Loss: 34.6284
Step [350/2000], Content Loss: 27.3130, Style Loss: 33.8245
Step [360/2000], Content Loss: 27.4284, Style Loss: 33.0575
Step [370/2000], Content Loss: 27.5356, Style Loss: 32.3269
Step [380/2000], Content Loss: 27.6426, Style Loss: 31.6281
Step [390/2000], Content Loss: 27.7454, Style Loss: 30.9596
Step [400/2000], Content Loss: 27.8430, Style Loss: 30.3200
Step [410/2000], Content Loss: 27.9398, Style Loss: 29.7072
Step [420/2000], Content Loss: 28.0368, Style Loss: 29.1180
Step [430/2000], Content Loss: 28.1289, Style Loss: 28.5518
Step [440/2000], Content Loss: 28.2207, Style Loss: 28.0077
Step [450/2000], Content Loss: 28.3101, Style Loss: 27.4842
Step [460/2000], Content Loss: 28.4016, Style Loss: 26.9804
Step [470/2000], Content Loss: 28.4844, Style Loss: 26.4949
Step [480/2000], Content Loss: 28.5667, Style Loss: 26.0286
Step [490/2000], Content Loss: 28.6440, Style Loss: 25.5799
Step [500/2000], Content Loss: 28.7183, Style Loss: 25.1476
Step [510/2000], Content Loss: 28.7939, Style Loss: 24.7302
Step [520/2000], Content Loss: 28.8708, Style Loss: 24.3261
Step [530/2000], Content Loss: 28.9440, Style Loss: 23.9349
Step [540/2000], Content Loss: 29.0163, Style Loss: 23.5566
Step [550/2000], Content Loss: 29.0864, Style Loss: 23.1890
Step [560/2000], Content Loss: 29.1529, Style Loss: 22.8329
Step [570/2000], Content Loss: 29.2189, Style Loss: 22.4880
Step [580/2000], Content Loss: 29.2833, Style Loss: 22.1529
Step [590/2000], Content Loss: 29.3477, Style Loss: 21.8286
Step [600/2000], Content Loss: 29.4093, Style Loss: 21.5141
Step [610/2000], Content Loss: 29.4694, Style Loss: 21.2083
Step [620/2000], Content Loss: 29.5252, Style Loss: 20.9107
Step [630/2000], Content Loss: 29.5821, Style Loss: 20.6206
Step [640/2000], Content Loss: 29.6378, Style Loss: 20.3381
Step [650/2000], Content Loss: 29.6938, Style Loss: 20.0623
Step [660/2000], Content Loss: 29.7449, Style Loss: 19.7930
Step [670/2000], Content Loss: 29.7975, Style Loss: 19.5310
Step [680/2000], Content Loss: 29.8479, Style Loss: 19.2760
Step [690/2000], Content Loss: 29.8950, Style Loss: 19.0278
Step [700/2000], Content Loss: 29.9427, Style Loss: 18.7856
Step [710/2000], Content Loss: 29.9889, Style Loss: 18.5502
Step [720/2000], Content Loss: 30.0369, Style Loss: 18.3209
Step [730/2000], Content Loss: 30.0841, Style Loss: 18.0967
Step [740/2000], Content Loss: 30.1312, Style Loss: 17.8776
Step [750/2000], Content Loss: 30.1793, Style Loss: 17.6630
Step [760/2000], Content Loss: 30.2209, Style Loss: 17.4535
Step [770/2000], Content Loss: 30.2625, Style Loss: 17.2486
Step [780/2000], Content Loss: 30.3043, Style Loss: 17.0483
Step [790/2000], Content Loss: 30.3472, Style Loss: 16.8526
Step [800/2000], Content Loss: 30.3883, Style Loss: 16.6612
Step [810/2000], Content Loss: 30.4279, Style Loss: 16.4737
Step [820/2000], Content Loss: 30.4663, Style Loss: 16.2899
Step [830/2000], Content Loss: 30.5036, Style Loss: 16.1099
Step [840/2000], Content Loss: 30.5427, Style Loss: 15.9336
Step [850/2000], Content Loss: 30.5801, Style Loss: 15.7608
Step [860/2000], Content Loss: 30.6190, Style Loss: 15.5913
Step [870/2000], Content Loss: 30.6561, Style Loss: 15.4249
Step [880/2000], Content Loss: 30.6927, Style Loss: 15.2619
Step [890/2000], Content Loss: 30.7275, Style Loss: 15.1023
Step [900/2000], Content Loss: 30.7620, Style Loss: 14.9457
Step [910/2000], Content Loss: 30.7954, Style Loss: 14.7917
Step [920/2000], Content Loss: 30.8298, Style Loss: 14.6399
Step [930/2000], Content Loss: 30.8670, Style Loss: 14.4906
Step [940/2000], Content Loss: 30.9016, Style Loss: 14.3440
Step [950/2000], Content Loss: 30.9369, Style Loss: 14.1998
Step [960/2000], Content Loss: 30.9720, Style Loss: 14.0581
Step [970/2000], Content Loss: 31.0021, Style Loss: 13.9193
Step [980/2000], Content Loss: 31.0370, Style Loss: 13.7825
Step [990/2000], Content Loss: 31.0691, Style Loss: 13.6480
Step [1000/2000], Content Loss: 31.0998, Style Loss: 13.5158
Step [1010/2000], Content Loss: 31.1302, Style Loss: 13.3861
Step [1020/2000], Content Loss: 31.1605, Style Loss: 13.2587
Step [1030/2000], Content Loss: 31.1915, Style Loss: 13.1332
Step [1040/2000], Content Loss: 31.2220, Style Loss: 13.0099
Step [1050/2000], Content Loss: 31.2528, Style Loss: 12.8889
Step [1060/2000], Content Loss: 31.2860, Style Loss: 12.7697
Step [1070/2000], Content Loss: 31.3174, Style Loss: 12.6525
Step [1080/2000], Content Loss: 31.3475, Style Loss: 12.5375
Step [1090/2000], Content Loss: 31.3775, Style Loss: 12.4245
Step [1100/2000], Content Loss: 31.4046, Style Loss: 12.3129
Step [1110/2000], Content Loss: 31.4350, Style Loss: 12.2038
Step [1120/2000], Content Loss: 31.4598, Style Loss: 12.0956
Step [1130/2000], Content Loss: 31.4878, Style Loss: 11.9894
Step [1140/2000], Content Loss: 31.5149, Style Loss: 11.8847
Step [1150/2000], Content Loss: 31.5406, Style Loss: 11.7818
Step [1160/2000], Content Loss: 31.5659, Style Loss: 11.6805
Step [1170/2000], Content Loss: 31.5901, Style Loss: 11.5803
Step [1180/2000], Content Loss: 31.6137, Style Loss: 11.4822
Step [1190/2000], Content Loss: 31.6345, Style Loss: 11.3851
Step [1200/2000], Content Loss: 31.6543, Style Loss: 11.2900
Step [1210/2000], Content Loss: 31.6787, Style Loss: 11.1968
Step [1220/2000], Content Loss: 31.7000, Style Loss: 11.1037
Step [1230/2000], Content Loss: 31.7205, Style Loss: 11.0116
Step [1240/2000], Content Loss: 31.7422, Style Loss: 10.9210
Step [1250/2000], Content Loss: 31.7633, Style Loss: 10.8319
Step [1260/2000], Content Loss: 31.7867, Style Loss: 10.7446
Step [1270/2000], Content Loss: 31.8046, Style Loss: 10.6565
Step [1280/2000], Content Loss: 31.8247, Style Loss: 10.5699
Step [1290/2000], Content Loss: 31.8469, Style Loss: 10.4858
Step [1300/2000], Content Loss: 31.8646, Style Loss: 10.4015
Step [1310/2000], Content Loss: 31.8859, Style Loss: 10.3201
Step [1320/2000], Content Loss: 31.9010, Style Loss: 10.2365
Step [1330/2000], Content Loss: 31.9236, Style Loss: 10.1575
Step [1340/2000], Content Loss: 31.9461, Style Loss: 10.0792
Step [1350/2000], Content Loss: 31.9616, Style Loss: 9.9980
Step [1360/2000], Content Loss: 31.9880, Style Loss: 9.9236
Step [1370/2000], Content Loss: 32.0038, Style Loss: 9.8461
Step [1380/2000], Content Loss: 32.0191, Style Loss: 9.7687
Step [1390/2000], Content Loss: 32.0434, Style Loss: 9.6970
Step [1400/2000], Content Loss: 32.0572, Style Loss: 9.6203
Step [1410/2000], Content Loss: 32.0787, Style Loss: 9.5496
Step [1420/2000], Content Loss: 32.0955, Style Loss: 9.4771
Step [1430/2000], Content Loss: 32.1123, Style Loss: 9.4056
Step [1440/2000], Content Loss: 32.1289, Style Loss: 9.3349
Step [1450/2000], Content Loss: 32.1441, Style Loss: 9.2636
Step [1460/2000], Content Loss: 32.1628, Style Loss: 9.1949
Step [1470/2000], Content Loss: 32.1851, Style Loss: 9.1302
Step [1480/2000], Content Loss: 32.1958, Style Loss: 9.0589
Step [1490/2000], Content Loss: 32.2141, Style Loss: 8.9938
Step [1500/2000], Content Loss: 32.2303, Style Loss: 8.9282
Step [1510/2000], Content Loss: 32.2414, Style Loss: 8.8597
Step [1520/2000], Content Loss: 32.2560, Style Loss: 8.7944
Step [1530/2000], Content Loss: 32.2785, Style Loss: 8.7337
Step [1540/2000], Content Loss: 32.2986, Style Loss: 8.6751
Step [1550/2000], Content Loss: 32.2955, Style Loss: 8.6001
Step [1560/2000], Content Loss: 32.3232, Style Loss: 8.5438
Step [1570/2000], Content Loss: 32.3409, Style Loss: 8.4860
Step [1580/2000], Content Loss: 32.3442, Style Loss: 8.4177
Step [1590/2000], Content Loss: 32.3604, Style Loss: 8.3581
Step [1600/2000], Content Loss: 32.3871, Style Loss: 8.3062
Step [1610/2000], Content Loss: 32.3841, Style Loss: 8.2353
Step [1620/2000], Content Loss: 32.4114, Style Loss: 8.1829
Step [1630/2000], Content Loss: 32.4267, Style Loss: 8.1247
Step [1640/2000], Content Loss: 32.4401, Style Loss: 8.0669
Step [1650/2000], Content Loss: 32.4480, Style Loss: 8.0066
Step [1660/2000], Content Loss: 32.4796, Style Loss: 7.9656
Step [1670/2000], Content Loss: 32.4754, Style Loss: 7.8967
Step [1680/2000], Content Loss: 32.4839, Style Loss: 7.8374
Step [1690/2000], Content Loss: 32.5063, Style Loss: 7.7878
Step [1700/2000], Content Loss: 32.5246, Style Loss: 7.7381
Step [1710/2000], Content Loss: 32.5257, Style Loss: 7.6759
Step [1720/2000], Content Loss: 32.5456, Style Loss: 7.6262
Step [1730/2000], Content Loss: 32.5680, Style Loss: 7.5811
Step [1740/2000], Content Loss: 32.5655, Style Loss: 7.5176
Step [1750/2000], Content Loss: 32.5831, Style Loss: 7.4672
Step [1760/2000], Content Loss: 32.6070, Style Loss: 7.4232
Step [1770/2000], Content Loss: 32.6441, Style Loss: 7.4071
Step [1780/2000], Content Loss: 32.6931, Style Loss: 7.4527
Step [1790/2000], Content Loss: 32.7056, Style Loss: 7.4441
Step [1800/2000], Content Loss: 32.6304, Style Loss: 7.2250
Step [1810/2000], Content Loss: 32.6647, Style Loss: 7.1710
Step [1820/2000], Content Loss: 32.6658, Style Loss: 7.1150
Step [1830/2000], Content Loss: 32.6795, Style Loss: 7.0659
Step [1840/2000], Content Loss: 32.6897, Style Loss: 7.0176
Step [1850/2000], Content Loss: 32.7024, Style Loss: 6.9711
Step [1860/2000], Content Loss: 32.7121, Style Loss: 6.9235
Step [1870/2000], Content Loss: 32.7327, Style Loss: 6.8816
Step [1880/2000], Content Loss: 32.7356, Style Loss: 6.8324
Step [1890/2000], Content Loss: 32.7485, Style Loss: 6.7878
Step [1900/2000], Content Loss: 32.7634, Style Loss: 6.7444
Step [1910/2000], Content Loss: 32.7753, Style Loss: 6.6990
Step [1920/2000], Content Loss: 32.7872, Style Loss: 6.6547
Step [1930/2000], Content Loss: 32.8038, Style Loss: 6.6145
Step [1940/2000], Content Loss: 32.8169, Style Loss: 6.5722
Step [1950/2000], Content Loss: 32.8173, Style Loss: 6.5240
Step [1960/2000], Content Loss: 32.8359, Style Loss: 6.4847
Step [1970/2000], Content Loss: 32.8538, Style Loss: 6.4470
Step [1980/2000], Content Loss: 32.8599, Style Loss: 6.4017
Step [1990/2000], Content Loss: 32.8634, Style Loss: 6.3566</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">denorm = transforms.Normalize((<span class="number">-2.12</span>, <span class="number">-2.04</span>, <span class="number">-1.80</span>), (<span class="number">4.37</span>, <span class="number">4.46</span>, <span class="number">4.44</span>))</span><br><span class="line">img = target.clone().squeeze()</span><br><span class="line">img = denorm(img).clamp_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">imshow(img, title=<span class="string">'Target Image'</span>)</span><br></pre></td></tr></table></figure>


<p><img src="output_11_0.png" alt="png"></p>
<h2 id="Generative-Adversarial-Networks"><a href="#Generative-Adversarial-Networks" class="headerlink" title="Generative Adversarial Networks"></a>Generative Adversarial Networks</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">batch_size=<span class="number">32</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>),</span><br><span class="line">                        std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">mnist_data = torchvision.datasets.MNIST(<span class="string">"./mnist_data"</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset=mnist_data,</span><br><span class="line">                                         batch_size=batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">image_size = <span class="number">784</span></span><br><span class="line"></span><br><span class="line">hidden_size = <span class="number">256</span></span><br><span class="line"><span class="comment"># discriminator</span></span><br><span class="line">D = nn.Sequential(</span><br><span class="line">    nn.Linear(image_size, hidden_size),</span><br><span class="line">    nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">    nn.Linear(hidden_size, hidden_size),</span><br><span class="line">    nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">    nn.Linear(hidden_size, <span class="number">1</span>),</span><br><span class="line">    nn.Sigmoid()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">latent_size = <span class="number">64</span></span><br><span class="line"><span class="comment"># Generator</span></span><br><span class="line">G = nn.Sequential(</span><br><span class="line">    nn.Linear(latent_size, hidden_size),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(hidden_size, hidden_size),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(hidden_size, image_size),</span><br><span class="line">    nn.Tanh()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">D = D.to(device)</span><br><span class="line">G = G.to(device)</span><br><span class="line"></span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line">d_optimizer = torch.optim.Adam(D.parameters(), lr=<span class="number">0.0002</span>)</span><br><span class="line">g_optimizer = torch.optim.Adam(G.parameters(), lr=<span class="number">0.0002</span>)</span><br></pre></td></tr></table></figure>

<p>开始训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset_grad</span><span class="params">()</span>:</span></span><br><span class="line">    d_optimizer.zero_grad()</span><br><span class="line">    g_optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">total_step = len(dataloader)</span><br><span class="line">num_epochs = <span class="number">200</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, _) <span class="keyword">in</span> enumerate(dataloader):</span><br><span class="line">        batch_size = images.size(<span class="number">0</span>)</span><br><span class="line">        images = images.reshape(batch_size, image_size).to(device)</span><br><span class="line">        </span><br><span class="line">        real_labels = torch.ones(batch_size, <span class="number">1</span>).to(device)</span><br><span class="line">        fake_labels = torch.zeros(batch_size, <span class="number">1</span>).to(device)</span><br><span class="line">        </span><br><span class="line">        outputs = D(images)</span><br><span class="line">        d_loss_real = loss_fn(outputs, real_labels)</span><br><span class="line">        real_score = outputs</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始生成fake images</span></span><br><span class="line">        z = torch.randn(batch_size, latent_size).to(device)</span><br><span class="line">        fake_images = G(z)</span><br><span class="line">        outputs = D(fake_images.detach())</span><br><span class="line">        d_loss_fake = loss_fn(outputs, fake_labels)</span><br><span class="line">        fake_score = outputs</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始优化discriminator</span></span><br><span class="line">        d_loss = d_loss_real + d_loss_fake</span><br><span class="line">        reset_grad()</span><br><span class="line">        d_loss.backward()</span><br><span class="line">        d_optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 开始优化generator</span></span><br><span class="line">        z = torch.randn(batch_size, latent_size).to(device)</span><br><span class="line">        fake_images = G(z)</span><br><span class="line">        outputs = D(fake_images)</span><br><span class="line">        g_loss = loss_fn(outputs, real_labels)</span><br><span class="line">        </span><br><span class="line">        reset_grad()</span><br><span class="line">        g_loss.backward()</span><br><span class="line">        g_optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], d_loss: &#123;:.4f&#125;, g_loss: &#123;:.4f&#125;, D(x): &#123;:.2f&#125;, D(G(z)): &#123;:.2f&#125;"</span></span><br><span class="line">                 .format(epoch, num_epochs, i, total_step, d_loss.item(), g_loss.item(), real_score.mean().item(), fake_score.mean().item()))</span><br></pre></td></tr></table></figure>

<pre><code>Epoch [0/200], Step [0/1875], d_loss: 0.6669, g_loss: 2.9577, D(x): 0.76, D(G(z)): 0.15
Epoch [0/200], Step [1000/1875], d_loss: 0.1716, g_loss: 3.0008, D(x): 0.93, D(G(z)): 0.09
Epoch [1/200], Step [0/1875], d_loss: 0.1716, g_loss: 4.1396, D(x): 0.93, D(G(z)): 0.02
Epoch [1/200], Step [1000/1875], d_loss: 0.0202, g_loss: 5.1296, D(x): 1.00, D(G(z)): 0.02
Epoch [2/200], Step [0/1875], d_loss: 0.2070, g_loss: 3.7713, D(x): 0.93, D(G(z)): 0.08
Epoch [2/200], Step [1000/1875], d_loss: 0.0829, g_loss: 4.9163, D(x): 0.99, D(G(z)): 0.07
Epoch [3/200], Step [0/1875], d_loss: 0.2986, g_loss: 3.6197, D(x): 0.90, D(G(z)): 0.03
Epoch [3/200], Step [1000/1875], d_loss: 0.4204, g_loss: 2.2956, D(x): 0.90, D(G(z)): 0.14
Epoch [4/200], Step [0/1875], d_loss: 0.4453, g_loss: 5.1677, D(x): 0.80, D(G(z)): 0.02
Epoch [4/200], Step [1000/1875], d_loss: 0.1900, g_loss: 2.7722, D(x): 0.93, D(G(z)): 0.10
Epoch [5/200], Step [0/1875], d_loss: 0.3418, g_loss: 2.4469, D(x): 1.00, D(G(z)): 0.21
Epoch [5/200], Step [1000/1875], d_loss: 0.4460, g_loss: 2.4152, D(x): 0.90, D(G(z)): 0.18
Epoch [6/200], Step [0/1875], d_loss: 0.3142, g_loss: 4.0145, D(x): 0.93, D(G(z)): 0.13
Epoch [6/200], Step [1000/1875], d_loss: 0.5893, g_loss: 3.9873, D(x): 0.97, D(G(z)): 0.31
Epoch [7/200], Step [0/1875], d_loss: 0.3118, g_loss: 3.2590, D(x): 0.88, D(G(z)): 0.10
Epoch [7/200], Step [1000/1875], d_loss: 0.5169, g_loss: 2.8562, D(x): 0.84, D(G(z)): 0.20
Epoch [8/200], Step [0/1875], d_loss: 0.1886, g_loss: 3.0765, D(x): 0.93, D(G(z)): 0.05
Epoch [8/200], Step [1000/1875], d_loss: 0.5987, g_loss: 3.0972, D(x): 0.86, D(G(z)): 0.17
Epoch [9/200], Step [0/1875], d_loss: 0.7312, g_loss: 2.5704, D(x): 0.93, D(G(z)): 0.30
Epoch [9/200], Step [1000/1875], d_loss: 0.2202, g_loss: 3.1345, D(x): 0.94, D(G(z)): 0.11
Epoch [10/200], Step [0/1875], d_loss: 0.5448, g_loss: 3.2835, D(x): 0.81, D(G(z)): 0.11
Epoch [10/200], Step [1000/1875], d_loss: 0.4599, g_loss: 2.8296, D(x): 0.81, D(G(z)): 0.09
Epoch [11/200], Step [0/1875], d_loss: 0.3990, g_loss: 3.9110, D(x): 0.86, D(G(z)): 0.11
Epoch [11/200], Step [1000/1875], d_loss: 0.4137, g_loss: 3.2849, D(x): 0.88, D(G(z)): 0.17
Epoch [12/200], Step [0/1875], d_loss: 0.6989, g_loss: 2.1561, D(x): 0.80, D(G(z)): 0.24
Epoch [12/200], Step [1000/1875], d_loss: 0.7982, g_loss: 2.6202, D(x): 0.75, D(G(z)): 0.27
Epoch [13/200], Step [0/1875], d_loss: 0.7775, g_loss: 2.6229, D(x): 0.70, D(G(z)): 0.09
Epoch [13/200], Step [1000/1875], d_loss: 0.7904, g_loss: 2.3377, D(x): 0.69, D(G(z)): 0.06
Epoch [14/200], Step [0/1875], d_loss: 0.5520, g_loss: 3.6026, D(x): 0.87, D(G(z)): 0.23
Epoch [14/200], Step [1000/1875], d_loss: 0.4877, g_loss: 1.8566, D(x): 0.81, D(G(z)): 0.11
Epoch [15/200], Step [0/1875], d_loss: 0.6178, g_loss: 2.8264, D(x): 0.73, D(G(z)): 0.08
Epoch [15/200], Step [1000/1875], d_loss: 0.5656, g_loss: 2.0427, D(x): 0.85, D(G(z)): 0.23
Epoch [16/200], Step [0/1875], d_loss: 0.7704, g_loss: 1.8280, D(x): 0.82, D(G(z)): 0.28
Epoch [16/200], Step [1000/1875], d_loss: 0.4717, g_loss: 2.3330, D(x): 0.87, D(G(z)): 0.23
Epoch [17/200], Step [0/1875], d_loss: 0.6158, g_loss: 2.3867, D(x): 0.80, D(G(z)): 0.21
Epoch [17/200], Step [1000/1875], d_loss: 0.5036, g_loss: 2.1572, D(x): 0.86, D(G(z)): 0.22
Epoch [18/200], Step [0/1875], d_loss: 0.2080, g_loss: 3.1542, D(x): 0.97, D(G(z)): 0.13
Epoch [18/200], Step [1000/1875], d_loss: 0.4262, g_loss: 3.2852, D(x): 0.85, D(G(z)): 0.12
Epoch [19/200], Step [0/1875], d_loss: 1.1834, g_loss: 1.7200, D(x): 0.82, D(G(z)): 0.44
Epoch [19/200], Step [1000/1875], d_loss: 0.7412, g_loss: 3.3823, D(x): 0.70, D(G(z)): 0.14
Epoch [20/200], Step [0/1875], d_loss: 0.8160, g_loss: 2.5552, D(x): 0.78, D(G(z)): 0.28
Epoch [20/200], Step [1000/1875], d_loss: 0.8000, g_loss: 1.9645, D(x): 0.82, D(G(z)): 0.31
Epoch [21/200], Step [0/1875], d_loss: 0.8578, g_loss: 2.7063, D(x): 0.70, D(G(z)): 0.24
Epoch [21/200], Step [1000/1875], d_loss: 0.4567, g_loss: 1.8023, D(x): 0.83, D(G(z)): 0.18
Epoch [22/200], Step [0/1875], d_loss: 0.6396, g_loss: 1.9526, D(x): 0.76, D(G(z)): 0.20
Epoch [22/200], Step [1000/1875], d_loss: 0.4177, g_loss: 2.4358, D(x): 0.89, D(G(z)): 0.18
Epoch [23/200], Step [0/1875], d_loss: 0.7560, g_loss: 2.3783, D(x): 0.83, D(G(z)): 0.36
Epoch [23/200], Step [1000/1875], d_loss: 0.8418, g_loss: 1.2812, D(x): 0.72, D(G(z)): 0.22
Epoch [24/200], Step [0/1875], d_loss: 0.8319, g_loss: 2.1962, D(x): 0.66, D(G(z)): 0.20
Epoch [24/200], Step [1000/1875], d_loss: 0.8614, g_loss: 2.3836, D(x): 0.67, D(G(z)): 0.20
Epoch [25/200], Step [0/1875], d_loss: 0.8590, g_loss: 1.5315, D(x): 0.78, D(G(z)): 0.36
Epoch [25/200], Step [1000/1875], d_loss: 0.9564, g_loss: 1.7998, D(x): 0.77, D(G(z)): 0.38
Epoch [26/200], Step [0/1875], d_loss: 0.8937, g_loss: 1.3713, D(x): 0.74, D(G(z)): 0.31
Epoch [26/200], Step [1000/1875], d_loss: 0.9061, g_loss: 2.4561, D(x): 0.74, D(G(z)): 0.27
Epoch [27/200], Step [0/1875], d_loss: 0.6779, g_loss: 2.1518, D(x): 0.76, D(G(z)): 0.23
Epoch [27/200], Step [1000/1875], d_loss: 1.0955, g_loss: 1.9235, D(x): 0.70, D(G(z)): 0.31
Epoch [28/200], Step [0/1875], d_loss: 0.7943, g_loss: 1.5614, D(x): 0.73, D(G(z)): 0.24
Epoch [28/200], Step [1000/1875], d_loss: 0.8096, g_loss: 1.8443, D(x): 0.86, D(G(z)): 0.40
Epoch [29/200], Step [0/1875], d_loss: 0.6123, g_loss: 1.8900, D(x): 0.80, D(G(z)): 0.23
Epoch [29/200], Step [1000/1875], d_loss: 0.9214, g_loss: 1.5088, D(x): 0.79, D(G(z)): 0.38
Epoch [30/200], Step [0/1875], d_loss: 1.1502, g_loss: 1.2392, D(x): 0.63, D(G(z)): 0.31
Epoch [30/200], Step [1000/1875], d_loss: 0.7820, g_loss: 1.2615, D(x): 0.81, D(G(z)): 0.35
Epoch [31/200], Step [0/1875], d_loss: 0.9985, g_loss: 1.9074, D(x): 0.63, D(G(z)): 0.23
Epoch [31/200], Step [1000/1875], d_loss: 0.7422, g_loss: 1.5258, D(x): 0.72, D(G(z)): 0.26
Epoch [32/200], Step [0/1875], d_loss: 0.9283, g_loss: 2.1753, D(x): 0.60, D(G(z)): 0.20
Epoch [32/200], Step [1000/1875], d_loss: 0.6156, g_loss: 1.8300, D(x): 0.88, D(G(z)): 0.34
Epoch [33/200], Step [0/1875], d_loss: 0.7572, g_loss: 2.5281, D(x): 0.69, D(G(z)): 0.20
Epoch [33/200], Step [1000/1875], d_loss: 1.2556, g_loss: 1.6872, D(x): 0.58, D(G(z)): 0.31
Epoch [34/200], Step [0/1875], d_loss: 0.9278, g_loss: 1.6144, D(x): 0.77, D(G(z)): 0.37
Epoch [34/200], Step [1000/1875], d_loss: 1.0190, g_loss: 1.9249, D(x): 0.65, D(G(z)): 0.31
Epoch [35/200], Step [0/1875], d_loss: 1.1411, g_loss: 1.3005, D(x): 0.79, D(G(z)): 0.47
Epoch [35/200], Step [1000/1875], d_loss: 0.9863, g_loss: 0.9696, D(x): 0.81, D(G(z)): 0.45
Epoch [36/200], Step [0/1875], d_loss: 0.6408, g_loss: 1.7086, D(x): 0.77, D(G(z)): 0.24
Epoch [36/200], Step [1000/1875], d_loss: 0.8755, g_loss: 1.4808, D(x): 0.71, D(G(z)): 0.31
Epoch [37/200], Step [0/1875], d_loss: 0.8984, g_loss: 1.3038, D(x): 0.77, D(G(z)): 0.37
Epoch [37/200], Step [1000/1875], d_loss: 0.8318, g_loss: 1.4391, D(x): 0.73, D(G(z)): 0.29
Epoch [38/200], Step [0/1875], d_loss: 0.6922, g_loss: 1.8307, D(x): 0.77, D(G(z)): 0.27
Epoch [38/200], Step [1000/1875], d_loss: 1.1070, g_loss: 1.1424, D(x): 0.71, D(G(z)): 0.45
Epoch [39/200], Step [0/1875], d_loss: 0.8160, g_loss: 1.7084, D(x): 0.79, D(G(z)): 0.31
Epoch [39/200], Step [1000/1875], d_loss: 0.7833, g_loss: 1.5914, D(x): 0.69, D(G(z)): 0.16
Epoch [40/200], Step [0/1875], d_loss: 1.1307, g_loss: 1.1723, D(x): 0.72, D(G(z)): 0.42
Epoch [40/200], Step [1000/1875], d_loss: 0.9260, g_loss: 1.5115, D(x): 0.58, D(G(z)): 0.19
Epoch [41/200], Step [0/1875], d_loss: 0.8279, g_loss: 2.0445, D(x): 0.71, D(G(z)): 0.26
Epoch [41/200], Step [1000/1875], d_loss: 1.0122, g_loss: 1.4877, D(x): 0.68, D(G(z)): 0.34
Epoch [42/200], Step [0/1875], d_loss: 1.0094, g_loss: 1.5560, D(x): 0.67, D(G(z)): 0.30
Epoch [42/200], Step [1000/1875], d_loss: 1.1574, g_loss: 1.0871, D(x): 0.80, D(G(z)): 0.48
Epoch [43/200], Step [0/1875], d_loss: 0.7671, g_loss: 1.4075, D(x): 0.72, D(G(z)): 0.23
Epoch [43/200], Step [1000/1875], d_loss: 0.8994, g_loss: 1.4649, D(x): 0.69, D(G(z)): 0.28
Epoch [44/200], Step [0/1875], d_loss: 0.8590, g_loss: 1.2829, D(x): 0.75, D(G(z)): 0.35
Epoch [44/200], Step [1000/1875], d_loss: 0.8026, g_loss: 2.1658, D(x): 0.64, D(G(z)): 0.18
Epoch [45/200], Step [0/1875], d_loss: 1.1981, g_loss: 1.5492, D(x): 0.65, D(G(z)): 0.37
Epoch [45/200], Step [1000/1875], d_loss: 1.0184, g_loss: 1.2799, D(x): 0.68, D(G(z)): 0.37
Epoch [46/200], Step [0/1875], d_loss: 0.7981, g_loss: 2.0579, D(x): 0.71, D(G(z)): 0.26
Epoch [46/200], Step [1000/1875], d_loss: 1.1051, g_loss: 1.2950, D(x): 0.63, D(G(z)): 0.28
Epoch [47/200], Step [0/1875], d_loss: 0.9363, g_loss: 1.2712, D(x): 0.64, D(G(z)): 0.26
Epoch [47/200], Step [1000/1875], d_loss: 0.7284, g_loss: 1.2780, D(x): 0.82, D(G(z)): 0.36
Epoch [48/200], Step [0/1875], d_loss: 0.9353, g_loss: 1.6880, D(x): 0.76, D(G(z)): 0.41
Epoch [48/200], Step [1000/1875], d_loss: 0.9996, g_loss: 1.7311, D(x): 0.70, D(G(z)): 0.32
Epoch [49/200], Step [0/1875], d_loss: 0.9926, g_loss: 1.4112, D(x): 0.78, D(G(z)): 0.42
Epoch [49/200], Step [1000/1875], d_loss: 0.8023, g_loss: 1.6557, D(x): 0.65, D(G(z)): 0.21
Epoch [50/200], Step [0/1875], d_loss: 0.8718, g_loss: 1.9058, D(x): 0.63, D(G(z)): 0.20
Epoch [50/200], Step [1000/1875], d_loss: 0.9961, g_loss: 1.5768, D(x): 0.62, D(G(z)): 0.28
Epoch [51/200], Step [0/1875], d_loss: 0.9317, g_loss: 1.3332, D(x): 0.70, D(G(z)): 0.33
Epoch [51/200], Step [1000/1875], d_loss: 0.9427, g_loss: 1.1736, D(x): 0.68, D(G(z)): 0.32
Epoch [52/200], Step [0/1875], d_loss: 0.7741, g_loss: 1.6549, D(x): 0.74, D(G(z)): 0.29
Epoch [52/200], Step [1000/1875], d_loss: 1.2812, g_loss: 1.1068, D(x): 0.71, D(G(z)): 0.49
Epoch [53/200], Step [0/1875], d_loss: 0.8245, g_loss: 1.5040, D(x): 0.73, D(G(z)): 0.28
Epoch [53/200], Step [1000/1875], d_loss: 1.0251, g_loss: 1.2684, D(x): 0.80, D(G(z)): 0.44
Epoch [54/200], Step [0/1875], d_loss: 1.1557, g_loss: 1.8746, D(x): 0.67, D(G(z)): 0.35
Epoch [54/200], Step [1000/1875], d_loss: 1.1738, g_loss: 1.6428, D(x): 0.57, D(G(z)): 0.33
Epoch [55/200], Step [0/1875], d_loss: 1.0400, g_loss: 1.3476, D(x): 0.55, D(G(z)): 0.21
Epoch [55/200], Step [1000/1875], d_loss: 1.0220, g_loss: 1.4821, D(x): 0.59, D(G(z)): 0.24
Epoch [56/200], Step [0/1875], d_loss: 0.7882, g_loss: 1.4944, D(x): 0.66, D(G(z)): 0.20
Epoch [56/200], Step [1000/1875], d_loss: 0.8876, g_loss: 1.5311, D(x): 0.73, D(G(z)): 0.34
Epoch [57/200], Step [0/1875], d_loss: 1.0530, g_loss: 1.7741, D(x): 0.69, D(G(z)): 0.36
Epoch [57/200], Step [1000/1875], d_loss: 1.1232, g_loss: 1.5487, D(x): 0.62, D(G(z)): 0.33
Epoch [58/200], Step [0/1875], d_loss: 1.0350, g_loss: 1.3535, D(x): 0.73, D(G(z)): 0.43
Epoch [58/200], Step [1000/1875], d_loss: 0.7528, g_loss: 1.4546, D(x): 0.74, D(G(z)): 0.28
Epoch [59/200], Step [0/1875], d_loss: 0.9243, g_loss: 1.3529, D(x): 0.71, D(G(z)): 0.31
Epoch [59/200], Step [1000/1875], d_loss: 1.0429, g_loss: 1.6492, D(x): 0.64, D(G(z)): 0.36
Epoch [60/200], Step [0/1875], d_loss: 0.9420, g_loss: 1.4876, D(x): 0.68, D(G(z)): 0.31
Epoch [60/200], Step [1000/1875], d_loss: 1.0196, g_loss: 1.6513, D(x): 0.67, D(G(z)): 0.34
Epoch [61/200], Step [0/1875], d_loss: 1.0662, g_loss: 1.4362, D(x): 0.64, D(G(z)): 0.29
Epoch [61/200], Step [1000/1875], d_loss: 1.1993, g_loss: 1.2304, D(x): 0.55, D(G(z)): 0.34
Epoch [62/200], Step [0/1875], d_loss: 1.1418, g_loss: 1.6582, D(x): 0.57, D(G(z)): 0.27
Epoch [62/200], Step [1000/1875], d_loss: 1.1739, g_loss: 1.0282, D(x): 0.72, D(G(z)): 0.50
Epoch [63/200], Step [0/1875], d_loss: 0.9645, g_loss: 1.2030, D(x): 0.67, D(G(z)): 0.32
Epoch [63/200], Step [1000/1875], d_loss: 1.0324, g_loss: 1.8831, D(x): 0.63, D(G(z)): 0.30
Epoch [64/200], Step [0/1875], d_loss: 1.2073, g_loss: 1.2013, D(x): 0.60, D(G(z)): 0.37
Epoch [64/200], Step [1000/1875], d_loss: 1.3382, g_loss: 1.4971, D(x): 0.69, D(G(z)): 0.47
Epoch [65/200], Step [0/1875], d_loss: 0.7616, g_loss: 1.4244, D(x): 0.79, D(G(z)): 0.33
Epoch [65/200], Step [1000/1875], d_loss: 0.9834, g_loss: 1.9160, D(x): 0.60, D(G(z)): 0.24
Epoch [66/200], Step [0/1875], d_loss: 0.9860, g_loss: 1.2135, D(x): 0.71, D(G(z)): 0.36
Epoch [66/200], Step [1000/1875], d_loss: 1.1599, g_loss: 1.9320, D(x): 0.56, D(G(z)): 0.24
Epoch [67/200], Step [0/1875], d_loss: 0.9280, g_loss: 1.6222, D(x): 0.62, D(G(z)): 0.25
Epoch [67/200], Step [1000/1875], d_loss: 0.8609, g_loss: 1.2151, D(x): 0.72, D(G(z)): 0.34
Epoch [68/200], Step [0/1875], d_loss: 1.1169, g_loss: 1.2863, D(x): 0.64, D(G(z)): 0.35
Epoch [68/200], Step [1000/1875], d_loss: 1.3884, g_loss: 1.1648, D(x): 0.80, D(G(z)): 0.59
Epoch [69/200], Step [0/1875], d_loss: 0.7709, g_loss: 1.5080, D(x): 0.72, D(G(z)): 0.29
Epoch [69/200], Step [1000/1875], d_loss: 0.9492, g_loss: 1.4181, D(x): 0.67, D(G(z)): 0.29
Epoch [70/200], Step [0/1875], d_loss: 0.8738, g_loss: 1.2650, D(x): 0.74, D(G(z)): 0.36
Epoch [70/200], Step [1000/1875], d_loss: 1.0756, g_loss: 1.4710, D(x): 0.74, D(G(z)): 0.41
Epoch [71/200], Step [0/1875], d_loss: 0.8898, g_loss: 1.4363, D(x): 0.69, D(G(z)): 0.30
Epoch [71/200], Step [1000/1875], d_loss: 0.9169, g_loss: 1.2323, D(x): 0.63, D(G(z)): 0.25
Epoch [72/200], Step [0/1875], d_loss: 0.9560, g_loss: 1.2931, D(x): 0.63, D(G(z)): 0.29
Epoch [72/200], Step [1000/1875], d_loss: 0.9121, g_loss: 1.6194, D(x): 0.69, D(G(z)): 0.30
Epoch [73/200], Step [0/1875], d_loss: 0.9210, g_loss: 1.6881, D(x): 0.64, D(G(z)): 0.29
Epoch [73/200], Step [1000/1875], d_loss: 0.9212, g_loss: 1.6392, D(x): 0.72, D(G(z)): 0.36
Epoch [74/200], Step [0/1875], d_loss: 1.2269, g_loss: 1.4554, D(x): 0.57, D(G(z)): 0.35
Epoch [74/200], Step [1000/1875], d_loss: 1.0380, g_loss: 1.3137, D(x): 0.81, D(G(z)): 0.46
Epoch [75/200], Step [0/1875], d_loss: 1.0824, g_loss: 2.1083, D(x): 0.60, D(G(z)): 0.28
Epoch [75/200], Step [1000/1875], d_loss: 1.0364, g_loss: 1.2388, D(x): 0.61, D(G(z)): 0.32
Epoch [76/200], Step [0/1875], d_loss: 1.0572, g_loss: 1.7266, D(x): 0.58, D(G(z)): 0.24
Epoch [76/200], Step [1000/1875], d_loss: 1.1760, g_loss: 1.3603, D(x): 0.66, D(G(z)): 0.39
Epoch [77/200], Step [0/1875], d_loss: 0.7916, g_loss: 1.2981, D(x): 0.71, D(G(z)): 0.27
Epoch [77/200], Step [1000/1875], d_loss: 0.9169, g_loss: 1.3591, D(x): 0.68, D(G(z)): 0.32
Epoch [78/200], Step [0/1875], d_loss: 0.9650, g_loss: 1.2724, D(x): 0.70, D(G(z)): 0.39
Epoch [78/200], Step [1000/1875], d_loss: 1.0706, g_loss: 1.5743, D(x): 0.72, D(G(z)): 0.41
Epoch [79/200], Step [0/1875], d_loss: 1.0080, g_loss: 1.4655, D(x): 0.61, D(G(z)): 0.30
Epoch [79/200], Step [1000/1875], d_loss: 0.9786, g_loss: 1.2689, D(x): 0.67, D(G(z)): 0.36
Epoch [80/200], Step [0/1875], d_loss: 0.9673, g_loss: 1.3955, D(x): 0.80, D(G(z)): 0.44
Epoch [80/200], Step [1000/1875], d_loss: 1.0951, g_loss: 1.3826, D(x): 0.71, D(G(z)): 0.43
Epoch [81/200], Step [0/1875], d_loss: 0.9750, g_loss: 1.7231, D(x): 0.55, D(G(z)): 0.21
Epoch [81/200], Step [1000/1875], d_loss: 0.8631, g_loss: 1.3905, D(x): 0.69, D(G(z)): 0.31
Epoch [82/200], Step [0/1875], d_loss: 1.2233, g_loss: 1.3238, D(x): 0.61, D(G(z)): 0.39
Epoch [82/200], Step [1000/1875], d_loss: 1.1894, g_loss: 1.3720, D(x): 0.70, D(G(z)): 0.40
Epoch [83/200], Step [0/1875], d_loss: 1.0209, g_loss: 1.5222, D(x): 0.63, D(G(z)): 0.26
Epoch [83/200], Step [1000/1875], d_loss: 0.7264, g_loss: 1.6697, D(x): 0.73, D(G(z)): 0.28
Epoch [84/200], Step [0/1875], d_loss: 0.8771, g_loss: 1.2173, D(x): 0.76, D(G(z)): 0.36
Epoch [84/200], Step [1000/1875], d_loss: 0.9297, g_loss: 1.4891, D(x): 0.72, D(G(z)): 0.34
Epoch [85/200], Step [0/1875], d_loss: 0.9688, g_loss: 1.7294, D(x): 0.63, D(G(z)): 0.29
Epoch [85/200], Step [1000/1875], d_loss: 0.8822, g_loss: 1.5354, D(x): 0.70, D(G(z)): 0.30
Epoch [86/200], Step [0/1875], d_loss: 1.1903, g_loss: 1.2292, D(x): 0.71, D(G(z)): 0.45
Epoch [86/200], Step [1000/1875], d_loss: 1.0713, g_loss: 1.3514, D(x): 0.67, D(G(z)): 0.39
Epoch [87/200], Step [0/1875], d_loss: 0.9523, g_loss: 1.4799, D(x): 0.63, D(G(z)): 0.26
Epoch [87/200], Step [1000/1875], d_loss: 1.1543, g_loss: 1.3191, D(x): 0.63, D(G(z)): 0.35
Epoch [88/200], Step [0/1875], d_loss: 1.0270, g_loss: 1.3444, D(x): 0.63, D(G(z)): 0.33
Epoch [88/200], Step [1000/1875], d_loss: 0.9212, g_loss: 1.6030, D(x): 0.60, D(G(z)): 0.23
Epoch [89/200], Step [0/1875], d_loss: 1.1040, g_loss: 1.2642, D(x): 0.64, D(G(z)): 0.34
Epoch [89/200], Step [1000/1875], d_loss: 0.8394, g_loss: 1.4969, D(x): 0.75, D(G(z)): 0.34
Epoch [90/200], Step [0/1875], d_loss: 0.9523, g_loss: 0.9641, D(x): 0.79, D(G(z)): 0.40
Epoch [90/200], Step [1000/1875], d_loss: 0.7576, g_loss: 1.0150, D(x): 0.78, D(G(z)): 0.33
Epoch [91/200], Step [0/1875], d_loss: 1.2105, g_loss: 0.9780, D(x): 0.66, D(G(z)): 0.41
Epoch [91/200], Step [1000/1875], d_loss: 1.0656, g_loss: 1.5340, D(x): 0.60, D(G(z)): 0.32
Epoch [92/200], Step [0/1875], d_loss: 0.9305, g_loss: 1.5715, D(x): 0.64, D(G(z)): 0.28
Epoch [92/200], Step [1000/1875], d_loss: 0.8817, g_loss: 1.5210, D(x): 0.71, D(G(z)): 0.31
Epoch [93/200], Step [0/1875], d_loss: 0.8735, g_loss: 1.8431, D(x): 0.62, D(G(z)): 0.23
Epoch [93/200], Step [1000/1875], d_loss: 1.2207, g_loss: 1.4299, D(x): 0.61, D(G(z)): 0.36
Epoch [94/200], Step [0/1875], d_loss: 1.1631, g_loss: 1.6790, D(x): 0.53, D(G(z)): 0.25
Epoch [94/200], Step [1000/1875], d_loss: 1.0503, g_loss: 1.3590, D(x): 0.67, D(G(z)): 0.37
Epoch [95/200], Step [0/1875], d_loss: 0.9073, g_loss: 1.3901, D(x): 0.65, D(G(z)): 0.29
Epoch [95/200], Step [1000/1875], d_loss: 0.9264, g_loss: 1.4881, D(x): 0.70, D(G(z)): 0.36
Epoch [96/200], Step [0/1875], d_loss: 0.8375, g_loss: 1.6237, D(x): 0.68, D(G(z)): 0.28
Epoch [96/200], Step [1000/1875], d_loss: 0.8759, g_loss: 1.6055, D(x): 0.70, D(G(z)): 0.32
Epoch [97/200], Step [0/1875], d_loss: 0.9862, g_loss: 1.2774, D(x): 0.73, D(G(z)): 0.42
Epoch [97/200], Step [1000/1875], d_loss: 0.8995, g_loss: 1.3931, D(x): 0.64, D(G(z)): 0.29
Epoch [98/200], Step [0/1875], d_loss: 1.1893, g_loss: 1.0463, D(x): 0.76, D(G(z)): 0.46
Epoch [98/200], Step [1000/1875], d_loss: 1.0180, g_loss: 1.0250, D(x): 0.58, D(G(z)): 0.26
Epoch [99/200], Step [0/1875], d_loss: 0.7713, g_loss: 1.3374, D(x): 0.70, D(G(z)): 0.26
Epoch [99/200], Step [1000/1875], d_loss: 0.9064, g_loss: 1.0758, D(x): 0.74, D(G(z)): 0.37
Epoch [100/200], Step [0/1875], d_loss: 1.0002, g_loss: 1.2143, D(x): 0.64, D(G(z)): 0.30
Epoch [100/200], Step [1000/1875], d_loss: 1.0911, g_loss: 1.3313, D(x): 0.70, D(G(z)): 0.41
Epoch [101/200], Step [0/1875], d_loss: 0.8495, g_loss: 1.9575, D(x): 0.62, D(G(z)): 0.19
Epoch [101/200], Step [1000/1875], d_loss: 0.8246, g_loss: 1.1735, D(x): 0.72, D(G(z)): 0.33
Epoch [102/200], Step [0/1875], d_loss: 0.8016, g_loss: 1.5931, D(x): 0.68, D(G(z)): 0.23
Epoch [102/200], Step [1000/1875], d_loss: 0.7966, g_loss: 1.5136, D(x): 0.65, D(G(z)): 0.22
Epoch [103/200], Step [0/1875], d_loss: 0.8603, g_loss: 1.2868, D(x): 0.80, D(G(z)): 0.39
Epoch [103/200], Step [1000/1875], d_loss: 0.9518, g_loss: 1.7202, D(x): 0.74, D(G(z)): 0.37
Epoch [104/200], Step [0/1875], d_loss: 0.7930, g_loss: 1.7609, D(x): 0.73, D(G(z)): 0.30
Epoch [104/200], Step [1000/1875], d_loss: 1.2606, g_loss: 1.1577, D(x): 0.66, D(G(z)): 0.44
Epoch [105/200], Step [0/1875], d_loss: 1.0098, g_loss: 1.5430, D(x): 0.65, D(G(z)): 0.34
Epoch [105/200], Step [1000/1875], d_loss: 0.9373, g_loss: 0.9949, D(x): 0.76, D(G(z)): 0.39
Epoch [106/200], Step [0/1875], d_loss: 0.9693, g_loss: 1.5791, D(x): 0.68, D(G(z)): 0.34
Epoch [106/200], Step [1000/1875], d_loss: 0.9154, g_loss: 1.4726, D(x): 0.73, D(G(z)): 0.31
Epoch [107/200], Step [0/1875], d_loss: 0.9514, g_loss: 1.7878, D(x): 0.60, D(G(z)): 0.22
Epoch [107/200], Step [1000/1875], d_loss: 1.0044, g_loss: 1.4046, D(x): 0.63, D(G(z)): 0.30
Epoch [108/200], Step [0/1875], d_loss: 0.8615, g_loss: 1.6039, D(x): 0.63, D(G(z)): 0.23
Epoch [108/200], Step [1000/1875], d_loss: 0.8843, g_loss: 1.9490, D(x): 0.62, D(G(z)): 0.25
Epoch [109/200], Step [0/1875], d_loss: 1.0323, g_loss: 1.4124, D(x): 0.63, D(G(z)): 0.32
Epoch [109/200], Step [1000/1875], d_loss: 0.8610, g_loss: 1.2935, D(x): 0.75, D(G(z)): 0.34
Epoch [110/200], Step [0/1875], d_loss: 1.1965, g_loss: 1.6509, D(x): 0.54, D(G(z)): 0.31
Epoch [110/200], Step [1000/1875], d_loss: 0.9098, g_loss: 1.0422, D(x): 0.69, D(G(z)): 0.27
Epoch [111/200], Step [0/1875], d_loss: 1.1742, g_loss: 1.7862, D(x): 0.60, D(G(z)): 0.34
Epoch [111/200], Step [1000/1875], d_loss: 1.0664, g_loss: 1.7042, D(x): 0.57, D(G(z)): 0.27
Epoch [112/200], Step [0/1875], d_loss: 0.9700, g_loss: 1.7371, D(x): 0.68, D(G(z)): 0.30
Epoch [112/200], Step [1000/1875], d_loss: 1.0423, g_loss: 1.7016, D(x): 0.60, D(G(z)): 0.26
Epoch [113/200], Step [0/1875], d_loss: 1.1020, g_loss: 1.0794, D(x): 0.70, D(G(z)): 0.44
Epoch [113/200], Step [1000/1875], d_loss: 1.1647, g_loss: 2.0496, D(x): 0.54, D(G(z)): 0.26
Epoch [114/200], Step [0/1875], d_loss: 1.1799, g_loss: 1.5188, D(x): 0.64, D(G(z)): 0.39
Epoch [114/200], Step [1000/1875], d_loss: 1.0539, g_loss: 1.3321, D(x): 0.72, D(G(z)): 0.40
Epoch [115/200], Step [0/1875], d_loss: 0.9181, g_loss: 1.3867, D(x): 0.71, D(G(z)): 0.35
Epoch [115/200], Step [1000/1875], d_loss: 1.0679, g_loss: 1.9318, D(x): 0.59, D(G(z)): 0.26
Epoch [116/200], Step [0/1875], d_loss: 1.0790, g_loss: 1.1137, D(x): 0.64, D(G(z)): 0.36
Epoch [116/200], Step [1000/1875], d_loss: 1.2793, g_loss: 1.0888, D(x): 0.73, D(G(z)): 0.48
Epoch [117/200], Step [0/1875], d_loss: 0.9659, g_loss: 1.6854, D(x): 0.63, D(G(z)): 0.26
Epoch [117/200], Step [1000/1875], d_loss: 1.0517, g_loss: 1.1859, D(x): 0.68, D(G(z)): 0.38
Epoch [118/200], Step [0/1875], d_loss: 1.0606, g_loss: 1.4192, D(x): 0.67, D(G(z)): 0.29
Epoch [118/200], Step [1000/1875], d_loss: 1.0837, g_loss: 1.5058, D(x): 0.61, D(G(z)): 0.32
Epoch [119/200], Step [0/1875], d_loss: 0.9450, g_loss: 1.2550, D(x): 0.71, D(G(z)): 0.35
Epoch [119/200], Step [1000/1875], d_loss: 1.1078, g_loss: 1.7936, D(x): 0.55, D(G(z)): 0.25
Epoch [120/200], Step [0/1875], d_loss: 0.9814, g_loss: 1.1776, D(x): 0.69, D(G(z)): 0.35
Epoch [120/200], Step [1000/1875], d_loss: 1.0611, g_loss: 1.3892, D(x): 0.59, D(G(z)): 0.31
Epoch [121/200], Step [0/1875], d_loss: 0.9461, g_loss: 1.2199, D(x): 0.70, D(G(z)): 0.36
Epoch [121/200], Step [1000/1875], d_loss: 0.9500, g_loss: 1.2922, D(x): 0.62, D(G(z)): 0.28
Epoch [122/200], Step [0/1875], d_loss: 0.8209, g_loss: 1.4023, D(x): 0.76, D(G(z)): 0.32
Epoch [122/200], Step [1000/1875], d_loss: 1.0864, g_loss: 1.0152, D(x): 0.59, D(G(z)): 0.32
Epoch [123/200], Step [0/1875], d_loss: 1.1689, g_loss: 1.4938, D(x): 0.59, D(G(z)): 0.27
Epoch [123/200], Step [1000/1875], d_loss: 1.0686, g_loss: 1.1028, D(x): 0.64, D(G(z)): 0.33
Epoch [124/200], Step [0/1875], d_loss: 0.9185, g_loss: 1.1483, D(x): 0.72, D(G(z)): 0.33
Epoch [124/200], Step [1000/1875], d_loss: 1.0521, g_loss: 1.0809, D(x): 0.64, D(G(z)): 0.30
Epoch [125/200], Step [0/1875], d_loss: 1.0460, g_loss: 1.7116, D(x): 0.63, D(G(z)): 0.32
Epoch [125/200], Step [1000/1875], d_loss: 1.2099, g_loss: 1.4824, D(x): 0.64, D(G(z)): 0.35
Epoch [126/200], Step [0/1875], d_loss: 1.0053, g_loss: 1.1960, D(x): 0.69, D(G(z)): 0.36
Epoch [126/200], Step [1000/1875], d_loss: 0.9684, g_loss: 1.1075, D(x): 0.66, D(G(z)): 0.34
Epoch [127/200], Step [0/1875], d_loss: 0.7114, g_loss: 1.2725, D(x): 0.76, D(G(z)): 0.30
Epoch [127/200], Step [1000/1875], d_loss: 0.8682, g_loss: 1.3727, D(x): 0.63, D(G(z)): 0.26
Epoch [128/200], Step [0/1875], d_loss: 0.9651, g_loss: 1.1287, D(x): 0.74, D(G(z)): 0.39
Epoch [128/200], Step [1000/1875], d_loss: 0.7600, g_loss: 1.4872, D(x): 0.73, D(G(z)): 0.30
Epoch [129/200], Step [0/1875], d_loss: 1.0353, g_loss: 1.1982, D(x): 0.73, D(G(z)): 0.38
Epoch [129/200], Step [1000/1875], d_loss: 0.9312, g_loss: 1.6565, D(x): 0.67, D(G(z)): 0.30
Epoch [130/200], Step [0/1875], d_loss: 0.7257, g_loss: 1.1873, D(x): 0.69, D(G(z)): 0.22
Epoch [130/200], Step [1000/1875], d_loss: 0.8490, g_loss: 1.5466, D(x): 0.65, D(G(z)): 0.25
Epoch [131/200], Step [0/1875], d_loss: 0.8980, g_loss: 1.5924, D(x): 0.68, D(G(z)): 0.28
Epoch [131/200], Step [1000/1875], d_loss: 0.9562, g_loss: 1.5058, D(x): 0.72, D(G(z)): 0.36
Epoch [132/200], Step [0/1875], d_loss: 1.0407, g_loss: 1.7313, D(x): 0.59, D(G(z)): 0.28
Epoch [132/200], Step [1000/1875], d_loss: 0.8018, g_loss: 1.4991, D(x): 0.72, D(G(z)): 0.31
Epoch [133/200], Step [0/1875], d_loss: 1.0846, g_loss: 1.0952, D(x): 0.69, D(G(z)): 0.38
Epoch [133/200], Step [1000/1875], d_loss: 0.8227, g_loss: 1.0884, D(x): 0.73, D(G(z)): 0.32
Epoch [134/200], Step [0/1875], d_loss: 0.9787, g_loss: 1.4190, D(x): 0.71, D(G(z)): 0.36
Epoch [134/200], Step [1000/1875], d_loss: 1.0852, g_loss: 1.8930, D(x): 0.60, D(G(z)): 0.26
Epoch [135/200], Step [0/1875], d_loss: 1.1340, g_loss: 1.4754, D(x): 0.53, D(G(z)): 0.26
Epoch [135/200], Step [1000/1875], d_loss: 0.8791, g_loss: 1.6002, D(x): 0.73, D(G(z)): 0.34
Epoch [136/200], Step [0/1875], d_loss: 0.9289, g_loss: 1.2938, D(x): 0.74, D(G(z)): 0.39
Epoch [136/200], Step [1000/1875], d_loss: 0.8836, g_loss: 1.4500, D(x): 0.67, D(G(z)): 0.27
Epoch [137/200], Step [0/1875], d_loss: 0.9663, g_loss: 1.2554, D(x): 0.72, D(G(z)): 0.32
Epoch [137/200], Step [1000/1875], d_loss: 0.7621, g_loss: 1.5249, D(x): 0.70, D(G(z)): 0.26
Epoch [138/200], Step [0/1875], d_loss: 1.1226, g_loss: 1.3983, D(x): 0.62, D(G(z)): 0.37
Epoch [138/200], Step [1000/1875], d_loss: 0.8552, g_loss: 1.2803, D(x): 0.68, D(G(z)): 0.30
Epoch [139/200], Step [0/1875], d_loss: 1.1601, g_loss: 1.5479, D(x): 0.66, D(G(z)): 0.37
Epoch [139/200], Step [1000/1875], d_loss: 0.9467, g_loss: 1.3331, D(x): 0.78, D(G(z)): 0.41
Epoch [140/200], Step [0/1875], d_loss: 0.9792, g_loss: 1.6201, D(x): 0.72, D(G(z)): 0.33
Epoch [140/200], Step [1000/1875], d_loss: 1.0290, g_loss: 1.6335, D(x): 0.69, D(G(z)): 0.36
Epoch [141/200], Step [0/1875], d_loss: 0.8760, g_loss: 1.4903, D(x): 0.73, D(G(z)): 0.32
Epoch [141/200], Step [1000/1875], d_loss: 1.1730, g_loss: 1.3827, D(x): 0.65, D(G(z)): 0.35
Epoch [142/200], Step [0/1875], d_loss: 1.2059, g_loss: 1.6793, D(x): 0.58, D(G(z)): 0.32
Epoch [142/200], Step [1000/1875], d_loss: 1.0551, g_loss: 1.3108, D(x): 0.64, D(G(z)): 0.36
Epoch [143/200], Step [0/1875], d_loss: 1.1493, g_loss: 1.2051, D(x): 0.76, D(G(z)): 0.49
Epoch [143/200], Step [1000/1875], d_loss: 0.9853, g_loss: 0.9375, D(x): 0.69, D(G(z)): 0.33
Epoch [144/200], Step [0/1875], d_loss: 0.9930, g_loss: 1.2293, D(x): 0.72, D(G(z)): 0.39
Epoch [144/200], Step [1000/1875], d_loss: 1.1021, g_loss: 1.4031, D(x): 0.58, D(G(z)): 0.31
Epoch [145/200], Step [0/1875], d_loss: 1.0788, g_loss: 1.1353, D(x): 0.76, D(G(z)): 0.45
Epoch [145/200], Step [1000/1875], d_loss: 0.9493, g_loss: 1.9824, D(x): 0.66, D(G(z)): 0.28
Epoch [146/200], Step [0/1875], d_loss: 0.9586, g_loss: 1.3733, D(x): 0.62, D(G(z)): 0.24
Epoch [146/200], Step [1000/1875], d_loss: 1.1211, g_loss: 1.1700, D(x): 0.66, D(G(z)): 0.35
Epoch [147/200], Step [0/1875], d_loss: 1.1163, g_loss: 1.6816, D(x): 0.60, D(G(z)): 0.31
Epoch [147/200], Step [1000/1875], d_loss: 1.1130, g_loss: 1.5149, D(x): 0.61, D(G(z)): 0.33
Epoch [148/200], Step [0/1875], d_loss: 0.9912, g_loss: 1.5274, D(x): 0.65, D(G(z)): 0.30
Epoch [148/200], Step [1000/1875], d_loss: 0.7933, g_loss: 1.3911, D(x): 0.73, D(G(z)): 0.30
Epoch [149/200], Step [0/1875], d_loss: 0.7205, g_loss: 1.7141, D(x): 0.75, D(G(z)): 0.25
Epoch [149/200], Step [1000/1875], d_loss: 1.0681, g_loss: 1.2448, D(x): 0.74, D(G(z)): 0.42
Epoch [150/200], Step [0/1875], d_loss: 0.7419, g_loss: 1.4390, D(x): 0.68, D(G(z)): 0.23
Epoch [150/200], Step [1000/1875], d_loss: 1.0537, g_loss: 1.4104, D(x): 0.65, D(G(z)): 0.33
Epoch [151/200], Step [0/1875], d_loss: 0.7947, g_loss: 1.2123, D(x): 0.72, D(G(z)): 0.31
Epoch [151/200], Step [1000/1875], d_loss: 0.9032, g_loss: 1.7344, D(x): 0.58, D(G(z)): 0.18
Epoch [152/200], Step [0/1875], d_loss: 0.9012, g_loss: 1.8501, D(x): 0.67, D(G(z)): 0.25
Epoch [152/200], Step [1000/1875], d_loss: 0.9152, g_loss: 1.6020, D(x): 0.65, D(G(z)): 0.28
Epoch [153/200], Step [0/1875], d_loss: 1.1215, g_loss: 1.6962, D(x): 0.59, D(G(z)): 0.28
Epoch [153/200], Step [1000/1875], d_loss: 0.9356, g_loss: 1.3529, D(x): 0.75, D(G(z)): 0.37
Epoch [154/200], Step [0/1875], d_loss: 0.9896, g_loss: 1.3403, D(x): 0.74, D(G(z)): 0.37
Epoch [154/200], Step [1000/1875], d_loss: 1.0119, g_loss: 1.2061, D(x): 0.74, D(G(z)): 0.42
Epoch [155/200], Step [0/1875], d_loss: 1.0402, g_loss: 1.2992, D(x): 0.67, D(G(z)): 0.35
Epoch [155/200], Step [1000/1875], d_loss: 0.9205, g_loss: 1.7426, D(x): 0.68, D(G(z)): 0.32
Epoch [156/200], Step [0/1875], d_loss: 0.9372, g_loss: 0.8833, D(x): 0.73, D(G(z)): 0.37
Epoch [156/200], Step [1000/1875], d_loss: 1.2032, g_loss: 1.1325, D(x): 0.61, D(G(z)): 0.34
Epoch [157/200], Step [0/1875], d_loss: 0.9232, g_loss: 1.3139, D(x): 0.71, D(G(z)): 0.36
Epoch [157/200], Step [1000/1875], d_loss: 1.0662, g_loss: 1.0879, D(x): 0.77, D(G(z)): 0.45
Epoch [158/200], Step [0/1875], d_loss: 1.0168, g_loss: 1.1149, D(x): 0.63, D(G(z)): 0.32
Epoch [158/200], Step [1000/1875], d_loss: 0.8170, g_loss: 1.6005, D(x): 0.73, D(G(z)): 0.29
Epoch [159/200], Step [0/1875], d_loss: 0.9503, g_loss: 0.9681, D(x): 0.75, D(G(z)): 0.38
Epoch [159/200], Step [1000/1875], d_loss: 1.0097, g_loss: 1.1410, D(x): 0.69, D(G(z)): 0.38
Epoch [160/200], Step [0/1875], d_loss: 0.8961, g_loss: 1.3045, D(x): 0.78, D(G(z)): 0.42
Epoch [160/200], Step [1000/1875], d_loss: 0.8125, g_loss: 1.5028, D(x): 0.73, D(G(z)): 0.31
Epoch [161/200], Step [0/1875], d_loss: 0.9205, g_loss: 1.6392, D(x): 0.68, D(G(z)): 0.27
Epoch [161/200], Step [1000/1875], d_loss: 0.8256, g_loss: 1.3770, D(x): 0.72, D(G(z)): 0.32
Epoch [162/200], Step [0/1875], d_loss: 1.0830, g_loss: 1.5884, D(x): 0.61, D(G(z)): 0.36
Epoch [162/200], Step [1000/1875], d_loss: 0.9695, g_loss: 1.7384, D(x): 0.63, D(G(z)): 0.27
Epoch [163/200], Step [0/1875], d_loss: 1.0718, g_loss: 1.7019, D(x): 0.71, D(G(z)): 0.35
Epoch [163/200], Step [1000/1875], d_loss: 0.7365, g_loss: 1.5347, D(x): 0.72, D(G(z)): 0.28
Epoch [164/200], Step [0/1875], d_loss: 1.0448, g_loss: 1.4188, D(x): 0.56, D(G(z)): 0.25
Epoch [164/200], Step [1000/1875], d_loss: 0.7024, g_loss: 1.1493, D(x): 0.80, D(G(z)): 0.34
Epoch [165/200], Step [0/1875], d_loss: 0.6509, g_loss: 1.3696, D(x): 0.80, D(G(z)): 0.28
Epoch [165/200], Step [1000/1875], d_loss: 0.9247, g_loss: 1.3655, D(x): 0.70, D(G(z)): 0.35
Epoch [166/200], Step [0/1875], d_loss: 0.9052, g_loss: 1.0978, D(x): 0.76, D(G(z)): 0.39
Epoch [166/200], Step [1000/1875], d_loss: 0.7881, g_loss: 1.3715, D(x): 0.73, D(G(z)): 0.29
Epoch [167/200], Step [0/1875], d_loss: 1.0630, g_loss: 1.3438, D(x): 0.70, D(G(z)): 0.40
Epoch [167/200], Step [1000/1875], d_loss: 1.1506, g_loss: 1.6357, D(x): 0.54, D(G(z)): 0.24
Epoch [168/200], Step [0/1875], d_loss: 0.7992, g_loss: 1.6564, D(x): 0.73, D(G(z)): 0.25
Epoch [168/200], Step [1000/1875], d_loss: 0.9592, g_loss: 1.4136, D(x): 0.65, D(G(z)): 0.30
Epoch [169/200], Step [0/1875], d_loss: 0.9599, g_loss: 1.2311, D(x): 0.66, D(G(z)): 0.31
Epoch [169/200], Step [1000/1875], d_loss: 0.9924, g_loss: 1.6626, D(x): 0.68, D(G(z)): 0.34
Epoch [170/200], Step [0/1875], d_loss: 0.8713, g_loss: 1.8207, D(x): 0.80, D(G(z)): 0.40
Epoch [170/200], Step [1000/1875], d_loss: 1.1869, g_loss: 1.2282, D(x): 0.66, D(G(z)): 0.38
Epoch [171/200], Step [0/1875], d_loss: 1.0279, g_loss: 1.1309, D(x): 0.63, D(G(z)): 0.32
Epoch [171/200], Step [1000/1875], d_loss: 0.8797, g_loss: 2.0040, D(x): 0.71, D(G(z)): 0.30
Epoch [172/200], Step [0/1875], d_loss: 0.9126, g_loss: 1.6225, D(x): 0.65, D(G(z)): 0.24
Epoch [172/200], Step [1000/1875], d_loss: 0.8287, g_loss: 1.5217, D(x): 0.69, D(G(z)): 0.27
Epoch [173/200], Step [0/1875], d_loss: 0.9320, g_loss: 1.1766, D(x): 0.68, D(G(z)): 0.28
Epoch [173/200], Step [1000/1875], d_loss: 1.0596, g_loss: 2.0341, D(x): 0.69, D(G(z)): 0.29
Epoch [174/200], Step [0/1875], d_loss: 0.8312, g_loss: 1.5397, D(x): 0.79, D(G(z)): 0.33
Epoch [174/200], Step [1000/1875], d_loss: 0.7674, g_loss: 1.2422, D(x): 0.70, D(G(z)): 0.24
Epoch [175/200], Step [0/1875], d_loss: 0.7503, g_loss: 1.7233, D(x): 0.73, D(G(z)): 0.24
Epoch [175/200], Step [1000/1875], d_loss: 1.0236, g_loss: 1.3441, D(x): 0.64, D(G(z)): 0.34
Epoch [176/200], Step [0/1875], d_loss: 0.9639, g_loss: 1.4112, D(x): 0.73, D(G(z)): 0.39
Epoch [176/200], Step [1000/1875], d_loss: 0.7873, g_loss: 1.5375, D(x): 0.76, D(G(z)): 0.32
Epoch [177/200], Step [0/1875], d_loss: 0.8955, g_loss: 1.4132, D(x): 0.68, D(G(z)): 0.29
Epoch [177/200], Step [1000/1875], d_loss: 1.1728, g_loss: 1.5841, D(x): 0.60, D(G(z)): 0.32
Epoch [178/200], Step [0/1875], d_loss: 0.8312, g_loss: 1.3275, D(x): 0.72, D(G(z)): 0.27
Epoch [178/200], Step [1000/1875], d_loss: 1.0104, g_loss: 1.3960, D(x): 0.74, D(G(z)): 0.38
Epoch [179/200], Step [0/1875], d_loss: 0.8851, g_loss: 1.2724, D(x): 0.77, D(G(z)): 0.39
Epoch [179/200], Step [1000/1875], d_loss: 1.0904, g_loss: 1.3150, D(x): 0.65, D(G(z)): 0.37
Epoch [180/200], Step [0/1875], d_loss: 0.8384, g_loss: 1.4742, D(x): 0.71, D(G(z)): 0.29
Epoch [180/200], Step [1000/1875], d_loss: 1.2366, g_loss: 1.3583, D(x): 0.69, D(G(z)): 0.46
Epoch [181/200], Step [0/1875], d_loss: 1.1119, g_loss: 1.6124, D(x): 0.72, D(G(z)): 0.37
Epoch [181/200], Step [1000/1875], d_loss: 1.1789, g_loss: 1.1550, D(x): 0.59, D(G(z)): 0.31
Epoch [182/200], Step [0/1875], d_loss: 1.0281, g_loss: 0.8599, D(x): 0.74, D(G(z)): 0.41
Epoch [182/200], Step [1000/1875], d_loss: 1.1698, g_loss: 1.5769, D(x): 0.63, D(G(z)): 0.36
Epoch [183/200], Step [0/1875], d_loss: 0.8879, g_loss: 1.2538, D(x): 0.73, D(G(z)): 0.34
Epoch [183/200], Step [1000/1875], d_loss: 0.9862, g_loss: 1.7838, D(x): 0.61, D(G(z)): 0.28
Epoch [184/200], Step [0/1875], d_loss: 0.8218, g_loss: 1.2922, D(x): 0.67, D(G(z)): 0.25
Epoch [184/200], Step [1000/1875], d_loss: 0.8309, g_loss: 1.4066, D(x): 0.81, D(G(z)): 0.36
Epoch [185/200], Step [0/1875], d_loss: 0.8038, g_loss: 1.1647, D(x): 0.68, D(G(z)): 0.25
Epoch [185/200], Step [1000/1875], d_loss: 1.1130, g_loss: 1.4807, D(x): 0.63, D(G(z)): 0.31
Epoch [186/200], Step [0/1875], d_loss: 1.3574, g_loss: 1.8987, D(x): 0.53, D(G(z)): 0.29
Epoch [186/200], Step [1000/1875], d_loss: 1.0933, g_loss: 1.5170, D(x): 0.59, D(G(z)): 0.29
Epoch [187/200], Step [0/1875], d_loss: 0.9468, g_loss: 1.6168, D(x): 0.72, D(G(z)): 0.35
Epoch [187/200], Step [1000/1875], d_loss: 0.9485, g_loss: 1.8171, D(x): 0.69, D(G(z)): 0.29
Epoch [188/200], Step [0/1875], d_loss: 0.9278, g_loss: 1.0927, D(x): 0.66, D(G(z)): 0.27
Epoch [188/200], Step [1000/1875], d_loss: 0.8841, g_loss: 1.4329, D(x): 0.74, D(G(z)): 0.34
Epoch [189/200], Step [0/1875], d_loss: 1.1402, g_loss: 1.1908, D(x): 0.60, D(G(z)): 0.34
Epoch [189/200], Step [1000/1875], d_loss: 0.9516, g_loss: 1.2448, D(x): 0.71, D(G(z)): 0.35
Epoch [190/200], Step [0/1875], d_loss: 0.8385, g_loss: 1.1752, D(x): 0.77, D(G(z)): 0.32
Epoch [190/200], Step [1000/1875], d_loss: 1.1430, g_loss: 1.3168, D(x): 0.70, D(G(z)): 0.41
Epoch [191/200], Step [0/1875], d_loss: 0.8999, g_loss: 1.4734, D(x): 0.65, D(G(z)): 0.25
Epoch [191/200], Step [1000/1875], d_loss: 0.8006, g_loss: 1.3487, D(x): 0.68, D(G(z)): 0.20
Epoch [192/200], Step [0/1875], d_loss: 0.9304, g_loss: 1.5564, D(x): 0.71, D(G(z)): 0.32
Epoch [192/200], Step [1000/1875], d_loss: 0.8803, g_loss: 1.3595, D(x): 0.62, D(G(z)): 0.23
Epoch [193/200], Step [0/1875], d_loss: 0.8008, g_loss: 1.4470, D(x): 0.67, D(G(z)): 0.24
Epoch [193/200], Step [1000/1875], d_loss: 1.0546, g_loss: 1.0424, D(x): 0.83, D(G(z)): 0.47
Epoch [194/200], Step [0/1875], d_loss: 0.8909, g_loss: 2.0232, D(x): 0.65, D(G(z)): 0.25
Epoch [194/200], Step [1000/1875], d_loss: 1.1190, g_loss: 1.4303, D(x): 0.60, D(G(z)): 0.28
Epoch [195/200], Step [0/1875], d_loss: 0.9886, g_loss: 1.5795, D(x): 0.59, D(G(z)): 0.27
Epoch [195/200], Step [1000/1875], d_loss: 0.8679, g_loss: 1.7040, D(x): 0.67, D(G(z)): 0.24
Epoch [196/200], Step [0/1875], d_loss: 1.0795, g_loss: 1.9095, D(x): 0.62, D(G(z)): 0.29
Epoch [196/200], Step [1000/1875], d_loss: 0.9541, g_loss: 1.3313, D(x): 0.72, D(G(z)): 0.33
Epoch [197/200], Step [0/1875], d_loss: 1.0868, g_loss: 1.6374, D(x): 0.78, D(G(z)): 0.45
Epoch [197/200], Step [1000/1875], d_loss: 1.0295, g_loss: 1.5136, D(x): 0.67, D(G(z)): 0.36
Epoch [198/200], Step [0/1875], d_loss: 1.0157, g_loss: 1.9654, D(x): 0.56, D(G(z)): 0.17
Epoch [198/200], Step [1000/1875], d_loss: 0.7938, g_loss: 1.6147, D(x): 0.79, D(G(z)): 0.31
Epoch [199/200], Step [0/1875], d_loss: 0.7751, g_loss: 1.2779, D(x): 0.84, D(G(z)): 0.39
Epoch [199/200], Step [1000/1875], d_loss: 0.9865, g_loss: 1.4814, D(x): 0.65, D(G(z)): 0.27</code></pre><p>fake images</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">z = torch.randn(<span class="number">1</span>, latent_size).to(device)</span><br><span class="line">fake_images = G(z).view(<span class="number">28</span>, <span class="number">28</span>).data.cpu().numpy()</span><br><span class="line">plt.imshow(fake_images)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.image.AxesImage at 0x7f55b00136d8&gt;</code></pre><p><img src="output_18_1.png" alt="png"></p>
<p>真实图片</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(images[<span class="number">0</span>].view(<span class="number">28</span>,<span class="number">28</span>).data.cpu().numpy())</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.image.AxesImage at 0x7f55b09e7f60&gt;</code></pre><p><img src="output_20_1.png" alt="png"></p>
<h2 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h2><p><a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank" rel="noopener">UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS</a></p>
<p><a href="https://drive.google.com/drive/folders/0B7EVK8r0v71pbWNEUjJKdDQ3dGc" target="_blank" rel="noopener">图片下载地址</a><br><a href="https://drive.google.com/drive/folders/0B7EVK8r0v71pbWNEUjJKdDQ3dGc" target="_blank" rel="noopener">https://drive.google.com/drive/folders/0B7EVK8r0v71pbWNEUjJKdDQ3dGc</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.utils <span class="keyword">as</span> vutils</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !ls celeba/img_align_celeba/img_align_celeba_png</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">image_size=<span class="number">64</span></span><br><span class="line">batch_size=<span class="number">128</span></span><br><span class="line">dataroot=<span class="string">"celeba/img_align_celeba"</span></span><br><span class="line">num_workers = <span class="number">2</span></span><br><span class="line">dataset = torchvision.datasets.ImageFolder(root=dataroot, transform=transforms.Compose([</span><br><span class="line">    transforms.Resize(image_size),</span><br><span class="line">    transforms.CenterCrop(image_size),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">]))</span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">real_batch=next(iter(dataloader))</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">plt.axis=(<span class="string">"off"</span>)</span><br><span class="line">plt.title(<span class="string">"Training Images"</span>)</span><br><span class="line">plt.imshow(np.transpose(vutils.make_grid(real_batch[<span class="number">0</span>].to(device)[:<span class="number">64</span>], padding=<span class="number">2</span>, normalize=<span class="literal">True</span>).cpu(), (<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.image.AxesImage at 0x7f6db16dafd0&gt;</code></pre><p><img src="output_27_1.png" alt="png"></p>
<p>我们把模型的所有参数都初始化城mean=0, std=0.2</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weights_init</span><span class="params">(m)</span>:</span></span><br><span class="line">    classname = m.__class__.__name__</span><br><span class="line">    <span class="keyword">if</span> classname.find(<span class="string">'Conv'</span>) != <span class="number">-1</span>:</span><br><span class="line">        nn.init.normal_(m.weight.data, <span class="number">0.0</span>, <span class="number">0.02</span>)</span><br><span class="line">    <span class="keyword">elif</span> classname.find(<span class="string">'BatchNorm'</span>) != <span class="number">-1</span>:</span><br><span class="line">        nn.init.normal_(m.weight.data, <span class="number">1.0</span>, <span class="number">0.02</span>)</span><br><span class="line">        nn.init.constant_(m.bias.data, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p><img src="images/dcgan_generator.png" alt="dcgan"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">nz = <span class="number">100</span> <span class="comment"># latent vector的大小</span></span><br><span class="line">ngf = <span class="number">64</span> <span class="comment"># generator feature map size</span></span><br><span class="line">ndf = <span class="number">64</span> <span class="comment"># discriminator feature map size</span></span><br><span class="line">nc = <span class="number">3</span> <span class="comment"># color channels</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Generator, self).__init__()</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># input is Z, going into a convolution</span></span><br><span class="line">            <span class="comment"># torch.nn.ConvTranspose2d(in_channels, out_channels, </span></span><br><span class="line">            <span class="comment"># kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)</span></span><br><span class="line">            nn.ConvTranspose2d( nz, ngf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">8</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ngf*8) x 4 x 4</span></span><br><span class="line">            nn.ConvTranspose2d(ngf * <span class="number">8</span>, ngf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">4</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ngf*4) x 8 x 8</span></span><br><span class="line">            nn.ConvTranspose2d( ngf * <span class="number">4</span>, ngf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ngf*2) x 16 x 16</span></span><br><span class="line">            nn.ConvTranspose2d( ngf * <span class="number">2</span>, ngf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ngf) x 32 x 32</span></span><br><span class="line">            nn.ConvTranspose2d( ngf, nc, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">            <span class="comment"># state size. (nc) x 64 x 64</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.main(input)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, we can instantiate the generator and apply the weights_init function. Check out the printed model to see how the generator object is structured.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the generator</span></span><br><span class="line">netG = Generator().to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply the weights_init function to randomly initialize all weights</span></span><br><span class="line"><span class="comment">#  to mean=0, stdev=0.2.</span></span><br><span class="line">netG.apply(weights_init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the model</span></span><br><span class="line">print(netG)</span><br></pre></td></tr></table></figure>

<pre><code>Generator(
  (main): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)</code></pre><p>Discriminator</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Discriminator, self).__init__()</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># input is (nc) x 64 x 64</span></span><br><span class="line">            nn.Conv2d(nc, ndf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ndf) x 32 x 32</span></span><br><span class="line">            nn.Conv2d(ndf, ndf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">2</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ndf*2) x 16 x 16</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">2</span>, ndf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">4</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ndf*4) x 8 x 8</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">4</span>, ndf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">8</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ndf*8) x 4 x 4</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">8</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.main(input)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, as with the generator, we can create the discriminator, apply the weights_init function, and print the model’s structure.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the Discriminator</span></span><br><span class="line">netD = Discriminator().to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply the weights_init function to randomly initialize all weights</span></span><br><span class="line"><span class="comment">#  to mean=0, stdev=0.2.</span></span><br><span class="line">netD.apply(weights_init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the model</span></span><br><span class="line">print(netD)</span><br></pre></td></tr></table></figure>

<pre><code>Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace)
    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (12): Sigmoid()
  )
)</code></pre><p>开始训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.0002</span></span><br><span class="line">beta1 = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line">fixed_noise = torch.randn(<span class="number">64</span>, nz, <span class="number">1</span>, <span class="number">1</span>, device=device)</span><br><span class="line">d_optimizer = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, <span class="number">0.999</span>))</span><br><span class="line">g_optimizer = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, <span class="number">0.999</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">G_losses = []</span><br><span class="line">D_losses = []</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(dataloader):</span><br><span class="line">        <span class="comment"># 训练discriminator, maximize log(D(x)) + log(1-D(G(z)))</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 首先训练真实图片</span></span><br><span class="line">        netD.zero_grad()</span><br><span class="line">        </span><br><span class="line">        real_images = data[<span class="number">0</span>].to(device)</span><br><span class="line">        b_size = real_images.size(<span class="number">0</span>)</span><br><span class="line">        label = torch.ones(b_size).to(device)</span><br><span class="line">        output = netD(real_images).view(<span class="number">-1</span>)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        real_loss = loss_fn(output, label)</span><br><span class="line">        real_loss.backward()</span><br><span class="line">        D_x = output.mean().item()</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 然后训练生成的假图片</span></span><br><span class="line">        noise = torch.randn(b_size, nz, <span class="number">1</span>, <span class="number">1</span>, device=device)</span><br><span class="line">        fake_images = netG(noise)</span><br><span class="line">        label.fill_(<span class="number">0</span>)</span><br><span class="line">        output = netD(fake_images.detach()).view(<span class="number">-1</span>)</span><br><span class="line">        fake_loss = loss_fn(output, label)</span><br><span class="line">        fake_loss.backward()</span><br><span class="line">        D_G_z1 = output.mean().item()</span><br><span class="line">        loss_D = real_loss + fake_loss</span><br><span class="line">        d_optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练Generator </span></span><br><span class="line">        netG.zero_grad()</span><br><span class="line">        label.fill_(<span class="number">1</span>)</span><br><span class="line">        output = netD(fake_images).view(<span class="number">-1</span>)</span><br><span class="line">        loss_G = loss_fn(output, label)</span><br><span class="line">        loss_G.backward()</span><br><span class="line">        D_G_z2 = output.mean().item()</span><br><span class="line">        g_optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"[&#123;&#125;/&#123;&#125;] [&#123;&#125;/&#123;&#125;] Loss_D: &#123;:.4f&#125; Loss_G &#123;:.4f&#125; D(x): &#123;:.4f&#125; D(G(z)): &#123;:.4f&#125;/&#123;:.4f&#125;"</span></span><br><span class="line">                 .format(epoch, num_epochs, i, len(dataloader), loss_D.item(), loss_G.item(), D_x, D_G_z1, D_G_z2))</span><br><span class="line">        </span><br><span class="line">        G_losses.append(loss_G.item())</span><br><span class="line">        D_losses.append(loss_D.item())</span><br></pre></td></tr></table></figure>

<pre><code>[0/5] [0/1583] Loss_D: 1.7977 Loss_G 2.8596 D(x): 0.3357 D(G(z)): 0.3494/0.0786
[0/5] [50/1583] Loss_D: 0.4748 Loss_G 30.1861 D(x): 0.7715 D(G(z)): 0.0000/0.0000
[0/5] [100/1583] Loss_D: 0.1432 Loss_G 8.7877 D(x): 0.9865 D(G(z)): 0.1092/0.0016
[0/5] [150/1583] Loss_D: 0.5332 Loss_G 6.9773 D(x): 0.8701 D(G(z)): 0.2674/0.0030
[0/5] [200/1583] Loss_D: 1.5008 Loss_G 8.1102 D(x): 0.4722 D(G(z)): 0.0029/0.0011
[0/5] [250/1583] Loss_D: 0.3476 Loss_G 5.5318 D(x): 0.8942 D(G(z)): 0.1540/0.0132
[0/5] [300/1583] Loss_D: 0.6494 Loss_G 5.9788 D(x): 0.9072 D(G(z)): 0.3348/0.0124
[0/5] [350/1583] Loss_D: 0.8482 Loss_G 5.6696 D(x): 0.8947 D(G(z)): 0.4554/0.0091
[0/5] [400/1583] Loss_D: 0.5689 Loss_G 3.3358 D(x): 0.7856 D(G(z)): 0.1807/0.0647
[0/5] [450/1583] Loss_D: 0.8698 Loss_G 7.5017 D(x): 0.8675 D(G(z)): 0.4281/0.0022
[0/5] [500/1583] Loss_D: 0.3542 Loss_G 3.1888 D(x): 0.8573 D(G(z)): 0.1214/0.0587
[0/5] [550/1583] Loss_D: 0.3387 Loss_G 3.9772 D(x): 0.7958 D(G(z)): 0.0605/0.0351
[0/5] [600/1583] Loss_D: 0.6330 Loss_G 4.3450 D(x): 0.7693 D(G(z)): 0.1875/0.0238
[0/5] [650/1583] Loss_D: 0.6735 Loss_G 4.8144 D(x): 0.6305 D(G(z)): 0.0358/0.0166
[0/5] [700/1583] Loss_D: 0.3484 Loss_G 4.6406 D(x): 0.8652 D(G(z)): 0.1372/0.0182
[0/5] [750/1583] Loss_D: 0.5287 Loss_G 5.8325 D(x): 0.8684 D(G(z)): 0.2675/0.0056
[0/5] [800/1583] Loss_D: 0.6363 Loss_G 3.1169 D(x): 0.6298 D(G(z)): 0.0332/0.0755
[0/5] [850/1583] Loss_D: 0.4994 Loss_G 5.3602 D(x): 0.8846 D(G(z)): 0.2461/0.0114
[0/5] [900/1583] Loss_D: 0.5199 Loss_G 5.4862 D(x): 0.9498 D(G(z)): 0.2993/0.0118
[0/5] [950/1583] Loss_D: 0.3113 Loss_G 3.8929 D(x): 0.8070 D(G(z)): 0.0317/0.0357
[0/5] [1000/1583] Loss_D: 1.3229 Loss_G 1.8840 D(x): 0.3859 D(G(z)): 0.0013/0.2331
[0/5] [1050/1583] Loss_D: 0.3150 Loss_G 3.5746 D(x): 0.8395 D(G(z)): 0.0970/0.0547
[0/5] [1100/1583] Loss_D: 0.5306 Loss_G 3.1867 D(x): 0.6945 D(G(z)): 0.0447/0.0750
[0/5] [1150/1583] Loss_D: 0.5492 Loss_G 2.5496 D(x): 0.6916 D(G(z)): 0.0663/0.1255
[0/5] [1200/1583] Loss_D: 0.3651 Loss_G 4.2102 D(x): 0.7647 D(G(z)): 0.0440/0.0365
[0/5] [1250/1583] Loss_D: 1.3114 Loss_G 2.9933 D(x): 0.4186 D(G(z)): 0.0093/0.0944
[0/5] [1300/1583] Loss_D: 0.7040 Loss_G 6.9100 D(x): 0.8776 D(G(z)): 0.3483/0.0018
[0/5] [1350/1583] Loss_D: 0.6155 Loss_G 2.0302 D(x): 0.6897 D(G(z)): 0.1118/0.1726
[0/5] [1400/1583] Loss_D: 0.5944 Loss_G 3.1167 D(x): 0.7538 D(G(z)): 0.1957/0.0642
[0/5] [1450/1583] Loss_D: 0.3558 Loss_G 3.7467 D(x): 0.8731 D(G(z)): 0.1555/0.0415
[0/5] [1500/1583] Loss_D: 0.4071 Loss_G 4.1953 D(x): 0.8410 D(G(z)): 0.1453/0.0310
[0/5] [1550/1583] Loss_D: 1.6558 Loss_G 9.1945 D(x): 0.9677 D(G(z)): 0.7053/0.0004
[1/5] [0/1583] Loss_D: 0.5024 Loss_G 4.3460 D(x): 0.8704 D(G(z)): 0.2554/0.0201
[1/5] [50/1583] Loss_D: 0.7825 Loss_G 5.5473 D(x): 0.9305 D(G(z)): 0.4510/0.0072
[1/5] [100/1583] Loss_D: 0.5763 Loss_G 4.2330 D(x): 0.8332 D(G(z)): 0.2738/0.0248
[1/5] [150/1583] Loss_D: 0.5093 Loss_G 3.9376 D(x): 0.8285 D(G(z)): 0.2162/0.0325
[1/5] [200/1583] Loss_D: 0.7584 Loss_G 4.4998 D(x): 0.8351 D(G(z)): 0.3689/0.0258
[1/5] [250/1583] Loss_D: 0.4091 Loss_G 3.9546 D(x): 0.7356 D(G(z)): 0.0257/0.0337
[1/5] [300/1583] Loss_D: 0.5199 Loss_G 4.4009 D(x): 0.8562 D(G(z)): 0.2620/0.0212
[1/5] [350/1583] Loss_D: 1.6999 Loss_G 1.1305 D(x): 0.3153 D(G(z)): 0.0194/0.3955
[1/5] [400/1583] Loss_D: 0.4612 Loss_G 5.0442 D(x): 0.9210 D(G(z)): 0.2755/0.0113
[1/5] [450/1583] Loss_D: 0.3626 Loss_G 2.7311 D(x): 0.8119 D(G(z)): 0.1034/0.1106
[1/5] [500/1583] Loss_D: 0.5614 Loss_G 3.6350 D(x): 0.7820 D(G(z)): 0.1946/0.0512
[1/5] [550/1583] Loss_D: 0.3365 Loss_G 3.3296 D(x): 0.8540 D(G(z)): 0.1276/0.0561
[1/5] [600/1583] Loss_D: 0.9953 Loss_G 1.0561 D(x): 0.4885 D(G(z)): 0.0517/0.4178
[1/5] [650/1583] Loss_D: 0.4633 Loss_G 4.3857 D(x): 0.9219 D(G(z)): 0.2868/0.0181
[1/5] [700/1583] Loss_D: 0.3547 Loss_G 3.1719 D(x): 0.8356 D(G(z)): 0.1229/0.0661
[1/5] [750/1583] Loss_D: 1.4018 Loss_G 7.3128 D(x): 0.9540 D(G(z)): 0.6648/0.0022
[1/5] [800/1583] Loss_D: 1.9716 Loss_G 2.3110 D(x): 0.2525 D(G(z)): 0.0097/0.1644
[1/5] [850/1583] Loss_D: 0.3039 Loss_G 3.3825 D(x): 0.8757 D(G(z)): 0.1389/0.0494
[1/5] [900/1583] Loss_D: 0.4306 Loss_G 4.5716 D(x): 0.9128 D(G(z)): 0.2424/0.0176
[1/5] [950/1583] Loss_D: 1.0529 Loss_G 6.2549 D(x): 0.9377 D(G(z)): 0.5375/0.0043
[1/5] [1000/1583] Loss_D: 0.5825 Loss_G 2.5413 D(x): 0.7108 D(G(z)): 0.1435/0.1155
[1/5] [1050/1583] Loss_D: 0.6516 Loss_G 4.6775 D(x): 0.9519 D(G(z)): 0.4014/0.0170
[1/5] [1100/1583] Loss_D: 0.8078 Loss_G 5.3468 D(x): 0.8942 D(G(z)): 0.4513/0.0077
[1/5] [1150/1583] Loss_D: 0.7372 Loss_G 4.2160 D(x): 0.8662 D(G(z)): 0.3771/0.0272
[1/5] [1200/1583] Loss_D: 0.5704 Loss_G 1.7837 D(x): 0.6827 D(G(z)): 0.0922/0.2175
[1/5] [1250/1583] Loss_D: 0.8721 Loss_G 4.8623 D(x): 0.9443 D(G(z)): 0.4977/0.0137
[1/5] [1300/1583] Loss_D: 0.5091 Loss_G 2.4733 D(x): 0.6754 D(G(z)): 0.0485/0.1242
[1/5] [1350/1583] Loss_D: 0.4865 Loss_G 3.0695 D(x): 0.8064 D(G(z)): 0.1955/0.0689
[1/5] [1400/1583] Loss_D: 0.6490 Loss_G 4.3856 D(x): 0.9040 D(G(z)): 0.3590/0.0200
[1/5] [1450/1583] Loss_D: 0.6000 Loss_G 2.2117 D(x): 0.7705 D(G(z)): 0.2435/0.1419
[1/5] [1500/1583] Loss_D: 0.5049 Loss_G 3.4771 D(x): 0.8402 D(G(z)): 0.2365/0.0487
[1/5] [1550/1583] Loss_D: 0.5885 Loss_G 1.5197 D(x): 0.6468 D(G(z)): 0.0694/0.2862
[2/5] [0/1583] Loss_D: 0.5091 Loss_G 2.2415 D(x): 0.7458 D(G(z)): 0.1528/0.1331
[2/5] [50/1583] Loss_D: 0.4685 Loss_G 2.8283 D(x): 0.8897 D(G(z)): 0.2576/0.0899
[2/5] [100/1583] Loss_D: 0.5364 Loss_G 2.2865 D(x): 0.7544 D(G(z)): 0.1845/0.1296
[2/5] [150/1583] Loss_D: 2.4751 Loss_G 4.7502 D(x): 0.9278 D(G(z)): 0.8115/0.0218
[2/5] [200/1583] Loss_D: 1.7663 Loss_G 1.6306 D(x): 0.2388 D(G(z)): 0.0119/0.2518
[2/5] [250/1583] Loss_D: 0.6184 Loss_G 1.8157 D(x): 0.6371 D(G(z)): 0.0831/0.2129
[2/5] [300/1583] Loss_D: 0.6009 Loss_G 2.4621 D(x): 0.6639 D(G(z)): 0.0986/0.1299
[2/5] [350/1583] Loss_D: 0.6172 Loss_G 2.7100 D(x): 0.7548 D(G(z)): 0.2272/0.0928
[2/5] [400/1583] Loss_D: 0.5001 Loss_G 2.0378 D(x): 0.6971 D(G(z)): 0.0869/0.1678
[2/5] [450/1583] Loss_D: 0.6404 Loss_G 3.3460 D(x): 0.8992 D(G(z)): 0.3705/0.0574
[2/5] [500/1583] Loss_D: 0.5403 Loss_G 2.1565 D(x): 0.6950 D(G(z)): 0.1098/0.1509
[2/5] [550/1583] Loss_D: 0.5993 Loss_G 3.6174 D(x): 0.9018 D(G(z)): 0.3564/0.0417
[2/5] [600/1583] Loss_D: 1.0482 Loss_G 3.6277 D(x): 0.9294 D(G(z)): 0.5477/0.0558
[2/5] [650/1583] Loss_D: 0.4903 Loss_G 2.8267 D(x): 0.8284 D(G(z)): 0.2277/0.0809
[2/5] [700/1583] Loss_D: 0.6068 Loss_G 2.0575 D(x): 0.6432 D(G(z)): 0.0900/0.1623
[2/5] [750/1583] Loss_D: 1.4213 Loss_G 1.1597 D(x): 0.3157 D(G(z)): 0.0459/0.3713
[2/5] [800/1583] Loss_D: 0.5707 Loss_G 2.9375 D(x): 0.8297 D(G(z)): 0.2824/0.0749
[2/5] [850/1583] Loss_D: 0.8145 Loss_G 0.8862 D(x): 0.5465 D(G(z)): 0.0760/0.4527
[2/5] [900/1583] Loss_D: 0.7114 Loss_G 1.6350 D(x): 0.6121 D(G(z)): 0.1375/0.2354
[2/5] [950/1583] Loss_D: 0.6885 Loss_G 2.2735 D(x): 0.6473 D(G(z)): 0.1660/0.1418
[2/5] [1000/1583] Loss_D: 1.0785 Loss_G 1.0148 D(x): 0.4366 D(G(z)): 0.0730/0.4223
[2/5] [1050/1583] Loss_D: 0.7579 Loss_G 2.5076 D(x): 0.6528 D(G(z)): 0.1961/0.1142
[2/5] [1100/1583] Loss_D: 0.6557 Loss_G 3.5820 D(x): 0.8655 D(G(z)): 0.3631/0.0372
[2/5] [1150/1583] Loss_D: 0.6402 Loss_G 3.3918 D(x): 0.9224 D(G(z)): 0.3697/0.0502
[2/5] [1200/1583] Loss_D: 0.6989 Loss_G 2.1415 D(x): 0.6174 D(G(z)): 0.1267/0.1470
[2/5] [1250/1583] Loss_D: 0.6699 Loss_G 1.9413 D(x): 0.6219 D(G(z)): 0.0995/0.1874
[2/5] [1300/1583] Loss_D: 0.6479 Loss_G 1.8731 D(x): 0.6013 D(G(z)): 0.0677/0.1886
[2/5] [1350/1583] Loss_D: 0.5023 Loss_G 3.0319 D(x): 0.8700 D(G(z)): 0.2779/0.0599
[2/5] [1400/1583] Loss_D: 0.4328 Loss_G 2.8918 D(x): 0.7801 D(G(z)): 0.1382/0.0732
[2/5] [1450/1583] Loss_D: 0.6579 Loss_G 2.0119 D(x): 0.7162 D(G(z)): 0.2334/0.1683
[2/5] [1500/1583] Loss_D: 0.8299 Loss_G 3.7579 D(x): 0.8492 D(G(z)): 0.4391/0.0331
[2/5] [1550/1583] Loss_D: 0.6887 Loss_G 1.4614 D(x): 0.6397 D(G(z)): 0.1633/0.2818
[3/5] [0/1583] Loss_D: 0.8251 Loss_G 2.7054 D(x): 0.7448 D(G(z)): 0.3643/0.0842
[3/5] [50/1583] Loss_D: 0.6720 Loss_G 2.8488 D(x): 0.8670 D(G(z)): 0.3652/0.0798
[3/5] [100/1583] Loss_D: 0.6498 Loss_G 1.4725 D(x): 0.7225 D(G(z)): 0.2206/0.2821
[3/5] [150/1583] Loss_D: 1.0247 Loss_G 1.1697 D(x): 0.4694 D(G(z)): 0.1067/0.3692
[3/5] [200/1583] Loss_D: 0.5313 Loss_G 2.4117 D(x): 0.8255 D(G(z)): 0.2553/0.1162
[3/5] [250/1583] Loss_D: 0.7865 Loss_G 2.2379 D(x): 0.5887 D(G(z)): 0.1421/0.1469
[3/5] [300/1583] Loss_D: 1.1039 Loss_G 3.4455 D(x): 0.8690 D(G(z)): 0.5555/0.0467
[3/5] [350/1583] Loss_D: 0.5300 Loss_G 1.9104 D(x): 0.7838 D(G(z)): 0.2207/0.1845
[3/5] [400/1583] Loss_D: 0.7535 Loss_G 3.2029 D(x): 0.7946 D(G(z)): 0.3583/0.0539
[3/5] [450/1583] Loss_D: 0.7322 Loss_G 4.1419 D(x): 0.8885 D(G(z)): 0.4089/0.0217
[3/5] [500/1583] Loss_D: 0.5901 Loss_G 2.4395 D(x): 0.7824 D(G(z)): 0.2573/0.1048
[3/5] [550/1583] Loss_D: 0.6639 Loss_G 3.1330 D(x): 0.8085 D(G(z)): 0.3284/0.0604
[3/5] [600/1583] Loss_D: 0.5979 Loss_G 2.5612 D(x): 0.8028 D(G(z)): 0.2748/0.0973
[3/5] [650/1583] Loss_D: 0.6524 Loss_G 2.2008 D(x): 0.7211 D(G(z)): 0.2281/0.1383
[3/5] [700/1583] Loss_D: 0.5078 Loss_G 2.2305 D(x): 0.7849 D(G(z)): 0.1987/0.1305
[3/5] [750/1583] Loss_D: 0.7095 Loss_G 3.5083 D(x): 0.8811 D(G(z)): 0.3953/0.0417
[3/5] [800/1583] Loss_D: 0.7160 Loss_G 2.6990 D(x): 0.8064 D(G(z)): 0.3518/0.0900
[3/5] [850/1583] Loss_D: 0.6407 Loss_G 3.0253 D(x): 0.8553 D(G(z)): 0.3457/0.0606
[3/5] [900/1583] Loss_D: 0.7381 Loss_G 3.8821 D(x): 0.8539 D(G(z)): 0.3712/0.0279
[3/5] [950/1583] Loss_D: 1.0212 Loss_G 1.1013 D(x): 0.5035 D(G(z)): 0.1802/0.3981
[3/5] [1000/1583] Loss_D: 0.5352 Loss_G 2.1082 D(x): 0.7537 D(G(z)): 0.1909/0.1556
[3/5] [1050/1583] Loss_D: 0.9204 Loss_G 1.1990 D(x): 0.5621 D(G(z)): 0.2122/0.3387
[3/5] [1100/1583] Loss_D: 1.3896 Loss_G 3.7979 D(x): 0.8729 D(G(z)): 0.6477/0.0351
[3/5] [1150/1583] Loss_D: 0.6079 Loss_G 2.3365 D(x): 0.7236 D(G(z)): 0.1868/0.1222
[3/5] [1200/1583] Loss_D: 0.7446 Loss_G 3.2400 D(x): 0.8669 D(G(z)): 0.4066/0.0536
[3/5] [1250/1583] Loss_D: 0.5165 Loss_G 2.2988 D(x): 0.7275 D(G(z)): 0.1453/0.1266
[3/5] [1300/1583] Loss_D: 0.4456 Loss_G 2.2971 D(x): 0.7558 D(G(z)): 0.1283/0.1286
[3/5] [1350/1583] Loss_D: 0.6839 Loss_G 1.8744 D(x): 0.7300 D(G(z)): 0.2578/0.1925
[3/5] [1400/1583] Loss_D: 0.5876 Loss_G 3.1330 D(x): 0.8353 D(G(z)): 0.3002/0.0564
[3/5] [1450/1583] Loss_D: 0.5586 Loss_G 3.2172 D(x): 0.9043 D(G(z)): 0.3380/0.0534
[3/5] [1500/1583] Loss_D: 0.5847 Loss_G 2.8399 D(x): 0.8091 D(G(z)): 0.2777/0.0809
[3/5] [1550/1583] Loss_D: 0.4929 Loss_G 2.3813 D(x): 0.7532 D(G(z)): 0.1533/0.1226
[4/5] [0/1583] Loss_D: 0.8560 Loss_G 4.1151 D(x): 0.8905 D(G(z)): 0.4680/0.0250
[4/5] [50/1583] Loss_D: 0.6350 Loss_G 2.4734 D(x): 0.7954 D(G(z)): 0.2928/0.1036
[4/5] [100/1583] Loss_D: 0.5003 Loss_G 2.0825 D(x): 0.7856 D(G(z)): 0.2060/0.1513
[4/5] [150/1583] Loss_D: 0.6394 Loss_G 2.3414 D(x): 0.7299 D(G(z)): 0.2361/0.1241
[4/5] [200/1583] Loss_D: 0.4699 Loss_G 1.9515 D(x): 0.7187 D(G(z)): 0.0963/0.1836
[4/5] [250/1583] Loss_D: 0.6581 Loss_G 1.8691 D(x): 0.6796 D(G(z)): 0.1988/0.1950
[4/5] [300/1583] Loss_D: 0.7072 Loss_G 2.3310 D(x): 0.7996 D(G(z)): 0.3419/0.1218
[4/5] [350/1583] Loss_D: 1.4915 Loss_G 4.6909 D(x): 0.9691 D(G(z)): 0.7055/0.0143
[4/5] [400/1583] Loss_D: 0.7722 Loss_G 3.2458 D(x): 0.8720 D(G(z)): 0.4223/0.0511
[4/5] [450/1583] Loss_D: 1.6807 Loss_G 0.2487 D(x): 0.3045 D(G(z)): 0.2069/0.7933
[4/5] [500/1583] Loss_D: 0.8011 Loss_G 2.0801 D(x): 0.7842 D(G(z)): 0.3814/0.1584
[4/5] [550/1583] Loss_D: 0.7781 Loss_G 1.3220 D(x): 0.5185 D(G(z)): 0.0437/0.3086
[4/5] [600/1583] Loss_D: 0.9146 Loss_G 1.1716 D(x): 0.5058 D(G(z)): 0.0925/0.3569
[4/5] [650/1583] Loss_D: 0.6587 Loss_G 2.8468 D(x): 0.8144 D(G(z)): 0.3266/0.0783
[4/5] [700/1583] Loss_D: 1.1936 Loss_G 0.4950 D(x): 0.3779 D(G(z)): 0.0447/0.6399
[4/5] [750/1583] Loss_D: 0.6820 Loss_G 2.3641 D(x): 0.7134 D(G(z)): 0.2400/0.1201
[4/5] [800/1583] Loss_D: 0.7211 Loss_G 3.0129 D(x): 0.9204 D(G(z)): 0.4249/0.0648
[4/5] [850/1583] Loss_D: 0.9899 Loss_G 3.3069 D(x): 0.8724 D(G(z)): 0.5214/0.0492
[4/5] [900/1583] Loss_D: 0.5789 Loss_G 2.5141 D(x): 0.7435 D(G(z)): 0.2110/0.1052
[4/5] [950/1583] Loss_D: 0.7162 Loss_G 1.3583 D(x): 0.5589 D(G(z)): 0.0576/0.3125
[4/5] [1000/1583] Loss_D: 1.1378 Loss_G 3.7072 D(x): 0.8517 D(G(z)): 0.5624/0.0364
[4/5] [1050/1583] Loss_D: 0.5823 Loss_G 2.5660 D(x): 0.7596 D(G(z)): 0.2257/0.0966
[4/5] [1100/1583] Loss_D: 0.7205 Loss_G 1.8147 D(x): 0.6805 D(G(z)): 0.2338/0.1991
[4/5] [1150/1583] Loss_D: 0.6265 Loss_G 2.7900 D(x): 0.7949 D(G(z)): 0.2872/0.0816
[4/5] [1200/1583] Loss_D: 1.1111 Loss_G 4.4571 D(x): 0.9287 D(G(z)): 0.5991/0.0167
[4/5] [1250/1583] Loss_D: 1.0609 Loss_G 4.3863 D(x): 0.8724 D(G(z)): 0.5500/0.0174
[4/5] [1300/1583] Loss_D: 0.6351 Loss_G 1.9326 D(x): 0.7810 D(G(z)): 0.2821/0.1783
[4/5] [1350/1583] Loss_D: 0.5135 Loss_G 2.3507 D(x): 0.7324 D(G(z)): 0.1416/0.1288
[4/5] [1400/1583] Loss_D: 0.6132 Loss_G 5.0354 D(x): 0.9302 D(G(z)): 0.3841/0.0102
[4/5] [1450/1583] Loss_D: 0.5440 Loss_G 2.3178 D(x): 0.7050 D(G(z)): 0.1354/0.1257
[4/5] [1500/1583] Loss_D: 0.5710 Loss_G 2.4214 D(x): 0.8401 D(G(z)): 0.2911/0.1163
[4/5] [1550/1583] Loss_D: 2.0148 Loss_G 4.4395 D(x): 0.9461 D(G(z)): 0.7895/0.0236</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    fake = netG(fixed_noise).detach().cpu()</span><br><span class="line"><span class="comment"># fake</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">real_batch = next(iter(dataloader))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the real images</span></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>,<span class="number">30</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.axis=(<span class="string">"off"</span>)</span><br><span class="line">plt.title(<span class="string">"Real Images"</span>)</span><br><span class="line">plt.imshow(np.transpose(vutils.make_grid(real_batch[<span class="number">0</span>].to(device)[:<span class="number">64</span>], padding=<span class="number">5</span>, normalize=<span class="literal">True</span>).cpu(),(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the fake images from the last epoch</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.axis=(<span class="string">"off"</span>)</span><br><span class="line">plt.title(<span class="string">"Fake Images"</span>)</span><br><span class="line">plt.imshow(np.transpose(vutils.make_grid(fake, padding=<span class="number">2</span>, normalize=<span class="literal">True</span>), (<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_40_0.png" alt="png"></p>

        </div>
    

</div>
            
        </section>
    </div>
</div>



    <div class="row">
        <div class="col-sm-12">
            <div class="wrap-pagination">
                <a class="disabled" href="/">
                    <i class="fa fa-chevron-left" aria-hidden="true"></i>
                </a>
                <a class="" href="/page/2/">
                    <i class="fa fa-chevron-right" aria-hidden="true"></i>
                </a>
            </div>
        </div>
    </div>




</div>

<!-- Footer -->
<div class="push"></div>

<footer class="footer-content">
    <div class="container">
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 footer-about">
                <h2>About</h2>
                <p>
                    This theme was developed by <a href="https://github.com/klugjo" target="_blank" rel="noopener">Jonathan Klughertz</a>. The source code is available on Github. Create Websites. Make Magic.
                </p>
            </div>
            
    <div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 recent-posts">
        <h2>Recent Posts</h2>
        <ul>
            
            <li>
                <a class="footer-post" href="/2020/03/08/AlexNet%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/">AlexNet详细解读</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2020/03/08/%E5%8D%B7%E7%A9%8D%E4%B8%AD%E7%9A%84stride%E5%92%8Cpadding/">卷積中的stride和padding</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2020/03/08/Why%20does%20overlapped%20pooling%20help%20reduce%20overfitting%20in%20conv%20nets/">Why does overlapped pooli</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2020/03/08/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5summary/">对称矩阵summary</a>
            </li>
            
        </ul>
    </div>



            
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <ul class="list-inline footer-social-icons">
                    
                    <li class="list-inline-item">
                        <a href="https://github.com/klugjo/hexo-theme-alpha-dust" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-github"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://twitter.com/?lang=en" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-twitter"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://www.facebook.com/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-facebook"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://www.instagram.com/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-instagram"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://dribbble.com/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-dribbble"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://plus.google.com/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-google-plus"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://www.behance.net/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-behance"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://500px.com/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-500px"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="mailto:test@example.com">
                            <span class="footer-icon-container">
                                <i class="fa fa-envelope-o"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="\#">
                            <span class="footer-icon-container">
                                <i class="fa fa-rss"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <div class="footer-copyright">
                    @Untitled. All right reserved | Design & Hexo <a href="http://www.codeblocq.com/" target="_blank" rel="noopener">Jonathan Klughertz</a>
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- After footer scripts -->

<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Tween Max -->
<script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.5/TweenMax.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Custom JavaScript -->

<script src="/js/main.js"></script>


<!-- Disqus Comments -->



</body>

</html>