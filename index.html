<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    

    <!--Author-->
    
        <meta name="author" content="Yunfan Li">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Hexo"/>
    

    <!--Open Graph Description-->
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="Hexo"/>

    <!--Type page-->
    
        <meta property="og:type" content="website" />
    

    <!--Page Cover-->
    

    
        <meta name="twitter:card" content="summary" />
    
    
    

    <!-- Title -->
    
    <title>Hexo</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.2/css/bootstrap.min.css" integrity="sha384-y3tfxAZXuh4HwSYylfB+J125MxIs6mR5FOHamPBG064zB+AFeWH94NdvaCBm8qnd" crossorigin="anonymous">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/style.css">


    <!-- Google Analytics -->
    


<meta name="generator" content="Hexo 4.2.0"></head>


<body>

<div class="bg-gradient"></div>
<div class="bg-pattern"></div>

<!-- Menu -->
<!--Menu Links and Overlay-->
<div class="menu-bg">
    <div class="menu-container">
        <ul>
            
            <li class="menu-item">
                <a href="/archives">
                    Home
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/archives">
                    Archives
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/about.html">
                    About
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/tags">
                    Tags
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/categories">
                    Categories
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/contact.html">
                    Contact
                </a>
            </li>
            
        </ul>
    </div>
</div>

<!--Hamburger Icon-->
<nav>
    <a href="#menu"></a>
</nav>

<div class="container">

    <!-- Main Content -->
    <div class="row">
    <div class="col-sm-12">

        <!--Title and Logo-->
        <header>
    <div class="logo">
        <a href="/"><i class="logo-icon fa fa-cube" aria-hidden="true"></i></a>
        
            <h1 id="main-title" class="title">Hexo</h1>
        
    </div>
</header>

        <section class="main">
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/04/17/2DPE_pics/clip/">
                2DPE_pics/clip
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-04-17</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/04/17/#%20%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1(Human%20Pose%20Estimation)%E7%BB%8F%E5%85%B8%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/">
                # 人体姿态估计(Human Pose Estimation)经典方法整理
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-04-17</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="人体姿态估计-Human-Pose-Estimation-经典方法整理"><a href="#人体姿态估计-Human-Pose-Estimation-经典方法整理" class="headerlink" title="人体姿态估计(Human Pose Estimation)经典方法整理"></a>人体姿态估计(Human Pose Estimation)经典方法整理</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上学期搬砖期间做了一些pose estimation相关的工作，但一直没有系统的整理过相关方法。近日疫情当头封闭在家，闲暇之余重温了一下之前看过的论文，对pose estimation的部分经典方法做了一个整理。内容大多为个人对这些方法的理解，所以本文也算是一个<strong>论文笔记合集</strong>吧。</p>
<p>本文涉及到的工作仅包含个人读过的部分论文，按时间顺序进行了整理，并不能代表pose estimation这一领域完整的发展历程。比如bottom-up中的PersonLab、PifPaf，以及传统top-down/bottom-up方法之外的一些single-stage方法等，都是近年来出现的一些值得研究的工作，由于个人还没有仔细了解过暂时没写，<strong>之后可能会继续更新</strong>。</p>
<h3 id="本文目录如下："><a href="#本文目录如下：" class="headerlink" title="本文目录如下："></a>本文目录如下：</h3><h4 id="·-top-down"><a href="#·-top-down" class="headerlink" title="·    top-down"></a>·    top-down</h4><p>o  CPM</p>
<p>o  Hourglass</p>
<p>o  CPN</p>
<p>o  Simple Baselines</p>
<p>o  HRNet</p>
<p>o  MSPN</p>
<h4 id="·-bottom-up"><a href="#·-bottom-up" class="headerlink" title="·    bottom-up"></a>·    bottom-up</h4><p>o  openpose</p>
<p>o  Hourglass+Associative Embedding</p>
<p>o  HigherHRNet</p>
<p><strong>在整理过程中，我参照了以下几篇文章的思路，也添加了一些个人的理解。这几篇文章整理的思路都非常清晰，作者的水平也都比我高得多，推荐大家阅读。</strong></p>
<p><a href="https://zhuanlan.zhihu.com/p/85506259" target="_blank" rel="noopener">俞刚：人体姿态估计的过去，现在，未来zhuanlan.zhihu.com</a><a href="https://zhuanlan.zhihu.com/p/72561165" target="_blank" rel="noopener">哇噻：重新思考人体姿态估计 Rethinking Human Pose Estimationzhuanlan.zhihu.com</a><a href="https://link.zhihu.com/?target=https%3A//nanonets.com/blog/human-pose-estimation-2d-guide/">A 2019 guide to Human Pose Estimation with Deep Learningnanonets.com</a></p>
<p>正文开始之前还是希望各位<strong>带着批判的眼光阅读</strong>，毕竟本人目前大三水平有限，可能有理解不到位或不正确的地方，希望大家批评指正，欢迎大家评论区或私信随时交流。</p>
<h2 id="Review-of-2D-Human-Pose-Estimation-with-Deep-Learning"><a href="#Review-of-2D-Human-Pose-Estimation-with-Deep-Learning" class="headerlink" title="Review of 2D Human Pose Estimation with Deep Learning"></a>Review of 2D Human Pose Estimation with Deep Learning</h2><p>人体姿态估计（Human Pose Estimation）是计算机视觉中的一个重要任务，也是计算机理解人类动作、行为必不可少的一步。近年来，使用深度学习进行人体姿态估计的方法陆续被提出，且达到了远超传统方法的表现。在实际求解时，对人体姿态的估计常常转化为对人体关键点的预测问题，即首先预测出人体各个关键点的位置坐标，然后根据先验知识确定关键点之间的空间位置关系，从而得到预测的人体骨架。</p>
<p>姿态估计问题可以分为两大类：<strong>2D姿态估计</strong>和<strong>3D姿态估计</strong>。顾名思义，前者是为每个关键点预测一个二维坐标 ；后者是为每个关键点预测一个三维坐标 ，增加了一维深度信息。本文主要介绍2D姿态估计。</p>
<p>对于2D姿态估计，当下研究的多为<strong>多人姿态估计</strong>，即每张图片可能包含多个人。解决该类问题的思路通常有两种：top-down和bottom-up：</p>
<p>·    top-down的思路是首先对图片进行目标检测，找出所有的人；然后将人从原图中crop出来，resize后输入到网络中进行姿态估计。换言之，top-down是<strong>将多人姿态估计的问题转化为多个单人姿态估计的问题</strong>。</p>
<p>·    bottom-up的思路是<strong>首先找出图片中所有关键点，然后对关键点进行分组</strong>，从而得到一个个人。</p>
<p>通常来说，<strong>top-down具有更高的精度，而bottom-up具有更快的速度</strong>。下面分别对这两种思路的经典算法展开介绍。</p>
<h2 id="Top-down"><a href="#Top-down" class="headerlink" title="Top-down"></a>Top-down</h2><p>由上文我们知道，top-down的方法将多人姿态估计转换为单人姿态估计，那么网络的输入就是包含一个人的bounding box，网络预测的是人的 个关键点坐标。对于关键点的ground truth（对应网络的输出）如何表示有两种思路：</p>
<p>·    ，即<strong>直接对坐标进行回归</strong>，网络的输出是经过fc层输出的 个数字</p>
<p>·    个heatmap，即<strong>为每个关键点预测一个heatmap</strong>作为关键点的中间表示，heatmap上的最大值处即对应关键点的坐标。对于改种方法，heatmap的ground truth是<strong>以关键点为中心的二维高斯分布</strong>（高斯核大小为超参）</p>
<p>早期的工作如DeepPose多为直接回归坐标，当下的工作多数以heatmap作为网络的输出，这种中间表示形式使得回归结果更加精确。接下来我们介绍top-down发展过程中的一些landmark。</p>
<p>需要说明的是，CPM和Hourglass提出时主要面向的是单人姿态估计，因为当时还没有COCO数据集，多使用MPII数据集进行evaluation。但top-down的方法本质上也是在解决单人姿态估计问题，所以将这两个模型放在此处介绍。</p>
<h3 id="CPM"><a href="#CPM" class="headerlink" title="CPM"></a>CPM</h3><p>CPM，Convolutional Pose Machines，是2015年CMU的一个工作。这个工作提出了很重要的一点：使用神经网络同时学习<strong>图片特征(image features)和空间信息(spatial context)</strong>，这是处理姿态估计问题必不可少的两样信息。在此之前，我们多使用CNN来提取图片特征，使用graphical model或其他模型来表达各个身体部位在空间上的联系。使用神经网络同时学习这两种信息，不仅效果更好，而且使<strong>端到端(end-to-end)</strong>学习成为可能。</p>
<p>CPM是一个<strong>multi-stage</strong>的结构，如下图所示。每个stage的输入是原始图片特征和上一个阶段输出的belief map，这个belief map可以认为是之前的stage学到的spatial context的一个encoding。这样当前stage根据这两种信息继续通过卷积层提取信息，并产生新的belief map，这样经过不断的<strong>refinement</strong>，最后产生一个较为准确的结果。</p>
<p><img src="2DPE_pics/clip_image002.jpg" alt="截图里有图片  描述已自动生成"></p>
<p>下面这张图给出了一个具体的例子来强调spatial context的重要性，也展现了refinement的过程。在stage1时，错误的将right elbow定位到了right knee处；在stage2时，由于有了stage1提供的spatial context信息，我们根据right shoulder的位置能够对right elbow的位置进行纠正，从图中可以看到响应的峰值已经基本到了正确位置。在stage3时，stage2中一些错误的响应（left elbow、right knee）彻底被消除，right elbow的定位也更加精确。</p>
<p><img src="2DPE_pics/clip_image003.jpg" alt="图片包含 女人, 钟表, 站, 华美  描述已自动生成"></p>
<p>这篇文章还提出了很重要的一点，就是<strong>通过intermediate supervision来解决梯度消失的问题</strong>。由于我们的网络可以包含许多个stage，随着网络的加深，梯度消失问题的出现导致网络无法收敛。因此，在每个stage结束后我们给当前的belief map加一个监督，可以有效缓解梯度消失的问题，后面可以看到在multi-stage的网络中这是比较常用的一种技巧。</p>
<h3 id="Hourglass"><a href="#Hourglass" class="headerlink" title="Hourglass"></a>Hourglass</h3><p>Hourglass也是一种multi-stage的结构，是2016年的一个工作，与CPM相比更加简洁一些，如下图所示。这个网络由多个堆叠起来的Hourglass module组成（因为网络长的很像多个堆叠起来的沙漏）。每个Hourglass module的结构都包含<strong>一个bottom-up过程和一个top-down过程</strong>，前者通过卷积和pooling将图片从高分辨率降到低分辨率，后者通过upsample将图片从低分辨率恢复到高分辨率。</p>
<p><img src="2DPE_pics/clip_image004.jpg" alt="图片包含 游戏机, 画, 桌子  描述已自动生成"></p>
<p>每个Hourglass module的结构如下图所示，其中每个box都是一个残差结构。可以看到在top-down阶段，对于两个<strong>相邻</strong>分辨率的feature map，我们通过upsampling（这里用的是nearest neighbor upsampling）对较低分辨率的feature map进行上采样，然后通过<strong>skip connection</strong>将bottom-up阶段较高分辨率的feature map拿过来，此时再通过element-wise addition将这两部分特征进行合并。通过这种方式，在top-down阶段将不同分辨率下的特征逐步进行了融合。</p>
<p><img src="2DPE_pics/clip_image005.jpg" alt="图片包含 游戏机, 桌子, 体育  描述已自动生成"></p>
<p>总而言之，Hourglass最大的特点就是能够<strong>提取并整合所有scale下的特征</strong>，这种设计的出发点也是出于我们在姿态估计时对各个不同scale下特征的需要。这种网络结构在当时达到了很好的效果。</p>
<p>值得注意的是，Hourglass也使用了intermediate supervision，对于multi-stage的网络这一点通常是必要的。</p>
<h3 id="CPN"><a href="#CPN" class="headerlink" title="CPN"></a>CPN</h3><p>CPN，Cascaded Pyramid Network，是2017年旷视提出的一种网络结构，获得了COCO 2017 Keypoint Benchmark的冠军，网络结构如下图所示。这个网络可以分为两部分：GlobalNet和RefineNet，从名字也可以看出<strong>后半部分网络是在前半部分的基础上做refinement</strong>。GlobalNet的作用主要是对关键点进行一个初步的检测，由于<strong>使用了强大的ResNet作为backbone</strong>，网络能够提取到较为丰富的特征（在此之前的CPM、Hourglass都没有使用，因此网络的特征提取能力较差），并且使用了FPN结构加强了特征提取，在这个过程中像head、eyes这些简单且可见的关键点基本能够被有效地定位。而对于GlobalNet没有检测到的关键点，使用RefineNet进行进一步的挖掘，RefineNet实际上是将pyramid结构中不同分辨率下的特征进行了一个整合，这样一些<strong>被遮挡的、难以定位</strong>的关键点，根据融合后的上下文语境信息能够更好的被定位到。</p>
<p><img src="2DPE_pics/clip_image006.jpg" alt="手机屏幕截图  描述已自动生成"></p>
<p>下面这张图给出了一个例子（绿点表示ground truth），对于eye来说较容易定位，通过GlobalNet即可定位到。而对于hip来说，在原图中被遮挡，仅仅使用GlobalNet难以直接精确定位。通过RefineNet将语境信息整合进来，才使得这些关键点被定位。</p>
<p><img src="2DPE_pics/clip_image007.jpg" alt="图片包含 游戏机, 画  描述已自动生成"></p>
<h3 id="Simple-Baselines"><a href="#Simple-Baselines" class="headerlink" title="Simple Baselines"></a>Simple Baselines</h3><p>Simple Baselines，是2018年MSRA的工作，网络结构如下图所示。之所以叫这个名字，是因为这个网络真的很简单。该网络就是在ResNet的基础上接了一个head，这个head仅仅包含几个<strong>deconvolutional layer</strong>，用于提升ResNet输出的feature map的分辨率，我们提到过多次高分辨率是姿态估计任务的需要。这里的deconvolutional layer是一种不太严谨的说法，阅读源代码可知，deconvolutional layer实际上是将<strong>transpose convolution、BatchNorm、ReLU</strong>封装成了一个结构。所以关键之处在于transpose convolution，可以认为是convolution的逆过程。</p>
<p>从图中看可以发现Simple Baselines的网络结构有点类似Hourglass中的一个module，但可以发现：①该网络没有使用类似Hourglass中的skip connection；②该网络是single-stage，Hourglass是multi-stage的。但令人惊讶的是，该网络的效果却超过了Hourglass。我个人认为有两点原因，一是Simple Baselines以ResNet作为backbone，特征提取能力相比Hourglass更强。二是Hourglass中上采样使用的是简单的nearest neighbor upsampling，而这里使用的是deconvolutional layer，后者的效果更好（后面可以看到在MSRA的Higher-HRNet中依旧使用了这种结构）。</p>
<p><img src="2DPE_pics/clip_image008.jpg" alt="图片包含 游戏机, 画, 钟表  描述已自动生成"></p>
<h3 id="HRNet"><a href="#HRNet" class="headerlink" title="HRNet"></a>HRNet</h3><p>HRNet，是2019年MSRA的工作，网络结构如下图所示，这个网络结构和之前的相比还是很novel的。我们知道，要想准确定位关键点，既离不开高分辨率的表示，也离不开低分辨率的语义信息。之前提到的几种网络结构也都着力于充分利用多个分辨率的信息，但之前的网络比如Hourglass、Simple Baselines，都是经历了一个先bottom-up再top-down的过程，换言之，我们得到的高分辨率的feature map都是从低分辨率的feature map经过upsampling/deconvolution恢复过来的，这样总会有一些潜在的信息丢失。HRNet的最大特点就是将不同分辨率feature map之间的连接<strong>从串行改成了并行</strong>，从图中可以清楚的看到，在整个过程中一直保持高分辨率分支的存在，并且随着网络的深入，逐渐添加低分辨率的分支，最后网络结构就是同时<strong>保持多个分辨率分支的并行网络</strong>。</p>
<p><img src="2DPE_pics/clip_image009.jpg" alt="图片包含 游戏机  描述已自动生成"></p>
<p>此外非常重要的一点，从图中我们也可以看到，为了使不同分辨率之间的信息融合在一起，从而获得包含多个分辨率下信息的feature map，在相邻的stage之间（每添加一个新的低分辨率分支时视为一个新stage的开始）加了<strong>fusion</strong>结构，fusion直观上类似在两边的feature maps之间加了一个fc层，下采样通过多个 卷积，上采样就是简单的nearest neighbor upsampling。这里的融合就是简单的累加。通过多次fusion，最后得到的feature map包含的信息是非常丰富的，也因此HRNet达到了很好的效果。</p>
<p><img src="2DPE_pics/clip_image010.jpg" alt="图片包含 游戏机, 钟表  描述已自动生成"></p>
<p>值得一提的是，MSRA后来在HRNet上做了一点微小的改动，称为HRNetv2。HRNetv1输出的feature map(heatmap)是最后一层最高分辨率的feature map，HRNetv2输出的feature map(heatmap)是最后一层所有分辨率的feature map变换scale后concat在一起。之后他们将该任务应用到了object detection、semantic segmentation、facial landmark detection等其他多个任务上，在许多数据集上达到了SOTA。</p>
<h3 id="MSPN"><a href="#MSPN" class="headerlink" title="MSPN"></a>MSPN</h3><p>MSPN，是2019年旷视的工作，网络结构如下图所示。此前我们介绍的网络中，有single-stage的例如CPN、Simple Baselines，也有multi-stage的如CPM、Hourglass，理论上multi-stage的效果应该更好，但实际上在COCO数据集上single-stage的表现超过了multi-stage。MSPN沿用了multi-stage的思路，并做出了一系列改进，最终使得MSPN的效果超过了当前的single-stage网络。</p>
<p>首先，对于每个stage的module，MSPN采用了前面提到的CPN中的GlobalNet（backbone为ResNet），当然这里使用其他backbone也没问题。其次，MSPN增加了跨阶段的特征融合，即图中的黄色箭头。由于经过反复的下采样-上采样，会有不可避免的信息损失，故MSPN中将前一个stage下采样和上采样过程中对应分辨率的两个feature maps都连接过来，与当前stage下采样的feature map进行融合，这样当前stage得到的feature map就包含了更多prior information，减少了stage之间的信息丢失。此外，这种类似残差结构的设计也有助于缓解梯度消失问题。最后，MSPN还采用了<strong>coarse-to-fine supervision</strong>，我们知道姿态估计的ground truth是以关键点为中心的二维高斯分布，这里的高斯核大小是一个超参数。直观上来说，对于multi-stage网络，随着stage的增加，我们对keypoint的估计是一个coarse-to-fine的过程，这样我们进行intermediate supervision的时候，可以将ground truth也设置成coarse-to-fine的heatmap，也就是前面stage的高斯核较大，后面stage的高斯核较小，随着stage的增加要求关键点位置越来越精确。</p>
<p><img src="2DPE_pics/clip_image011.jpg" alt="手机屏幕截图  描述已自动生成"></p>
<h2 id="Bottom-up"><a href="#Bottom-up" class="headerlink" title="Bottom-up"></a>Bottom-up</h2><p>前面我们提到诸多top-down的方法都是将多人姿态估计转化为单人姿态估计问题，但在进行多人姿态估计时，top-down的方法有两个缺点：①<strong>性能受到detector性能的影响</strong>（虽然在CPN的论文中证明了当detector性能足够好时提高detector的性能对最后的结果提高很微小）；②<strong>运行时间随着图片中人数增加而增加</strong>。而bottom-up的方法则是另一条思路：先检测出图中所有人的所有关键点，再对关键点进行分组，进而组装成多个人。这种方法的好处是性能受人数影响较小，实际上bottom-up的速度往往会比top-down的更快，几乎能做到real-time，在移动端部署的时候往往采用的也是bottom-up的方法。接下来介绍近年出现的一些有代表性的bottom-up的工作。</p>
<h3 id="Openpose"><a href="#Openpose" class="headerlink" title="Openpose"></a>Openpose</h3><p>Openpose是2016年CMU的一个工作，获得了COCO 2016 Keypoints challenge的冠军，这个工作在后来产生了很大的影响，github上目前有15.8k个stars。下图是openpose的pipeline，首先根据输入图片(a)生成一个<strong>Part Confidence Maps</strong>(b)和一个<strong>Part Affinity Fields</strong>(c)：前者就是我们上文常提到的heatmap，用来预测关键点的位置；后者是本文的一个主要创新点）——PAF，PAF实际上是在关键点之间建立的一个向量场，描述一个limb的方向。有了heatmap和PAF，我们使用二分图最大权匹配算法来对关键点进行组装(d)，从而得到人体骨架(e)。由于文字描述过于抽象，下面花一些篇幅引用原文中的一些数学表达形式来分别介绍这几部分。</p>
<p><img src="2DPE_pics/clip_image012.jpg" alt="图片包含 照片, 球, 球拍, 监控  描述已自动生成"></p>
<p>对于生成heatmap和PAF的部分，使用了下图所示的网络结构。首先 是初始的feature map，网络的输出是heatmap和PAF，分别用 和 表示，其中 是part(即上文中的keypoint，这里遵循原文中的说法)的数量， 是limb的数量。 ，即第 个part对应的heatmap，每个pixel对应一个响应值，可以认为是概率值； ，即第 个limb对应的PAF，每个pixel对应一个二维向量，表示该pixel所在limb的方向。二者都是pixel-wise的。这里借鉴CPM使用了多个stage不断进行<strong>refinement</strong>，后一阶段的输入是前一阶段的 、 和初始的 的结合。</p>
<p><img src="2DPE_pics/clip_image013.jpg" alt="手机屏幕截图  描述已自动生成"></p>
<p>接下来需要说明heatmap和PAF的ground truth分别是怎样的。heatmap和top-down中的类似，对于第 个人的第 个part，令其位置为 ，则ground truth是以 为中心的二维高斯分布，用 表示。在这里由于一张图片中有多个人，ground truth中的每个channel对应一个part，第 个part对应的ground truth为 ， 表示单个位置，即对所有人该part的ground truth按pixel取<strong>max</strong>。</p>
<p>PAF的ground truth则更加复杂，对于第 个人的第 个limb（连接关键点 和 ），ground truth用 表示。如果位置 在这个limb上， ，否则为零向量。这里 实际上是 指向 的单位向量。那么如何判断一个位置 是否在当前limb上呢？只要 满足：①在线段 上，②距离线段 在一个阈值范围内（框处了一个矩形范围），就认为 在该limb上。最后对于某个limb的所有，按pixel采用<strong>average</strong>进行处理，即 ，这里 为 位置处非零向量的个数，也就是只有非零向量才参与均值计算。此处用到的一些符号在图中含义如下。</p>
<p><img src="2DPE_pics/clip_image014.jpg" alt="图片包含 游戏机, 刀  描述已自动生成"></p>
<p>至于loss的计算，就是对每个stage的 和 分别计算L2 loss，最后所有stage的loss相加即可。同样类似之前top-down中提到的，intermediate supervision有助于缓解梯度消失的问题。</p>
<p>现在我们有了heatmap，在heatmap上采用<strong>nms</strong>可以为每个part找出一系列候选点（因为图中有不止一个人，以及false positive的点），这些候选点之间互相组合能够产生大量可能的limb，如何从中选出真正的limb，这就需要使用我们预测的PAF。首先定义两个关键点 和 之间组合的权值 ，这里 ， 分别表示 的坐标。实际上就是<strong>对</strong> <strong>和</strong> <strong>间各点的PAF在线段</strong> <strong>上投影的积分</strong>，直观上说，如果线段上各点的PAF方向与线段的方向越一致， 就越大，那么这两个点组成一个limb的可能性就越大。</p>
<p>知道了如何计算两个候选点之间组合的权值，对于任意两个part对应的候选点集合，我们使用<strong>二分图最大权匹配算法</strong>即可给出一组匹配。但如果我们考虑所有part之间的PAF，这将是一个K分图最大权匹配问题，该问题是NP-Hard的。因此我们做一个简化，我们抽取人体骨架的一棵<strong>最小生成树</strong>，这样对每条树边连接的两个part采用二分图最大权匹配来求解，不同树边之间是互不干扰的。也就是将原问题<strong>划分成了若干个二分图最大权匹配问题</strong>，最后将每条树边对应的匹配集合组装在一起即可得到人体骨架。</p>
<p><img src="2DPE_pics/clip_image015.jpg" alt="图片包含 游戏机, 画, 钟表  描述已自动生成"></p>
<p>上述即openpose的整个pipeline，虽然看起来比较复杂，但许多想法都是围绕PAF展开的，毕竟PAF还是这篇文章最大的亮点。</p>
<h3 id="Hourglass-Associative-Embedding"><a href="#Hourglass-Associative-Embedding" class="headerlink" title="Hourglass+Associative Embedding"></a>Hourglass+Associative Embedding</h3><p>Associative embedding，是一种处理detection+grouping任务的方法。也就是先检测再组装的任务，比如多人姿态估计是检测出所有关键点再组装成多个人体，实例分割是先检测出所有像素点的语义类别再组装成多个实例。往往这类任务都是two-stage的，即先detection，再grouping。这篇文章的作者提出了一种新的思路：<strong>同时处理detection和grouping两个任务</strong>，这么做的初衷是因为detection和grouping两个任务之间本身密切相关，分成两步来先后处理可能会导致性能下降。作者将该方法应用到了Hourglass上，在当时达到了多人姿态估计任务的SOTA。</p>
<p>在单人姿态估计时，我们网络的输出是m个heatmap，m表示关键点数量。现在在之前的基础上多输出了m个associative embeddings。Associative embeddings实际上是给heatmap的每个值都<strong>额外嵌入一个vector作为一个tag</strong>用于标识所在的组，拥有相同tag的所有关键点我们将其划分为一组，也就是属于某一个人。下图是Hourglass+Associative embedding的示意图，Hourglass输出了m个detection heatmaps（灰色）和m个associative embeddings（蓝色），根据heatmaps上的响应值确定关键点的坐标，根据embeddings上的tag（下图中不同tag用不同颜色表示）确定哪些关键点属于同一个人。</p>
<p><img src="2DPE_pics/clip_image016.jpg" alt="卡通人物  描述已自动生成"></p>
<p>现在我们考虑ground truth，对于heatmaps来说和之前一样，不再赘述。对于embeddings来说实际上<strong>没有ground truth</strong>，因为<strong>tag的绝对值并不重要</strong>，只要保证同一个人的关键点tag相同，不同人的关键点tag之间互不相同即可。这里需要说明的是，tag虽然是一个vector，但vector的维数并不重要，实践证明1D vector已经足够（即一个实数）。为了使tag满足上述要求，我们需要设计一个loss来评价当前的tag是否符合实际的分组。用 表示第 个关键点对应的embeddings(tagging heatmap)， 表示人的数量， 表示关键点数量， 表示第 个人第 个关键点的坐标。我们定义第 个人的参考embeddings为 ，则loss定义为 。loss的前半部分使<strong>同一个人的所有embeddings尽量接近</strong>，后半部分 使<strong>不同人的embeddings间隔尽量增大</strong>。最后所有关键点的embeddings分布如下图所示。inference时将距离小于一定阈值的embeddings分为一组即可。</p>
<p><img src="2DPE_pics/clip_image017.jpg" alt="图片包含 游戏机  描述已自动生成"></p>
<h3 id="HigherHRNet"><a href="#HigherHRNet" class="headerlink" title="HigherHRNet"></a>HigherHRNet</h3><p>HigherHRNet，是微软在HRNet之后延续的一个工作。前面我们提到过HRNet在top-down的方法中表现的很好，是因为这种并行的结构使得最后的feature map能够包含各个分辨率的信息，尤其是对高分辨率信息保留的效果较之前提升尤为明显。在bottom-up的方法中，作者认为有两个问题需要解决：①<strong>scale variation</strong>，即图片中有各种scale的人，如果仅仅在一个分辨率的feature map下进行预测，难以保证每个scale的人的关键点都能被精确预测；②精确定位<strong>small person的关键点</strong>。之前一些网络在推理时使用<strong>multiscale evaluation</strong>，能够缓解问题①，但仍然无法解决问题②，对small person的预测不够精确。</p>
<p>HigherHRNet的思路是首先使用HRNet生成feature map（最高分辨率分支），然后接一个类似Simple Baselines中的deconvolution层，生成一个更高分辨率的feature map。显然，更高分辨率的feature map有助于更加<strong>精确地定位small person的关键点</strong>（实践证明接一层deconv. module足够）。在训练时，使用<strong>multi-resolution supervision</strong>，即对原图1/4和1/2大小的两个feature map同时进行监督，这样做是为了<strong>在训练时就使网络获得处理scale variation的能力</strong>，1/4的feature map主要处理大一些的人，1/2的feature map主要处理小一些的人，而不是在推理时依赖multiscale evaluation处理scale variation的问题。在推理时，使用<strong>multi-resolution heatmap aggregation</strong>，即将不同分辨率的heatmap取平均用于最后的预测，也是为了处理scale variation。</p>
<p><img src="2DPE_pics/clip_image018.jpg" alt="图片包含 游戏机  描述已自动生成"></p>
<p>前面仅仅讨论了如何生成一个准确且scale-aware的heatmap，对于grouping采用的也是上文提到的<strong>associative embedding</strong>。最后这个工作达到了SOTA，是目前bottom-up方法中性能最强劲的网络之一。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>·    Convolutional Pose Machines, Wei etc, CVPR 2016</p>
<p>·    Stacked Hourglass Networks for Human Pose Estimation, Newell etc, ECCV 2016</p>
<p>·    Cascaded Pyramid Network for Multi-Person Pose Estimation, Chen etc, CVPR 2017</p>
<p>·    Simple Baselines for Human Pose Estimation and Tracking, Xiao etc, ECCV 2018</p>
<p>·    Deep High-Resolution Representation Learning for Human Pose Estimation, Sun etc, CVPR 2019</p>
<p>·    Rethinking on Multi-Stage Networks for Human Pose Estimation, Li etc, Arxiv 2019</p>
<p>·    Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields, Cao etc, CVPR 2017</p>
<p>·    Associative Embedding: End-to-End Learning for Joint Detection and Grouping, Newell etc, NIPS 2017</p>
<p>·    Bottom-up Higher-Resolution Networks for Multi-Person Pose Estimation, Cheng etc, Arxiv 2019</p>
<p>编辑于 2020-02-03</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/04/17/%E9%9B%B6%E6%AC%A1%E5%AD%A6%E4%B9%A0%EF%BC%88Zero-Shot%20Learning%EF%BC%89%E5%85%A5%E9%97%A8/">
                零次学习（Zero-Shot Learning）入门
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-04-17</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="零次学习（Zero-Shot-Learning）入门"><a href="#零次学习（Zero-Shot-Learning）入门" class="headerlink" title="零次学习（Zero-Shot Learning）入门"></a>零次学习（Zero-Shot Learning）入门</h1><p>转载自 <a href="https://zhuanlan.zhihu.com/p/34656727" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34656727</a></p>
<p>很久没有更文章了，主要是没有找到zero-shot learning(ZSL)方面我特别想要分享的文章，且中间有一段时间在考虑要不要继续做这个题目，再加上我懒 (￢_￢)，所以一直拖到了现在。</p>
<p>最近科研没什么进展，就想着写一个ZSL的入门性的文章，目的是为了帮助完全没有接触过这方面，并有些兴趣的同学，能在较短的时间对ZSL有一定的认识，并且对目前的发展情况有一定的把握。</p>
<p>在此之前，需要提到的是：<strong>无论是论文笔记，还是总结性的读物，都包含了作者自己的理解和二次加工，想要做出好的工作必定需要自己看论文和总结。</strong></p>
<p><strong>零次学习</strong>（zero-shot learning）基本概念</p>
<p>每次在实验室做工作汇报的时候，总会把ZSL的基本概念讲一遍，但是每次的效果都不是很好，工作都讲完了，提的第一个问题依然是：ZSL到底是什么？这让我一度认为我的表达能力有问题。。。。。。不过回忆起我第一次接触这个题目的时候，也花了挺长的时间才搞清楚到底在做一件什么事情，那篇入门的文章[1]看了很久才基本看懂。因此，我尽量用最简单的，不带任何公式的方式来讲一下这到底是个什么问题。</p>
<p>假设小暗（纯粹因为不想用小明）和爸爸，到了动物园，看到了马，然后爸爸告诉他，这就是马；之后，又看到了老虎，告诉他：“看，这种身上有条纹的动物就是老虎。”；最后，又带他去看了熊猫，对他说：“你看这熊猫是黑白色的。”然后，爸爸给小暗安排了一个任务，让他在动物园里找一种他从没见过的动物，叫斑马，并告诉了小暗有关于斑马的信息：“斑马有着马的轮廓，身上有像老虎一样的条纹，而且它像熊猫一样是黑白色的。”最后，小暗根据爸爸的提示，在动物园里找到了斑马（意料之中的结局。。。）。</p>
<p>上述例子中包含了一个人类的推理过程，就是利用过去的知识（马，老虎，熊猫和斑马的描述），在脑海中推理出新对象的具体形态，从而能对新对象进行辨认。（如图1所示）ZSL就是希望能够模仿人类的这个推理过程，使得计算机具有识别新事物的能力。</p>
<p><img src="ZSL_pics/clip_image002.jpg" alt="社交网络的地图  描述已自动生成">图1 ZSL概念图[17]</p>
<p>如今深度学习非常火热，使得纯监督学习在很多任务上都达到了让人惊叹的结果，但其限制是：往往需要足够多的样本才能训练出足够好的模型，并且利用猫狗训练出来的分类器，就只能对猫狗进行分类，其他的物种它都无法识别。这样的模型显然并不符合我们对人工智能的终极想象，我们希望机器能够像上文中的小暗一样，具有通过推理，识别新类别的能力。</p>
<p>ZSL就是希望我们的模型能够对其从没见过的类别进行分类，让机器具有推理能力，实现真正的智能。其中零次（Zero-shot）是指对于要分类的类别对象，一次也不学习。这样的能力听上去很具有吸引力，那么到底是怎么实现的呢？</p>
<p>假设我们的模型已经能够识别马，老虎和熊猫了，现在需要该模型也识别斑马，那么我们需要像爸爸一样告诉模型，怎样的对象才是斑马，但是并不能直接让模型看见斑马。所以模型需要知道的信息是马的样本、老虎的样本、熊猫的样本和样本的标签，以及关于前三种动物和斑马的描述。将其转换为常规的机器学习，这里我们只讨论一般的图片分类问题：</p>
<p>（1）训练集数据 及其标签 ，包含了模型需要学习的类别（马、老虎和熊猫），这里和传统的监督学习中的定义一致；</p>
<p>（2）测试集数据 及其标签 ，包含了模型需要辨识的类别（斑马），这里和传统的监督学习中也定义一直；</p>
<p>（3）训练集类别的描述 ，以及测试集类别的描述 ；我们将每一个类别 ，都表示成一个语义向量 的形式，而这个语义向量的每一个维度都表示一种高级的属性，比如“黑白色”、“有尾巴”、“有羽毛”等等，当这个类别包含这种属性时，那在其维度上被设置为非零值。对于一个数据集来说，语义向量的维度是固定的，它包含了能够较充分描述数据集中类别的属性。</p>
<p>在ZSL中，我们希望利用 和 来训练模型，而模型能够具有识别 的能力，因此模型需要知道所有类别的描述 和 。ZSL这样的设置其实就是上文中小暗识别斑马的过程中，爸爸为他提供的条件。</p>
<p><img src="ZSL_pics/clip_image003.jpg" alt="图片包含 游戏机, 文字, 画  描述已自动生成">图2 ZSL设置图[16]</p>
<p>如图2，可以较为直观地了解ZSL的设置。</p>
<p>讲到这，很多同学可能会问：</p>
<p>（1）类别的描述 到底是怎么获取的？</p>
<p>答：有人工专家定义的，也有通过海量的附加数据集自动学习出来的，但前者的效果目前要好很多。</p>
<p>（2）这样做让人觉得有点失望呀！我希望模型能够在没有斑马样本的情况下，识别斑马，而现在，虽然我不需要为模型提供斑马的样本，但是却要为每一个类别添加一种描述，更离谱的是我还需要斑马（测试集）的描述，这个过程并没有想象中智能诶！</p>
<p>答：的确，在我们的想象中，我们期待的智能是：只给机器马、老虎和熊猫，然后它就可以识别斑马了，这样多爽，多神奇。但我们回过头去，再想想小暗的思考过程，如果爸爸不告诉小暗关于斑马的任何信息，那么当小暗看见斑马的时候，并不会知道它是什么，只是小暗能够描述它：“这是一匹有着黑白颜色条纹的马。”这里，有同学可能又会说：至少我们可以不用告诉小暗类别的描述呀，但是ZSL就不行。其实，我们是需要告诉小暗类别描述的，或者说小暗在之前就学习到了类别描述，比如怎样的图案是“条纹”，怎样的颜色称为“黑白色”，这样的属性定义。对于一个模型来说，它就像刚出生的婴儿，我们需要教会它这些属性的定义。</p>
<p>（3）就算是这样，需要实现定义这个描述 还是很蛋疼的一件事情。</p>
<p>答：（1）中就有提到，描述 可以自动学习，我们将小暗已经掌握的知识描述为一个知识库，这个知识库里就有对各种属性的定义；而能够模仿人类知识库的最好东西就是“百度百科”，“维基百科”等等各种百科，我们可以利用百科中的各种定义，生成类别的定义，这方面侧重于NLP，因此不进一步讨论。</p>
<p>在此，我们小小总结一下ZSL问题的定义。<strong>利用训练集数据训练模型，使得模型能够对测试集的对象进行分类，但是训练集类别和测试集类别之间没有交集；期间需要借助类别的描述，来建立训练集和测试集之间的联系，从而使得模型有效</strong>。</p>
<p><strong>目前的研究方式</strong></p>
<p>在上文中提到，要实现ZSL功能似乎需要解决两个部分的问题：第一个问题是获取合适的类别描述 ；第二个问题是建立一个合适的分类模型。</p>
<p>目前大部分工作都集中在第二个问题上，而第一个问题的研究进展比较缓慢。个人认为的原因是， 目前 的获取主要集中于一些NLP的方法，而且难度较大；而第二个问题能够用的方法较多，比较容易出成果。</p>
<p>因此，接下来的算法部分，也只介绍研究分类模型的方法。</p>
<p><strong>数据集介绍</strong></p>
<p>先介绍数据集，是因为希望在算法介绍部分，直接给出实例，让大家能够直接上手，这里顺便插个沐神 </p>
<p><a href="https://www.zhihu.com/people/13fd0fce2affd948bfd821a8f7ed10f3" target="_blank" rel="noopener">@李沐</a></p>
<p> 的感悟。</p>
<p>虽然在我认识的人里，好些人能够读一篇论文或者听一个报告后就能问出很好的问题，然后就基本弄懂了。但我在这个上笨很多。读过的论文就像喝过的水，第二天就不记得了。一定是需要静下心来，从头到尾实现一篇，跑上几个数据，调些参数，才能心安地觉得懂了。例如在港科大的两年读了很多论文，但现在反过来看，仍然记得可能就是那两个老老实实动手实现过写过论文的模型了。即使后来在机器学习这个方向又走了五年，学习任何新东西仍然是要靠动手。——李沐（MXNet开发者）</p>
<p>（1）<strong>Animal with Attributes（AwA）</strong>官网：<a href="https://link.zhihu.com/?target=https%3A//cvml.ist.ac.at/AwA/">Animals with Attributes</a></p>
<p>提出ZSL定义的作者，给出的数据集，都是动物的图片，包括50个类别的图片，其中40个类别作为训练集，10个类别作为测试集，每个类别的语义为85维，总共有30475张图片。但是目前由于版权问题，已经无法获取这个数据集的图片了，作者便提出了AwA2，与前者类似，总共37322张图片。</p>
<p>（2）<strong>Caltech-UCSD-Birds-200-2011（CUB）</strong>官网：<a href="https://link.zhihu.com/?target=http%3A//www.vision.caltech.edu/visipedia/CUB-200-2011.html">Caltech-UCSD Birds-200-2011</a></p>
<p>全部都是鸟类的图片，总共200类，150类为训练集，50类为测试集，类别的语义为312维，有11788张图片。</p>
<p>（3）<strong>Sun database（SUN）</strong>官网：<a href="https://link.zhihu.com/?target=http%3A//groups.csail.mit.edu/vision/SUN/">SUN Database</a></p>
<p>总共有717个类别，每个类别20张图片，类别语义为102维。传统的分法是训练集707类，测试集10类。</p>
<p>（4）<strong>Attribute Pascal and Yahoo dataset（aPY）</strong>官网：<a href="https://link.zhihu.com/?target=http%3A//vision.cs.uiuc.edu/attributes/">Describing Objects by their Attributes</a></p>
<p>共有32个类，其中20个类作为训练集，12个类作为测试集，类别语义为64维，共有15339张图片。</p>
<p>（5）<strong>ILSVRC2012/ILSVRC2010（ImNet-2）</strong></p>
<p>利用ImageNet做成的数据集，由ILSVRC2012的1000个类作为训练集，ILSVRC2010的360个类作为测试集，有254000张图片。它由 4.6M 的Wikipedia数据集训练而得到，共1000维。</p>
<p>上述数据集中（1）-（4）都是较小型（small-scale）的数据集，（5）是大型（large-scale）数据集。虽然（1）-（4）已经提供了人工定义的类别语义，但是有些作者也会从维基语料库中自动提取出类别的语义表示，来检测自己的模型。</p>
<p>这里给大家提供一些已经用GoogleNet提取好的数据集图片特征，大家可以比较方便地使用。<a href="https://zhuanlan.zhihu.com/p/29807635" target="_blank" rel="noopener">Zero-Shot Learing问题数据集分享（GoogleNet 提取）</a></p>
<p><strong>基础算法介绍</strong></p>
<p>在此，只具体介绍最简单的方法，让大家可以快速上手。我们面对的是一个图片分类问题，即对测试集的样本 进行分类，而我们分类时需要借助类别的描述 ，由于每一个类别 ，都对应一个语义向量 ，因此我们现在可以忘掉 ，直接使用 。我们把 （利用深度网络提取的图片特征，比如GoogleNet提取为1024维）称为特征空间（visual feature space），把类别的语义表示 ，称为语义空间。<strong>我们要做的，其实就是建立特征空间与语义空间之间的映射</strong>。</p>
<p>对于分类，我们能想到的最简单的形式就是岭回归（ridge regression），俗称均方误差加范数约束，具体形式为：</p>
<p> (1)</p>
<p>其中， 通常为2范数约束， 为超参，对 求导，并让导为0，即可求出 的值。测试时，利用 将 投影到语义空间中，并在该空间中寻找到离它最近的 ，则样本的类别为 所对应的标签 。</p>
<p>简单写一个matlab实现。</p>
<p>regression_lambda = 1.0;</p>
<p>W = ridge_regression(param.train_set, param.train_class_attributes, regression_lambda , 1024);</p>
<p>S_test = param.test_set * W;</p>
<p>[zsl_accuracy]= zsl_el(S_test, param.S_te, param); </p>
<p>fprintf(‘AwA ZSL accuracy on test set: %.1f%%\n’, zsl_accuracy*100);</p>
<p>我们使用AwA数据集，图片事先利用GoogleNet提取了特征（1024维），在测试集上可以得到59.1%的准确率。</p>
<p>这样一个岭回归之所以有效，是因为训练集类别语义 与测试集类别语义 之间存在的密切联系。其实任何ZSL方法有效的基础，都是因为这两者之间具体的联系。</p>
<p>仅仅利用如此naive的方式，得到的结果显然不能满足我们的要求，那么建立更好的模型，则需要进一步了解ZSL问题中，存在着哪些和传统监督分类的差异。</p>
<p><strong>ZSL中存在的问题</strong></p>
<p>在此，介绍一些目前ZSL中主要存在的问题，以便让大家了解目前ZS领域有哪些研究点。</p>
<p><strong>领域漂移问题（domain shift problem）</strong></p>
<p>该问题的正式定义首先由[2]提出。简单来说，就是同一种属性，在不同的类别中，视觉特征的表现可能很大。如图3所示，斑马和猪都有尾巴，因此在它的类别语义表示中，“有尾巴”这一项都是非0值，但是两者尾巴的视觉特征却相差很远。如果斑马是训练集，而猪是测试集，那么利用斑马训练出来的模型，则很难正确地对猪进行分类。</p>
<p><img src="ZSL_pics/clip_image004.jpg" alt="手机屏幕截图  描述已自动生成">图3 domain shift示意图，图中的prototype表示类别在语义空间中的位置[2]</p>
<p><strong>枢纽点问题（Hubness problem）</strong></p>
<p>这其实是高维空间中固有的问题：在高维空间中，某些点会成为大多数点的最近邻点。这听上去有些反直观，细节方面可以参考[3]。由于ZSL在计算最终的正确率时，使用的是K-NN，所以会受到hubness problem的影响，并且[4]中，证明了基于岭回归的方法会加重hubness problem问题。</p>
<p><strong>语义间隔（semantic gap）</strong></p>
<p>样本的特征往往是视觉特征，比如用深度网络提取到的特征，而语义表示却是非视觉的，这直接反应到数据上其实就是：样本在特征空间中所构成的流型与语义空间中类别构成的流型是不一致的。（如图4所示）</p>
<p><img src="ZSL_pics/clip_image005.jpg" alt="图片包含 游戏机, 钟表, 画  描述已自动生成">图4 流型不一致示意图[8]</p>
<p>这使得直接学习两者之间的映射变得困难。</p>
<p>还有其他的，比如semantic loss[5]问题，样本通过映射坍塌到一点[6]等，由于还不常研究，在此就不再讨论。</p>
<p>在此，我们给出解决上述三个问题的基本方法，从而更加深度地了解这三个问题。</p>
<p>（1）领域漂移</p>
<p>由于样本的特征维度往往比语义的维度大，所以建立从 到 的映射往往会丢失信息，为了保留更多的信息，保持更多的丰富性，最流行的做法是将映射到语义空间中的样本，再重建回去，这样学习到的映射就能够得到保留更多的信息。因此，在原来简单岭回归[1]的基础上，可以将目标函数改为：[7]</p>
<p> (2)</p>
<p>从目标函数可以看出，这其实完成的是一个简易的自编码器过程，我们简称这个算法为SAE，利用matlab可以轻松对其实现。</p>
<p>lambda1 = 800000;</p>
<p>W = SAE(param.train_set’, param.train_class_attributes’, lambda1);</p>
<p>S_test = param.test_set * NormalizeFea(W’);</p>
<p>[zsl_accuracy]= zsl_el(S_test, param.S_te, param); </p>
<p>fprintf(‘AwA ZSL accuracy on test set: <em>%.1f%%\n’, zsl_accuracy*100);</em></p>
<p>依然是在AwA上进行测试，可以得到83.2%的准确率，比简单的岭回归(1)提高了24.1%。自编码器的这个结构目前在ZSL方法中非常流行，稍后我们还会提到。</p>
<p>（2）枢纽点问题</p>
<p>目前对于枢纽点问题的解决主要有两种方法：</p>
<p>a. 如果模型建立的方式为岭回归，那么可以建立从语义空间到特征空间的映射，从而不加深hubness problem对结果的影响[4]，也就是说将目标函数（1）改为：</p>
<p> (3)</p>
<p>在AwA数据集上，这种简单的改变能够得到76.5%的正确率，比原本提高了17.4%。</p>
<p>b.可以使用生成模型，比如自编码器、GAN等，生成测试集的样本，这样就变成了一个传统的监督分类问题，不存在K-NN的操作，所以不存在hubness problem的影响。</p>
<p>（3）语义间隔问题</p>
<p>语义间隔问题的本质是二者的流形结构不一致，因此，解决此问题的着手点就在于将两者的流形调整到一致，再学习两者之间的映射[8]。最简单的方法自然是将类别的语义表示调整到样本的流型上，即用类别语义表示的K近邻样本点，重新表示类别语义即可。</p>
<p><strong>有关ZSL的一些其他的概念</strong></p>
<p>这里将提到一些ZSL涉及到的其他概念。</p>
<p>（1）直推式学习（Transductive setting）</p>
<p>这里的直推式学习其实是指在训练模型的时候，我们可以拿到测试集的数据，只是不能拿到测试集的样本的标签，因此我们可以利用测试集数据，得到一些测试集类别的先验知识。这种设置在迁移学习中很常见。</p>
<p><img src="ZSL_pics/clip_image006.jpg" alt="图片包含 游戏机, 文字  描述已自动生成">图5 非直推式（inductive）和直推式学习的区别[16]</p>
<p>（2）泛化的ZSL（generalized ZSL）</p>
<p>上文中提到的ZSL，在测试时使用K-NN进行正确率的评估时，只在测试类别中找最近邻的类别，但是在现实的问题中，拿到的样本也可能属于训练集类别，因此在测试时，同时加入训练集类别。[9]现在的很多方法都开始测试模型在这种设置下的能力。</p>
<p><strong>推荐阅读的论文</strong></p>
<p>我一直不想写ZSL的发展史，因为据我的经验，写了一大段发展史之后，往往大家的兴致不高，而且看完之后一般都不会有什么特别的感觉，基本也记不得什么东西。所以倒不如给大家推荐一些论文，从最早的到目前最新的，使得大家在短时间内能对ZSL的发展有一个大概的概念。</p>
<p>（1）Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer[1]</p>
<p>ZSL问题的开创性文章，当然是必读的喽，而且可以顺便看看别人是如何阐述一个新问题（挖坑）的。</p>
<p>（2）An embarrassingly simple approach to zero-shot learning[10]</p>
<p>有着很强的理论基础，算法简单、有效，虽然已经过去很多年了，但还是目前新工作需要进行对比的方法之一。</p>
<p>（3）Transductive Multi-View Zero-Shot Learning[2]</p>
<p>第一次定义了domain shift问题。</p>
<p>（4）Zero-shot recognition using dual visualsemantic mapping paths[11]</p>
<p>解决semantic gap问题的简单做法。</p>
<p>（5）Predicting visual exemplars of unseen classes for zero-shot learning[12]</p>
<p>从本质的角度出发，将ZSL问题，看作聚类问题，用最简单的方法直接建立映射。</p>
<p>（6）Semantic Autoencoder for Zero-Shot Learning[7]</p>
<p>引入自编码器结构的第一篇文章，直接导致现在出现的新方法大都具有这种结构。</p>
<p>（7）Zero-Shot Learning - A Comprehensive Evaluation of the Good, the Bad and the Ugly[14]</p>
<p>综述性的文章，总结了17年底以前的方法，提出了新的评价标准，对当时领域发展比较混乱的地方做出了一些更标准的评估。</p>
<p>（8）Zero-Shot Learning via Class-Conditioned Deep Generative Models[6]</p>
<p>将[7]改造为深度模型，并加上一些其他的约束。</p>
<p>（9）Preserving Semantic Relations for Zero-Shot Learning[13]</p>
<p>在自编码器结构的基础上，显示地加入语义类别之间的关系约束。</p>
<p>（10）Recent Advances in Zero-shot Recognition[15]</p>
<p>综述性的文章，读起来很顺畅，可以看看别人是怎么写综述，中顶刊的。</p>
<p>以上几篇文章，是我认为较有代表性，比较值得读的工作。</p>
<p><strong>代码</strong></p>
<p>有很多工作，作者都是提供代码的，我自己也实现了一些工作，如果有时间我会将其整理在一起，方便大家使用。</p>
<p><strong>我自己的看法</strong></p>
<p>我当初做这个课题，纯粹是因为项目的需要，再加上当时并没有想清楚自己要做什么，所以就做着试试了。目前这个领域属于很好发论文的阶段，而且并不需要十分深刻的理解，就能发不错等级的文章，比较容易能够看到它的发展趋势及下一步大家扎堆的地方，很多时候是在拼速度，而不是拼想法。但好发论文，并不代表它发展迅速，在我看来，真正有贡献的工作少之又少，且其对本质的研究发展缓慢。并且，该问题离实际应用还太远，很可能并不属于这个时代。基于这些原因，之前有一段时间很不想再继续这个课题。。。</p>
<p><strong>总结</strong></p>
<p>稍微总结一下，其实我也不知道要总结什么，只是习惯了每篇文章最后都要写个总结。花了大概一天的时间，写了这篇ZSL入门文章。写它一方面是因为希望能够有一篇ZSL的入门性质的读物，为大家提供便利；另一方面就是近期科研不顺，总是怀疑自己不是读书的料，写写文章让自己心情好些。希望大家阅读之后，能够得到一定的帮助吧！</p>
<p><strong>其他</strong></p>
<p>文章仓促之下写的，没有经过什么构思，就是想到哪，写到哪。后面我应该还会修改，添加一些其他的内容，如果大家有什么问题，欢迎评论或者私信。</p>
<p>祝大家科研顺利！为人类理解这个世界做一点点贡献！</p>
<p><strong>参考文献</strong></p>
<p>[1]Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer</p>
<p>[2]Transductive Multi-View Zero-Shot Learning.</p>
<p>[3]Hubness and Pollution: Delving into Class-Space Mapping for Zero-Shot Learning.</p>
<p>[4]Ridge Regression, Hubness, and Zero-Shot Learning.</p>
<p>[5]Zero-Shot Visual Recognition using Semantics-Preserving Adversarial Embedding Network.</p>
<p>[6]Zero-Shot Learning via Class-Conditioned Deep Generative Models.</p>
<p>[7]Semantic Autoencoder for Zero-Shot Learning.</p>
<p>[8]Zero-Shot Recognition using Dual Visual-Semantic Mapping Paths.</p>
<p>[9]An Empirical Study and Analysis of Generalized Zero-Shot Learning for Object Recognition in the Wild.</p>
<p>[10]An embarrassingly simple approach to zero-shot learning</p>
<p>[11]Zero-shot recognition using dual visualsemantic mapping paths</p>
<p>[12]Predicting visual exemplars of unseen classes for zero-shot learning</p>
<p>[13]Preserving Semantic Relations for Zero-Shot Learning</p>
<p>[14]Zero-Shot Learning - A Comprehensive Evaluation of the Good, the Bad and the Ugly</p>
<p>[15]Recent Advances in Zero-shot Recognition</p>
<p>[16]<a href="https://link.zhihu.com/?target=http%3A//people.duke.edu/~ww107/material/ZSL.pdf">http://people.duke.edu/~ww107/material/ZSL.pdf</a></p>
<p>[17]Attribute-Based Synthetic Network (ABS-Net): Learning More From Pseudo Feature Representation</p>
<p>编辑于 2018-04-17</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/04/13/LaTeX%E5%85%AC%E5%BC%8F%E6%89%8B%E5%86%8C(%E5%85%A8%E7%BD%91%E6%9C%80%E5%85%A8)/">
                LaTeX公式手册(全网最全)
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-04-13</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="LaTeX公式手册-全网最全"><a href="#LaTeX公式手册-全网最全" class="headerlink" title="LaTeX公式手册(全网最全)"></a><a href="https://www.cnblogs.com/1024th/p/11623258.html" target="_blank" rel="noopener">LaTeX公式手册(全网最全)</a></h1><blockquote>
<p>参考维基百科的<a href="https://zh.wikipedia.org/wiki/Help:数学公式" target="_blank" rel="noopener">数学公式教程</a><br>参考<a href="https://www.zybuluo.com/codeep/note/163962#七交换图表使用参考" target="_blank" rel="noopener">Cmd Markdown 公式指导手册</a></p>
</blockquote>
<p>本文为 MathJax 在 Markdown 环境下的语法指引。</p>
<h2 id="如何插入公式"><a href="#如何插入公式" class="headerlink" title="如何插入公式#"></a>如何插入公式<a href="https://www.cnblogs.com/1024th/p/11623258.html#2137547647" target="_blank" rel="noopener">#</a></h2><p>𝐿𝐴𝑇𝐸𝑋LATEX 的数学公式有两种：行中公式和独立公式（行间公式）。行中公式放在文中与其它文字混编，独立公式单独成行。</p>
<p>行中公式可以用如下方法表示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ 数学公式 $</span><br></pre></td></tr></table></figure>

<p>独立公式可以用如下方法表示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$ 数学公式 $$</span><br></pre></td></tr></table></figure>

<h2 id="函数、符号及特殊字符"><a href="#函数、符号及特殊字符" class="headerlink" title="函数、符号及特殊字符#"></a>函数、符号及特殊字符<a href="https://www.cnblogs.com/1024th/p/11623258.html#2021782392" target="_blank" rel="noopener">#</a></h2><h3 id="声调-变音符号"><a href="#声调-变音符号" class="headerlink" title="声调 / 变音符号#"></a>声调 / 变音符号<a href="https://www.cnblogs.com/1024th/p/11623258.html#3048523243" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\dot&#123;a&#125;, \ddot&#123;a&#125;, \acute&#123;a&#125;, \grave&#123;a&#125;</span><br></pre></td></tr></table></figure>

<p>𝑎˙,𝑎¨,𝑎́ ,𝑎̀ a˙,a¨,a´,a`</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\check&#123;a&#125;, \breve&#123;a&#125;, \tilde&#123;a&#125;, \bar&#123;a&#125;</span><br></pre></td></tr></table></figure>

<p>𝑎ˇ,𝑎˘,𝑎̃ ,𝑎¯aˇ,a˘,a~,a¯</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\hat&#123;a&#125;, \widehat&#123;a&#125;, \vec&#123;a&#125;</span><br></pre></td></tr></table></figure>

<p>𝑎̂ ,𝑎ˆ,𝑎⃗ a^,a^,a→</p>
<h3 id="标准函数"><a href="#标准函数" class="headerlink" title="标准函数#"></a>标准函数<a href="https://www.cnblogs.com/1024th/p/11623258.html#1169873504" target="_blank" rel="noopener">#</a></h3><p>指数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\exp_a b &#x3D; a^b, \exp b &#x3D; e^b, 10^m</span><br></pre></td></tr></table></figure>

<p>exp𝑎𝑏=𝑎𝑏,exp𝑏=𝑒𝑏,10𝑚expa⁡b=ab,exp⁡b=eb,10m</p>
<p>对数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\ln c, \lg d &#x3D; \log e, \log_&#123;10&#125; f</span><br></pre></td></tr></table></figure>

<p>ln𝑐,lg𝑑=log𝑒,log10𝑓ln⁡c,lg⁡d=log⁡e,log10⁡f</p>
<p>三角函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\sin a, \cos b, \tan c, \cot d, \sec e, \csc f</span><br></pre></td></tr></table></figure>

<p>sin𝑎,cos𝑏,tan𝑐,cot𝑑,sec𝑒,csc𝑓sin⁡a,cos⁡b,tan⁡c,cot⁡d,sec⁡e,csc⁡f</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\arcsin a, \arccos b, \arctan c</span><br></pre></td></tr></table></figure>

<p>arcsin𝑎,arccos𝑏,arctan𝑐arcsin⁡a,arccos⁡b,arctan⁡c</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\arccot d, \arcsec e, \arccsc f</span><br></pre></td></tr></table></figure>

<p>arccot𝑑,arcsec𝑒,arccsc𝑓arccot⁡d,arcsec⁡e,arccsc⁡f</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\sinh a, \cosh b, \tanh c, \coth d</span><br></pre></td></tr></table></figure>

<p>sinh𝑎,cosh𝑏,tanh𝑐,coth𝑑sinh⁡a,cosh⁡b,tanh⁡c,coth⁡d</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\operatorname&#123;sh&#125;k, \operatorname&#123;ch&#125;l, \operatorname&#123;th&#125;m, \operatorname&#123;coth&#125;n</span><br></pre></td></tr></table></figure>

<p>sh𝑘,ch𝑙,th𝑚,coth𝑛sh⁡k,ch⁡l,th⁡m,coth⁡n</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\operatorname&#123;argsh&#125;o, \operatorname&#123;argch&#125;p, \operatorname&#123;argth&#125;q</span><br></pre></td></tr></table></figure>

<p>argsh𝑜,argch𝑝,argth𝑞argsh⁡o,argch⁡p,argth⁡q</p>
<p>符号函数，绝对值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\sgn r, \left\vert s \right\vert</span><br></pre></td></tr></table></figure>

<p>sgn𝑟,|𝑠|sgn⁡r,|s|</p>
<p>最大值，最小值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\min(x,y), \max(x,y)</span><br></pre></td></tr></table></figure>

<p>min(𝑥,𝑦),max(𝑥,𝑦)min(x,y),max(x,y)</p>
<h3 id="界限，极限"><a href="#界限，极限" class="headerlink" title="界限，极限#"></a>界限，极限<a href="https://www.cnblogs.com/1024th/p/11623258.html#369121514" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\min x, \max y, \inf s, \sup t</span><br></pre></td></tr></table></figure>

<p>min𝑥,max𝑦,inf𝑠,sup𝑡minx,maxy,infs,supt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\lim u, \liminf v, \limsup w</span><br></pre></td></tr></table></figure>

<p>lim𝑢,liminf𝑣,limsup𝑤limu,lim infv,lim supw</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\lim_&#123;x \to \infty&#125; \frac&#123;1&#125;&#123;n(n+1)&#125;</span><br></pre></td></tr></table></figure>

<p>lim𝑥→∞1𝑛(𝑛+1)limx→∞1n(n+1)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\dim p, \deg q, \det m, \ker\phi</span><br></pre></td></tr></table></figure>

<p>dim𝑝,deg𝑞,det𝑚,ker𝜙dim⁡p,deg⁡q,detm,ker⁡ϕ</p>
<h3 id="投射"><a href="#投射" class="headerlink" title="投射#"></a>投射<a href="https://www.cnblogs.com/1024th/p/11623258.html#3489407678" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Pr j, \hom l, \lVert z \rVert, \arg z</span><br></pre></td></tr></table></figure>

<p>Pr𝑗,hom𝑙,‖𝑧‖,arg𝑧Prj,hom⁡l,‖z‖,arg⁡z</p>
<h3 id="微分及导数"><a href="#微分及导数" class="headerlink" title="微分及导数#"></a>微分及导数<a href="https://www.cnblogs.com/1024th/p/11623258.html#396538292" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dt, \mathrm&#123;d&#125;t, \partial t, \nabla\psi</span><br></pre></td></tr></table></figure>

<p>𝑑𝑡,d𝑡,∂𝑡,∇𝜓dt,dt,∂t,∇ψ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dy&#x2F;dx, \mathrm&#123;d&#125;y&#x2F;\mathrm&#123;d&#125;x, \frac&#123;dy&#125;&#123;dx&#125;, \frac&#123;\mathrm&#123;d&#125;y&#125;&#123;\mathrm&#123;d&#125;x&#125;, \frac&#123;\partial^2&#125;&#123;\partial x_1\partial x_2&#125;y</span><br></pre></td></tr></table></figure>

<p>𝑑𝑦/𝑑𝑥,d𝑦/d𝑥,𝑑𝑦𝑑𝑥,d𝑦d𝑥,∂2∂𝑥1∂𝑥2𝑦dy/dx,dy/dx,dydx,dydx,∂2∂x1∂x2y</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\prime, \backprime, f^\prime, f&#39;, f&#39;&#39;, f^&#123;(3)&#125;, \dot y, \ddot y</span><br></pre></td></tr></table></figure>

<p>′,‵,𝑓′,𝑓′,𝑓″,𝑓(3),𝑦˙,𝑦¨′,‵,f′,f′,f″,f(3),y˙,y¨</p>
<h3 id="类字母符号及常数"><a href="#类字母符号及常数" class="headerlink" title="类字母符号及常数#"></a>类字母符号及常数<a href="https://www.cnblogs.com/1024th/p/11623258.html#513781915" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\infty, \aleph, \complement, \backepsilon, \eth, \Finv, \hbar</span><br></pre></td></tr></table></figure>

<p>∞,ℵ,∁,∍,ð,Ⅎ,ℏ∞,ℵ,∁,∍,ð,Ⅎ,ℏ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Im, \imath, \jmath, \Bbbk, \ell, \mho, \wp, \Re, \circledS</span><br></pre></td></tr></table></figure>

<p>ℑ,ı,ȷ,𝕜,ℓ,℧,℘,ℜ,Ⓢℑ,ı,ȷ,k,ℓ,℧,℘,ℜ,Ⓢ</p>
<h3 id="模运算"><a href="#模运算" class="headerlink" title="模运算#"></a>模运算<a href="https://www.cnblogs.com/1024th/p/11623258.html#3896518284" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s_k \equiv 0 \pmod&#123;m&#125;</span><br></pre></td></tr></table></figure>

<p>𝑠𝑘≡0(mod𝑚)sk≡0(modm)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a \bmod b</span><br></pre></td></tr></table></figure>

<p>𝑎mod𝑏amodb</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\gcd(m, n), \operatorname&#123;lcm&#125;(m, n)</span><br></pre></td></tr></table></figure>

<p>gcd(𝑚,𝑛),lcm(𝑚,𝑛)gcd(m,n),lcm⁡(m,n)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mid, \nmid, \shortmid, \nshortmid</span><br></pre></td></tr></table></figure>

<p>∣,∤,∣,∤∣,∤,∣,∤</p>
<h3 id="根号"><a href="#根号" class="headerlink" title="根号#"></a>根号<a href="https://www.cnblogs.com/1024th/p/11623258.html#2774396316" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\surd, \sqrt&#123;2&#125;, \sqrt[n]&#123;&#125;, \sqrt[3]&#123;\frac&#123;x^3+y^3&#125;&#123;2&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>√,2‾√,√𝑛,𝑥3+𝑦32‾‾‾‾‾‾‾‾√3√,2,n,x3+y323</p>
<h3 id="运算符"><a href="#运算符" class="headerlink" title="运算符#"></a>运算符<a href="https://www.cnblogs.com/1024th/p/11623258.html#1464542519" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+, -, \pm, \mp, \dotplus</span><br></pre></td></tr></table></figure>

<p>+,−,±,∓,∔+,−,±,∓,∔</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\times, \div, \divideontimes, &#x2F;, \backslash</span><br></pre></td></tr></table></figure>

<p>×,÷,⋇,/,∖×,÷,⋇,/,∖</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\cdot, * \ast, \star, \circ, \bullet</span><br></pre></td></tr></table></figure>

<p>⋅,∗∗,⋆,∘,∙⋅,∗∗,⋆,∘,∙</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\boxplus, \boxminus, \boxtimes, \boxdot</span><br></pre></td></tr></table></figure>

<p>⊞,⊟,⊠,⊡⊞,⊟,⊠,⊡</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\oplus, \ominus, \otimes, \oslash, \odot</span><br></pre></td></tr></table></figure>

<p>⊕,⊖,⊗,⊘,⊙⊕,⊖,⊗,⊘,⊙</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\circleddash, \circledcirc, \circledast</span><br></pre></td></tr></table></figure>

<p>⊝,⊚,⊛⊝,⊚,⊛</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\bigoplus, \bigotimes, \bigodot</span><br></pre></td></tr></table></figure>

<p>⨁,⨂,⨀⨁,⨂,⨀</p>
<h3 id="集合"><a href="#集合" class="headerlink" title="集合#"></a>集合<a href="https://www.cnblogs.com/1024th/p/11623258.html#1331018051" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\&#123; \&#125;, \O \empty \emptyset, \varnothing</span><br></pre></td></tr></table></figure>

<p>{},∅∅∅,∅{},∅∅∅,∅</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\in, \notin \not\in, \ni, \not\ni</span><br></pre></td></tr></table></figure>

<p>∈,∉∉,∋,∌∈,∉∉,∋,∌</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\cap, \Cap, \sqcap, \bigcap</span><br></pre></td></tr></table></figure>

<p>∩,⋒,⊓,⋂∩,⋒,⊓,⋂</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\cup, \Cup, \sqcup, \bigcup, \bigsqcup, \uplus, \biguplus</span><br></pre></td></tr></table></figure>

<p>∪,⋓,⊔,⋃,⨆,⊎,⨄∪,⋓,⊔,⋃,⨆,⊎,⨄</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\setminus, \smallsetminus, \times</span><br></pre></td></tr></table></figure>

<p>∖,∖,×∖,∖,×</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\subset, \Subset, \sqsubset</span><br></pre></td></tr></table></figure>

<p>⊂,⋐,⊏⊂,⋐,⊏</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\supset, \Supset, \sqsupset</span><br></pre></td></tr></table></figure>

<p>⊃,⋑,⊐⊃,⋑,⊐</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\subseteq, \nsubseteq, \subsetneq, \varsubsetneq, \sqsubseteq</span><br></pre></td></tr></table></figure>

<p>⊆,⊈,⊊,⊊,⊑⊆,⊈,⊊,⊊,⊑</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\supseteq, \nsupseteq, \supsetneq, \varsupsetneq, \sqsupseteq</span><br></pre></td></tr></table></figure>

<p>⊇,⊉,⊋,⊋,⊒⊇,⊉,⊋,⊋,⊒</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\subseteqq, \nsubseteqq, \subsetneqq, \varsubsetneqq</span><br></pre></td></tr></table></figure>

<p>⫅,,⫋,⫋⫅,⊈,⫋,⫋</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\supseteqq, \nsupseteqq, \supsetneqq, \varsupsetneqq</span><br></pre></td></tr></table></figure>

<p>⫆,,⫌,⫌⫆,⊉,⫌,⫌</p>
<h3 id="关系符号"><a href="#关系符号" class="headerlink" title="关系符号#"></a>关系符号<a href="https://www.cnblogs.com/1024th/p/11623258.html#1432537897" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x3D;, \ne, \neq, \equiv, \not\equiv</span><br></pre></td></tr></table></figure>

<p>=,≠,≠,≡,≢=,≠,≠,≡,≢</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\doteq, \doteqdot,&#96; &#96;\overset&#123;\underset&#123;\mathrm&#123;def&#125;&#125;&#123;&#125;&#125;&#123;&#x3D;&#125;,&#96; &#96;:&#x3D;</span><br></pre></td></tr></table></figure>

<p>≐,≑,=def,:=≐,≑,=def,:=</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\sim, \nsim, \backsim, \thicksim, \simeq, \backsimeq, \eqsim, \cong, \ncong</span><br></pre></td></tr></table></figure>

<p>∼,≁,∽,∼,≃,⋍,≂,≅,≆∼,≁,∽,∼,≃,⋍,≂,≅,≆</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\approx, \thickapprox, \approxeq, \asymp, \propto, \varpropto</span><br></pre></td></tr></table></figure>

<p>≈,≈,≊,≍,∝,∝≈,≈,≊,≍,∝,∝</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;, \nless, \ll, \not\ll, \lll, \not\lll, \lessdot</span><br></pre></td></tr></table></figure>

<p>&lt;,≮,≪,≪̸,⋘,⋘̸,⋖&lt;,≮,≪,≪̸,⋘,⋘̸,⋖</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;, \ngtr, \gg, \not\gg, \ggg, \not\ggg, \gtrdot</span><br></pre></td></tr></table></figure>

<p>&gt;,≯,≫,≫̸,⋙,⋙̸,⋗&gt;,≯,≫,≫̸,⋙,⋙̸,⋗</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\le, \leq, \lneq, \leqq, \nleq, \nleqq, \lneqq, \lvertneqq</span><br></pre></td></tr></table></figure>

<p>≤,≤,⪇,≦,≰,,≨,≨≤,≤,⪇,≦,≰,≰,≨,≨</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\ge, \geq, \gneq, \geqq, \ngeq, \ngeqq, \gneqq, \gvertneqq</span><br></pre></td></tr></table></figure>

<p>≥,≥,⪈,≧,≱,,≩,≩≥,≥,⪈,≧,≱,≱,≩,≩</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\lessgtr, \lesseqgtr, \lesseqqgtr, \gtrless, \gtreqless, \gtreqqless</span><br></pre></td></tr></table></figure>

<p>≶,⋚,⪋,≷,⋛,⪌≶,⋚,⪋,≷,⋛,⪌</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\leqslant, \nleqslant, \eqslantless</span><br></pre></td></tr></table></figure>

<p>⩽,,⪕⩽,⪇,⪕</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\geqslant, \ngeqslant, \eqslantgtr</span><br></pre></td></tr></table></figure>

<p>⩾,,⪖⩾,⪈,⪖</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\lesssim, \lnsim, \lessapprox, \lnapprox</span><br></pre></td></tr></table></figure>

<p>≲,⋦,⪅,⪉≲,⋦,⪅,⪉</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\gtrsim, \gnsim, \gtrapprox, \gnapprox</span><br></pre></td></tr></table></figure>

<p>≳,⋧,⪆,⪊≳,⋧,⪆,⪊</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\prec, \nprec, \preceq, \npreceq, \precneqq</span><br></pre></td></tr></table></figure>

<p>≺,⊀,⪯,,⪵≺,⊀,⪯,⋠,⪵</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\succ, \nsucc, \succeq, \nsucceq, \succneqq</span><br></pre></td></tr></table></figure>

<p>≻,⊁,⪰,,⪶≻,⊁,⪰,⋡,⪶</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\preccurlyeq, \curlyeqprec</span><br></pre></td></tr></table></figure>

<p>≼,⋞≼,⋞</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\succcurlyeq, \curlyeqsucc</span><br></pre></td></tr></table></figure>

<p>≽,⋟≽,⋟</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\precsim, \precnsim, \precapprox, \precnapprox</span><br></pre></td></tr></table></figure>

<p>≾,⋨,⪷,⪹≾,⋨,⪷,⪹</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\succsim, \succnsim, \succapprox, \succnapprox</span><br></pre></td></tr></table></figure>

<p>≿,⋩,⪸,⪺≿,⋩,⪸,⪺</p>
<h3 id="几何符号"><a href="#几何符号" class="headerlink" title="几何符号#"></a>几何符号<a href="https://www.cnblogs.com/1024th/p/11623258.html#2377994005" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\parallel, \nparallel, \shortparallel, \nshortparallel</span><br></pre></td></tr></table></figure>

<p>∥,∦,∥,∦∥,∦,∥,∦</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\perp, \angle, \sphericalangle, \measuredangle, 45^\circ</span><br></pre></td></tr></table></figure>

<p>⊥,∠,∢,∡,45∘⊥,∠,∢,∡,45∘</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Box, \blacksquare, \diamond, \Diamond \lozenge, \blacklozenge, \bigstar</span><br></pre></td></tr></table></figure>

<p>◻,◼,⋄,◊◊,⧫,★◻,◼,⋄,◊◊,⧫,★</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\bigcirc, \triangle, \bigtriangleup, \bigtriangledown</span><br></pre></td></tr></table></figure>

<p>◯,△,△,▽◯,△,△,▽</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\vartriangle, \triangledown</span><br></pre></td></tr></table></figure>

<p>▵,▿△,▽</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\blacktriangle, \blacktriangledown, \blacktriangleleft, \blacktriangleright</span><br></pre></td></tr></table></figure>

<p>▴,▾,◂,▸▴,▾,◂,▸</p>
<h3 id="逻辑符号"><a href="#逻辑符号" class="headerlink" title="逻辑符号#"></a>逻辑符号<a href="https://www.cnblogs.com/1024th/p/11623258.html#2097857188" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\forall, \exists, \nexists</span><br></pre></td></tr></table></figure>

<p>∀,∃,∄∀,∃,∄</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\therefore, \because, \And</span><br></pre></td></tr></table></figure>

<p>∴,∵,&amp;∴,∵,&amp;</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\or \lor \vee, \curlyvee, \bigvee</span><br></pre></td></tr></table></figure>

<p>∨,∨,∨,⋎,⋁∨,∨,∨,⋎,⋁</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\and \land \wedge, \curlywedge, \bigwedge</span><br></pre></td></tr></table></figure>

<p>∧,∧,∧,⋏,⋀∧,∧,∧,⋏,⋀</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">\bar&#123;q&#125;, \bar&#123;abc&#125;, \overline&#123;q&#125;, \overline&#123;abc&#125;,</span><br><span class="line">\lnot \neg, \not\operatorname&#123;R&#125;, \bot, \top</span><br></pre></td></tr></table></figure>

<p>𝑞¯,𝑎𝑏𝑐¯,𝑞⎯⎯⎯,𝑎𝑏𝑐⎯⎯⎯⎯⎯⎯⎯⎯,q¯,abc¯,q¯,abc¯,</p>
<p>¬¬,⧸R,⊥,⊤¬¬,⧸R,⊥,⊤</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\vdash \dashv, \vDash, \Vdash, \models</span><br></pre></td></tr></table></figure>

<p>⊢,⊣,⊨,⊩,⊨⊢,⊣,⊨,⊩,⊨</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Vvdash \nvdash \nVdash \nvDash \nVDash</span><br></pre></td></tr></table></figure>

<p>⊪,⊬,⊮,⊭,⊯⊪,⊬,⊮,⊭,⊯</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\ulcorner \urcorner \llcorner \lrcorner</span><br></pre></td></tr></table></figure>

<p>⌜⌝⌞⌟⌜⌝⌞⌟</p>
<h3 id="箭头"><a href="#箭头" class="headerlink" title="箭头#"></a>箭头<a href="https://www.cnblogs.com/1024th/p/11623258.html#2515855580" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Rrightarrow, \Lleftarrow</span><br></pre></td></tr></table></figure>

<p>⇛,⇚⇛,⇚</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Rightarrow, \nRightarrow, \Longrightarrow \implies</span><br></pre></td></tr></table></figure>

<p>⇒,⇏,⟹,⟹⇒,⇏,⟹,⟹</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Leftarrow, \nLeftarrow, \Longleftarrow</span><br></pre></td></tr></table></figure>

<p>⇐,⇍,⟸⇐,⇍,⟸</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Leftrightarrow, \nLeftrightarrow, \Longleftrightarrow \iff</span><br></pre></td></tr></table></figure>

<p>⇔,⇎,⟺⟺⇔,⇎,⟺⟺</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Uparrow, \Downarrow, \Updownarrow</span><br></pre></td></tr></table></figure>

<p>⇑,⇓,⇕⇑,⇓,⇕</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\rightarrow \to, \nrightarrow, \longrightarrow</span><br></pre></td></tr></table></figure>

<p>→→,↛,⟶→→,↛,⟶</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\leftarrow \gets, \nleftarrow, \longleftarrow</span><br></pre></td></tr></table></figure>

<p>←←,↚,⟵←←,↚,⟵</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\leftrightarrow, \nleftrightarrow, \longleftrightarrow</span><br></pre></td></tr></table></figure>

<p>↔,↮,⟷↔,↮,⟷</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\uparrow, \downarrow, \updownarrow</span><br></pre></td></tr></table></figure>

<p>↑,↓,↕↑,↓,↕</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\nearrow, \swarrow, \nwarrow, \searrow</span><br></pre></td></tr></table></figure>

<p>↗,↙,↖,↘↗,↙,↖,↘</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mapsto, \longmapsto</span><br></pre></td></tr></table></figure>

<p>↦,⟼↦,⟼</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\rightharpoonup \rightharpoondown \leftharpoonup \leftharpoondown \upharpoonleft \upharpoonright \downharpoonleft \downharpoonright \rightleftharpoons \leftrightharpoons</span><br></pre></td></tr></table></figure>

<p>⇀,⇁,↼,↽,↿,↾,⇃,⇂,⇌,⇋⇀,⇁,↼,↽,↿,↾,⇃,⇂,⇌,⇋</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\curvearrowleft \circlearrowleft \Lsh \upuparrows \rightrightarrows \rightleftarrows \rightarrowtail \looparrowright</span><br></pre></td></tr></table></figure>

<p>↶,↺,↰,⇈,⇉,⇄,↣,↬↶,↺,↰,⇈,⇉,⇄,↣,↬</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\curvearrowright \circlearrowright \Rsh \downdownarrows \leftleftarrows \leftrightarrows \leftarrowtail \looparrowleft</span><br></pre></td></tr></table></figure>

<p>↷,↻,↱,⇊,⇇,⇆,↢,↫↷,↻,↱,⇊,⇇,⇆,↢,↫</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\hookrightarrow \hookleftarrow \multimap \leftrightsquigarrow \rightsquigarrow \twoheadrightarrow \twoheadleftarrow</span><br></pre></td></tr></table></figure>

<p>↪,↩,⊸,↭,⇝,↠,↞↪,↩,⊸,↭,⇝,↠,↞</p>
<h3 id="特殊符号"><a href="#特殊符号" class="headerlink" title="特殊符号#"></a>特殊符号<a href="https://www.cnblogs.com/1024th/p/11623258.html#986101740" target="_blank" rel="noopener">#</a></h3><p>省略号：数学公式中常见的省略号有两种，<code>\ldots</code> 表示与文本底线对齐的省略号，<code>\cdots</code> 表示与文本中线对齐的省略号。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\amalg \% \dagger \ddagger \ldots \cdots</span><br></pre></td></tr></table></figure>

<p>⨿%†‡…⋯⨿%†‡…⋯</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\smile \frown \wr \triangleleft \triangleright</span><br></pre></td></tr></table></figure>

<p>⌣⌢≀◃▹⌣⌢≀◃▹</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\diamondsuit, \heartsuit, \clubsuit, \spadesuit, \Game, \flat, \natural, \sharp</span><br></pre></td></tr></table></figure>

<p>♢,♡,♣,♠,⅁,♭,♮,♯♢,♡,♣,♠,⅁,♭,♮,♯</p>
<h3 id="未分类"><a href="#未分类" class="headerlink" title="未分类#"></a>未分类<a href="https://www.cnblogs.com/1024th/p/11623258.html#2352184071" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\diagup \diagdown \centerdot \ltimes \rtimes \leftthreetimes \rightthreetimes</span><br></pre></td></tr></table></figure>

<p>╱,╲,⋅,⋉,⋊,⋋,⋌╱,╲,⋅,⋉,⋊,⋋,⋌</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\eqcirc \circeq \triangleq \bumpeq \Bumpeq \doteqdot \risingdotseq \fallingdotseq</span><br></pre></td></tr></table></figure>

<p>≖,≗,≜,≏,≎,≑,≓,≒≖,≗,≜,≏,≎,≑,≓,≒</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\intercal \barwedge \veebar \doublebarwedge \between \pitchfork</span><br></pre></td></tr></table></figure>

<p>⊺,⊼,⊻,⩞,≬,⋔⊺,⊼,⊻,⩞,≬,⋔</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\vartriangleleft \ntriangleleft \vartriangleright \ntriangleright</span><br></pre></td></tr></table></figure>

<p>⊲,⋪,⊳,⋫⊲,⋪,⊳,⋫</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\trianglelefteq \ntrianglelefteq \trianglerighteq \ntrianglerighteq</span><br></pre></td></tr></table></figure>

<p>⊴,⋬,⊵,⋭⊴,⋬,⊵,⋭</p>
<p>关于这些符号的更多语义，参阅 <a href="https://web.archive.org/web/20160305074303/https://www.math.upenn.edu/tex-stuff/cookbook.pdf" target="_blank" rel="noopener">TeX Cookbook</a> 的简述。</p>
<h2 id="上标、下标及积分等"><a href="#上标、下标及积分等" class="headerlink" title="上标、下标及积分等#"></a>上标、下标及积分等<a href="https://www.cnblogs.com/1024th/p/11623258.html#1810717751" target="_blank" rel="noopener">#</a></h2><p>功能|语法|效果</p>
<p><code>^</code> 表示上标, <code>_</code> 表示下标。如果上下标的内容多于一个字符，需要用 <code>{}</code> 将这些内容括成一个整体。上下标可以嵌套，也可以同时使用。</p>
<p>上标</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a^2</span><br></pre></td></tr></table></figure>

<p>𝑎2a2</p>
<p>下标</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a_2</span><br></pre></td></tr></table></figure>

<p>𝑎2a2</p>
<p>组合</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a^&#123;2+2&#125;</span><br></pre></td></tr></table></figure>

<p>𝑎2+2a2+2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a_&#123;i,j&#125;</span><br></pre></td></tr></table></figure>

<p>𝑎𝑖,𝑗ai,j</p>
<p>结合上下标</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_2^3</span><br></pre></td></tr></table></figure>

<p>𝑥32x23</p>
<p>前置上下标</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#125;_1^2\!X_3^4</span><br></pre></td></tr></table></figure>

<p>21𝑋4312X34</p>
<p>导数（<strong>HTML</strong>）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x&#39;</span><br></pre></td></tr></table></figure>

<p>𝑥′x′</p>
<p>导数（<strong>PNG</strong>）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x^\prime</span><br></pre></td></tr></table></figure>

<p>𝑥′x′</p>
<p>导数（<strong>错误</strong>）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x\prime</span><br></pre></td></tr></table></figure>

<p>𝑥′x′</p>
<p>导数点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\dot&#123;x&#125;</span><br></pre></td></tr></table></figure>

<p>𝑥˙x˙</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\ddot&#123;y&#125;</span><br></pre></td></tr></table></figure>

<p>𝑦¨y¨</p>
<p>向量</p>
<p><code>\vec{c}</code>（只有一个字母）</p>
<p>𝑐⃗ c→</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\overleftarrow&#123;a b&#125;</span><br></pre></td></tr></table></figure>

<p>𝑎𝑏←−ab←</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\overrightarrow&#123;c d&#125;</span><br></pre></td></tr></table></figure>

<p>𝑐𝑑−→cd→</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\overleftrightarrow&#123;a b&#125;</span><br></pre></td></tr></table></figure>

<p>𝑎𝑏←→ab↔</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\widehat&#123;e f g&#125;</span><br></pre></td></tr></table></figure>

<p>𝑒𝑓𝑔ˆefg^</p>
<p>上弧</p>
<p>（注: 正确应该用 \overarc，但在这里行不通。要用建议的语法作为解决办法。）（使用  overarc 时需要引入 {arcs} 包。）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\overset&#123;\frown&#125; &#123;AB&#125;</span><br></pre></td></tr></table></figure>

<p>𝐴𝐵⌢AB⌢</p>
<p>上划线</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\overline&#123;h i j&#125;</span><br></pre></td></tr></table></figure>

<p>ℎ𝑖𝑗⎯⎯⎯⎯⎯⎯⎯hij¯</p>
<p>下划线</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\underline&#123;k l m&#125;</span><br></pre></td></tr></table></figure>

<p>𝑘𝑙𝑚⎯⎯⎯⎯⎯⎯klm_</p>
<p>上括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\overbrace&#123;1+2+\cdots+100&#125;</span><br></pre></td></tr></table></figure>

<p>1+2+⋯+1001+2+⋯+100⏞</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;matrix&#125; 5050 \\ \overbrace&#123; 1+2+\cdots+100 &#125; \end&#123;matrix&#125;</span><br></pre></td></tr></table></figure>

<p>50501+2+⋯+10050501+2+⋯+100⏞</p>
<p>下括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\underbrace&#123;a+b+\cdots+z&#125;</span><br></pre></td></tr></table></figure>

<p>𝑎+𝑏+⋯+𝑧a+b+⋯+z⏟</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;matrix&#125; \underbrace&#123; a+b+\cdots+z &#125; \\ 26 \end&#123;matrix&#125;</span><br></pre></td></tr></table></figure>

<p>𝑎+𝑏+⋯+𝑧26a+b+⋯+z⏟26</p>
<p>求和（累加）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\sum_&#123;k&#x3D;1&#125;^N k^2</span><br></pre></td></tr></table></figure>

<p>∑𝑘=1𝑁𝑘2∑k=1Nk2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;matrix&#125; \sum_&#123;k&#x3D;1&#125;^N k^2 \end&#123;matrix&#125;</span><br></pre></td></tr></table></figure>

<p>∑𝑁𝑘=1𝑘2∑k=1Nk2</p>
<p>求积（累乘）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\prod_&#123;i&#x3D;1&#125;^N x_i</span><br></pre></td></tr></table></figure>

<p>∏𝑖=1𝑁𝑥𝑖∏i=1Nxi</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;matrix&#125; \prod_&#123;i&#x3D;1&#125;^N x_i \end&#123;matrix&#125;</span><br></pre></td></tr></table></figure>

<p>∏𝑁𝑖=1𝑥𝑖∏i=1Nxi</p>
<p>上积</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\coprod_&#123;i&#x3D;1&#125;^N x_i</span><br></pre></td></tr></table></figure>

<p>∐𝑖=1𝑁𝑥𝑖∐i=1Nxi</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;matrix&#125; \coprod_&#123;i&#x3D;1&#125;^N x_i \end&#123;matrix&#125;</span><br></pre></td></tr></table></figure>

<p>∐𝑁𝑖=1𝑥𝑖∐i=1Nxi</p>
<p>极限</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\lim_&#123;n \to \infty&#125;x_n</span><br></pre></td></tr></table></figure>

<p>lim𝑛→∞𝑥𝑛limn→∞xn</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;matrix&#125; \lim_&#123;n \to \infty&#125;x_n \end&#123;matrix&#125;</span><br></pre></td></tr></table></figure>

<p>lim𝑛→∞𝑥𝑛limn→∞xn</p>
<p>积分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\int_&#123;-N&#125;^&#123;N&#125; e^x\, &#123;\rm d&#125;x</span><br></pre></td></tr></table></figure>

<p>∫𝑁−𝑁𝑒𝑥d𝑥∫−NNexdx</p>
<p>本例中 <code>\,</code> 和 <code>{\rm d}</code> 部分可省略，但建议加入，能使式子更美观。<code>{\rm d}</code>可以用<code>\mathrm{d}</code>等价替换。</p>
<p><code>\begin{matrix} \int_{-N}^{N} e^x\, \mathrm{d}x \end{matrix}</code>（矩阵中积分符号变小）</p>
<p>∫𝑁−𝑁𝑒𝑥d𝑥∫−NNexdx</p>
<p>双重积分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\iint_&#123;D&#125;^&#123;W&#125; \, \mathrm&#123;d&#125;x\,\mathrm&#123;d&#125;y</span><br></pre></td></tr></table></figure>

<p>∬𝑊𝐷d𝑥d𝑦∬DWdxdy</p>
<p>三重积分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\iiint_&#123;E&#125;^&#123;V&#125; \, \mathrm&#123;d&#125;x\,\mathrm&#123;d&#125;y\,\mathrm&#123;d&#125;z</span><br></pre></td></tr></table></figure>

<p>∭𝑉𝐸d𝑥d𝑦d𝑧∭EVdxdydz</p>
<p>闭合的曲线、曲面积分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\oint_&#123;C&#125; x^3\, \mathrm&#123;d&#125;x + 4y^2\, \mathrm&#123;d&#125;y</span><br></pre></td></tr></table></figure>

<p>∮𝐶𝑥3d𝑥+4𝑦2d𝑦∮C⁡x3dx+4y2dy</p>
<p>交集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\bigcap_1^&#123;n&#125; p</span><br></pre></td></tr></table></figure>

<p>⋂1𝑛𝑝⋂1np</p>
<p>并集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\bigcup_1^&#123;k&#125; p</span><br></pre></td></tr></table></figure>

<p>⋃1𝑘𝑝⋃1kp</p>
<h2 id="分数"><a href="#分数" class="headerlink" title="分数#"></a>分数<a href="https://www.cnblogs.com/1024th/p/11623258.html#108128303" target="_blank" rel="noopener">#</a></h2><p>通常使用 <code>\frac {分子} {分母}</code> 命令产生一个分数，分数可嵌套。<br>便捷情况可直接输入 <code>\frac ab</code> 来快速生成一个 𝑎𝑏ab 。<br>如果分式很复杂，亦可使用 <code>分子 \over 分母</code> 命令，此时分数仅有一层。</p>
<p>功能|语法|效果</p>
<p>分数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\frac&#123;2&#125;&#123;4&#125;&#x3D;0.5</span><br></pre></td></tr></table></figure>

<p>24=0.524=0.5</p>
<p>小型分数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\tfrac&#123;2&#125;&#123;4&#125; &#x3D; 0.5</span><br></pre></td></tr></table></figure>

<p>24=0.524=0.5</p>
<p>连分式（大型嵌套分式）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\cfrac&#123;2&#125;&#123;c + \cfrac&#123;2&#125;&#123;d + \cfrac&#123;2&#125;&#123;4&#125;&#125;&#125; &#x3D; a</span><br></pre></td></tr></table></figure>

<p>2𝑐+2𝑑+24=𝑎2c+2d+24=a</p>
<p>大型不嵌套分式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\dfrac&#123;2&#125;&#123;4&#125; &#x3D; 0.5 \qquad \dfrac&#123;2&#125;&#123;c + \dfrac&#123;2&#125;&#123;d + \dfrac&#123;2&#125;&#123;4&#125;&#125;&#125; &#x3D; a</span><br></pre></td></tr></table></figure>

<p>24=0.52𝑐+2𝑑+24=𝑎24=0.52c+2d+24=a</p>
<p>二项式系数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\dbinom&#123;n&#125;&#123;r&#125;&#x3D;\binom&#123;n&#125;&#123;n-r&#125;&#x3D;\mathrm&#123;C&#125;_n^r&#x3D;\mathrm&#123;C&#125;_n^&#123;n-r&#125;</span><br></pre></td></tr></table></figure>

<p>(𝑛𝑟)=(𝑛𝑛−𝑟)=C𝑟𝑛=C𝑛−𝑟𝑛(nr)=(nn−r)=Cnr=Cnn−r</p>
<p>小型二项式系数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\tbinom&#123;n&#125;&#123;r&#125;&#x3D;\tbinom&#123;n&#125;&#123;n-r&#125;&#x3D;\mathrm&#123;C&#125;_n^r&#x3D;\mathrm&#123;C&#125;_n^&#123;n-r&#125;</span><br></pre></td></tr></table></figure>

<p>(𝑛𝑟)=(𝑛𝑛−𝑟)=C𝑟𝑛=C𝑛−𝑟𝑛(nr)=(nn−r)=Cnr=Cnn−r</p>
<p>大型二项式系数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\binom&#123;n&#125;&#123;r&#125;&#x3D;\dbinom&#123;n&#125;&#123;n-r&#125;&#x3D;\mathrm&#123;C&#125;_n^r&#x3D;\mathrm&#123;C&#125;_n^&#123;n-r&#125;</span><br></pre></td></tr></table></figure>

<p>(𝑛𝑟)=(𝑛𝑛−𝑟)=C𝑟𝑛=C𝑛−𝑟𝑛(nr)=(nn−r)=Cnr=Cnn−r</p>
<p>在以e为底的指数函数、极限和积分中尽量不要使用 <code>\frac</code> 符号：它会使整段函数看起来很怪，而且可能产生歧义。也正是因此它在专业数学排版中几乎从不出现。<br>横着写这些分式，中间使用斜线间隔 <code>/</code> （用斜线代替分数线）。</p>
<ul>
<li>例子：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;array&#125;&#123;cc&#125;</span><br><span class="line">\mathrm&#123;Bad&#125; &amp; \mathrm&#123;Better&#125; \\</span><br><span class="line">\hline \\</span><br><span class="line">e^&#123;i\frac&#123;\pi&#125;2&#125; \quad e^&#123;\frac&#123;i\pi&#125;2&#125;&amp; e^&#123;i\pi&#x2F;2&#125; \\</span><br><span class="line">\int_&#123;-\frac\pi2&#125;^\frac\pi2 \sin x\,dx &amp; \int_&#123;-\pi&#x2F;2&#125;^&#123;\pi&#x2F;2&#125;\sin x\,dx \\</span><br><span class="line">\end&#123;array&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>显示：</li>
</ul>
<p>  Bad𝑒𝑖𝜋2𝑒𝑖𝜋2∫𝜋2−𝜋2sin𝑥𝑑𝑥Better𝑒𝑖𝜋/2∫𝜋/2−𝜋/2sin𝑥𝑑𝑥BadBettereiπ2eiπ2eiπ/2∫−π2π2sin⁡xdx∫−π/2π/2sin⁡xdx</p>
<h2 id="矩阵、条件表达式、方程组"><a href="#矩阵、条件表达式、方程组" class="headerlink" title="矩阵、条件表达式、方程组#"></a>矩阵、条件表达式、方程组<a href="https://www.cnblogs.com/1024th/p/11623258.html#410904693" target="_blank" rel="noopener">#</a></h2><p>语法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;类型&#125;</span><br><span class="line">公式内容</span><br><span class="line">\end&#123;类型&#125;</span><br></pre></td></tr></table></figure>

<p>类型可以是：矩阵 <code>matrix</code> <code>pmatrix</code> <code>bmatrix</code> <code>Bmatrix</code> <code>vmatrix</code> <code>Vmatrix</code>、条件表达式 <code>cases</code>、多行对齐方程式 <code>aligned</code>、数组 <code>array</code>。</p>
<p>在公式内容中：在每一行中插入 <code>&amp;</code> 来指定需要<strong>对齐</strong>的内容，在每行结尾处使用 <code>\\</code> <strong>换行</strong>。</p>
<h3 id="无框矩阵"><a href="#无框矩阵" class="headerlink" title="无框矩阵#"></a>无框矩阵<a href="https://www.cnblogs.com/1024th/p/11623258.html#1931252606" target="_blank" rel="noopener">#</a></h3><p>在开头使用 <code>begin{matrix}</code>，在结尾使用 <code>end{matrix}</code>，在中间插入矩阵元素，每个元素之间插入 <code>&amp;</code> ，并在每行结尾处使用 <code>\\</code> 。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;matrix&#125;</span><br><span class="line">x &amp; y \\</span><br><span class="line">z &amp; v</span><br><span class="line">\end&#123;matrix&#125;</span><br></pre></td></tr></table></figure>

<p>𝑥𝑧𝑦𝑣xyzv</p>
<h3 id="有框矩阵"><a href="#有框矩阵" class="headerlink" title="有框矩阵#"></a>有框矩阵<a href="https://www.cnblogs.com/1024th/p/11623258.html#1726574240" target="_blank" rel="noopener">#</a></h3><p>在开头将 <code>matrix</code> 替换为 <code>pmatrix</code> <code>bmatrix</code> <code>Bmatrix</code> <code>vmatrix</code> <code>Vmatrix</code> 。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;vmatrix&#125;</span><br><span class="line">x &amp; y \\</span><br><span class="line">z &amp; v</span><br><span class="line">\end&#123;vmatrix&#125;</span><br></pre></td></tr></table></figure>

<p>∣∣∣𝑥𝑧𝑦𝑣∣∣∣|xyzv|</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;Vmatrix&#125;</span><br><span class="line">x &amp; y \\</span><br><span class="line">z &amp; v</span><br><span class="line">\end&#123;Vmatrix&#125;</span><br></pre></td></tr></table></figure>

<p>‖‖‖𝑥𝑧𝑦𝑣‖‖‖‖xyzv‖</p>
<p>使用 <code>\cdots</code> ⋯⋯ , <code>\ddots</code> ⋱⋱ , <code>\vdots</code> ⋮⋮ 来输入<strong>省略符号</strong>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;bmatrix&#125;</span><br><span class="line">0      &amp; \cdots &amp; 0      \\</span><br><span class="line">\vdots &amp; \ddots &amp; \vdots \\</span><br><span class="line">0      &amp; \cdots &amp; 0</span><br><span class="line">\end&#123;bmatrix&#125;</span><br></pre></td></tr></table></figure>

<p>⎡⎣⎢⎢⎢0⋮0⋯⋱⋯0⋮0⎤⎦⎥⎥⎥[0⋯0⋮⋱⋮0⋯0]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;Bmatrix&#125;</span><br><span class="line">x &amp; y \\</span><br><span class="line">z &amp; v</span><br><span class="line">\end&#123;Bmatrix&#125;</span><br></pre></td></tr></table></figure>

<p>{𝑥𝑧𝑦𝑣}{xyzv}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;pmatrix&#125;</span><br><span class="line">x &amp; y \\</span><br><span class="line">z &amp; v</span><br><span class="line">\end&#123;pmatrix&#125;</span><br></pre></td></tr></table></figure>

<p>(𝑥𝑧𝑦𝑣)(xyzv)</p>
<h3 id="条件表达式"><a href="#条件表达式" class="headerlink" title="条件表达式#"></a>条件表达式<a href="https://www.cnblogs.com/1024th/p/11623258.html#1395712733" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Copyf(n) &#x3D;</span><br><span class="line">\begin&#123;cases&#125; </span><br><span class="line">n&#x2F;2,  &amp; \text&#123;if &#125;n\text&#123; is even&#125; \\</span><br><span class="line">3n+1, &amp; \text&#123;if &#125;n\text&#123; is odd&#125;</span><br><span class="line">\end&#123;cases&#125;</span><br></pre></td></tr></table></figure>

<p>𝑓(𝑛)={𝑛/2,3𝑛+1,if 𝑛 is evenif 𝑛 is oddf(n)={n/2,if n is even3n+1,if n is odd</p>
<h3 id="多行等式、同余式"><a href="#多行等式、同余式" class="headerlink" title="多行等式、同余式#"></a>多行等式、同余式<a href="https://www.cnblogs.com/1024th/p/11623258.html#1479862649" target="_blank" rel="noopener">#</a></h3><p>人们经常想要一列整齐且居中的方程式序列。使用 <code>\begin{aligned}…\end{aligned}</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;aligned&#125;</span><br><span class="line">f(x) &amp; &#x3D; (m+n)^2 \\</span><br><span class="line">     &amp; &#x3D; m^2+2mn+n^2 \\</span><br><span class="line">\end&#123;aligned&#125;</span><br></pre></td></tr></table></figure>

<p>𝑓(𝑥)=(𝑚+𝑛)2=𝑚2+2𝑚𝑛+𝑛2f(x)=(m+n)2=m2+2mn+n2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Copybegin&#123;aligned&#125;</span><br><span class="line">3^&#123;6n+3&#125;+4^&#123;6n+3&#125; </span><br><span class="line">&amp; \equiv (3^3)^&#123;2n+1&#125;+(4^3)^&#123;2n+1&#125;\\  </span><br><span class="line">&amp; \equiv 27^&#123;2n+1&#125;+64^&#123;2n+1&#125;\\  </span><br><span class="line">&amp; \equiv 27^&#123;2n+1&#125;+(-27)^&#123;2n+1&#125;\\ </span><br><span class="line">&amp; \equiv 27^&#123;2n+1&#125;-27^&#123;2n+1&#125;\\</span><br><span class="line">&amp; \equiv 0 \pmod&#123;91&#125;\\</span><br><span class="line">\end&#123;aligned&#125;</span><br></pre></td></tr></table></figure>

<p>36𝑛+3+46𝑛+3≡(33)2𝑛+1+(43)2𝑛+1≡272𝑛+1+642𝑛+1≡272𝑛+1+(−27)2𝑛+1≡272𝑛+1−272𝑛+1≡0(mod91)36n+3+46n+3≡(33)2n+1+(43)2n+1≡272n+1+642n+1≡272n+1+(−27)2n+1≡272n+1−272n+1≡0(mod91)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;alignedat&#125;&#123;3&#125;</span><br><span class="line">f(x) &amp; &#x3D; (m-n)^2 \\</span><br><span class="line">f(x) &amp; &#x3D; (-m+n)^2 \\</span><br><span class="line">     &amp; &#x3D; m^2-2mn+n^2 \\</span><br><span class="line">\end&#123;alignedat&#125;</span><br></pre></td></tr></table></figure>

<p>𝑓(𝑥)𝑓(𝑥)=(𝑚−𝑛)2=(−𝑚+𝑛)2=𝑚2−2𝑚𝑛+𝑛2f(x)=(m−n)2f(x)=(−m+n)2=m2−2mn+n2</p>
<h3 id="方程组"><a href="#方程组" class="headerlink" title="方程组#"></a>方程组<a href="https://www.cnblogs.com/1024th/p/11623258.html#1718509031" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;cases&#125;</span><br><span class="line">3x + 5y +  z \\</span><br><span class="line">7x - 2y + 4z \\</span><br><span class="line">-6x + 3y + 2z</span><br><span class="line">\end&#123;cases&#125;</span><br></pre></td></tr></table></figure>



<p>⎧⎩⎨⎪⎪3𝑥+5𝑦+𝑧7𝑥−2𝑦+4𝑧−6𝑥+3𝑦+2𝑧{3x+5y+z7x−2y+4z−6x+3y+2z</p>
<p>或</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Copy\left\&#123;\begin&#123;aligned&#125;</span><br><span class="line">3x + 5y +  z \\</span><br><span class="line">7x - 2y + 4z \\</span><br><span class="line">-6x + 3y + 2z</span><br><span class="line">\end&#123;aligned&#125;\right.</span><br></pre></td></tr></table></figure>



<p>⎧⎩⎨⎪⎪3𝑥+5𝑦+𝑧7𝑥−2𝑦+4𝑧−6𝑥+3𝑦+2𝑧{3x+5y+z7x−2y+4z−6x+3y+2z</p>
<h2 id="数组与表格"><a href="#数组与表格" class="headerlink" title="数组与表格#"></a>数组与表格<a href="https://www.cnblogs.com/1024th/p/11623258.html#2801096508" target="_blank" rel="noopener">#</a></h2><p>通常，一个格式化后的表格比单纯的文字或排版后的文字更具有可读性。数组和表格均以 <code>\begin{array}</code> 开头，并在其后定义列数及每一列的文本对齐属性，<code>c</code> <code>l</code> <code>r</code> 分别代表居中、左对齐及右对齐。若需要插入垂直分割线，在定义式中插入 <code>|</code> ，若要插入水平分割线，在下一行输入前插入 <code>\hline</code> 。与矩阵相似，每行元素间均须要插入 <code>&amp;</code> ，每行元素以 <code>\\</code> 结尾，最后以 <code>\end{array}</code> 结束数组。</p>
<ul>
<li>例子：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;array&#125;&#123;c|lcr&#125;</span><br><span class="line">n &amp; \text&#123;左对齐&#125; &amp; \text&#123;居中对齐&#125; &amp; \text&#123;右对齐&#125; \\</span><br><span class="line">\hline</span><br><span class="line">1 &amp; 0.24 &amp; 1 &amp; 125 \\</span><br><span class="line">2 &amp; -1 &amp; 189 &amp; -8 \\</span><br><span class="line">3 &amp; -20 &amp; 2000 &amp; 1+10i</span><br><span class="line">\end&#123;array&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>显示：</p>
<p>𝑛123左对齐0.24−1−20居中对齐11892000右对齐125−81+10𝑖n左对齐居中对齐右对齐10.2411252−1189−83−2020001+10i</p>
</li>
</ul>
<ul>
<li>例子:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;array&#125;&#123;lcl&#125;</span><br><span class="line">z        &amp; &#x3D; &amp; a \\</span><br><span class="line">f(x,y,z) &amp; &#x3D; &amp; x + y + z </span><br><span class="line">\end&#123;array&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>显示：</li>
</ul>
<p>𝑧𝑓(𝑥,𝑦,𝑧)==𝑎𝑥+𝑦+𝑧z=af(x,y,z)=x+y+z</p>
<ul>
<li>例子:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;array&#125;&#123;lcr&#125;</span><br><span class="line">z        &amp; &#x3D; &amp; a \\</span><br><span class="line">f(x,y,z) &amp; &#x3D; &amp; x + y + z    </span><br><span class="line">\end&#123;array&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>显示:</li>
</ul>
<p>𝑧𝑓(𝑥,𝑦,𝑧)==𝑎𝑥+𝑦+𝑧z=af(x,y,z)=x+y+z</p>
<ul>
<li>例子:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;array&#125;&#123;ccc&#125;</span><br><span class="line">a &amp; b &amp; S \\</span><br><span class="line">\hline</span><br><span class="line">0&amp;0&amp;1\\</span><br><span class="line">0&amp;1&amp;1\\</span><br><span class="line">1&amp;0&amp;1\\</span><br><span class="line">1&amp;1&amp;0\\</span><br><span class="line">\end&#123;array&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>显示:</li>
</ul>
<p>𝑎0011𝑏0101𝑆1110abS001011101110</p>
<h3 id="嵌套数组或表格"><a href="#嵌套数组或表格" class="headerlink" title="嵌套数组或表格#"></a>嵌套数组或表格<a href="https://www.cnblogs.com/1024th/p/11623258.html#435988021" target="_blank" rel="noopener">#</a></h3><p>多个数组/表格可 <strong>互相嵌套</strong> 并组成一组数组/一组表格。<br>使用嵌套前必须声明 <code>$$</code> 符号。</p>
<ul>
<li>例子：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">Copy% outer vertical array of arrays 外层垂直表格</span><br><span class="line">\begin&#123;array&#125;&#123;c&#125;</span><br><span class="line">    % inner horizontal array of arrays 内层水平表格</span><br><span class="line">    \begin&#123;array&#125;&#123;cc&#125;</span><br><span class="line">        % inner array of minimum values 内层&quot;最小值&quot;数组</span><br><span class="line">        \begin&#123;array&#125;&#123;c|cccc&#125;</span><br><span class="line">        \text&#123;min&#125; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\</span><br><span class="line">        \hline</span><br><span class="line">        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\</span><br><span class="line">        1 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\</span><br><span class="line">        2 &amp; 0 &amp; 1 &amp; 2 &amp; 2\\</span><br><span class="line">        3 &amp; 0 &amp; 1 &amp; 2 &amp; 3</span><br><span class="line">        \end&#123;array&#125;</span><br><span class="line">    &amp;</span><br><span class="line">        % inner array of maximum values 内层&quot;最大值&quot;数组</span><br><span class="line">        \begin&#123;array&#125;&#123;c|cccc&#125;</span><br><span class="line">        \text&#123;max&#125;&amp;0&amp;1&amp;2&amp;3\\</span><br><span class="line">        \hline</span><br><span class="line">        0 &amp; 0 &amp; 1 &amp; 2 &amp; 3\\</span><br><span class="line">        1 &amp; 1 &amp; 1 &amp; 2 &amp; 3\\</span><br><span class="line">        2 &amp; 2 &amp; 2 &amp; 2 &amp; 3\\</span><br><span class="line">        3 &amp; 3 &amp; 3 &amp; 3 &amp; 3</span><br><span class="line">        \end&#123;array&#125;</span><br><span class="line">    \end&#123;array&#125;</span><br><span class="line">    % 内层第一行表格组结束</span><br><span class="line">    \\</span><br><span class="line">    % inner array of delta values 内层第二行Delta值数组</span><br><span class="line">        \begin&#123;array&#125;&#123;c|cccc&#125;</span><br><span class="line">        \Delta&amp;0&amp;1&amp;2&amp;3\\</span><br><span class="line">        \hline</span><br><span class="line">        0 &amp; 0 &amp; 1 &amp; 2 &amp; 3\\</span><br><span class="line">        1 &amp; 1 &amp; 0 &amp; 1 &amp; 2\\</span><br><span class="line">        2 &amp; 2 &amp; 1 &amp; 0 &amp; 1\\</span><br><span class="line">        3 &amp; 3 &amp; 2 &amp; 1 &amp; 0</span><br><span class="line">        \end&#123;array&#125;</span><br><span class="line">        % 内层第二行表格组结束</span><br><span class="line">\end&#123;array&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>显示：</li>
</ul>
<p>  min012300000101112012230123max012300123111232222333333Δ012300123110122210133210min012300000101112012230123max012300123111232222333333Δ012300123110122210133210</p>
<h3 id="用数组实现带分割符号的矩阵"><a href="#用数组实现带分割符号的矩阵" class="headerlink" title="用数组实现带分割符号的矩阵#"></a>用数组实现带分割符号的矩阵<a href="https://www.cnblogs.com/1024th/p/11623258.html#1569596663" target="_blank" rel="noopener">#</a></h3><ul>
<li>例子：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Copy$$</span><br><span class="line">\left[</span><br><span class="line">    \begin&#123;array&#125;&#123;cc|c&#125;</span><br><span class="line">      1&amp;2&amp;3\\</span><br><span class="line">      4&amp;5&amp;6</span><br><span class="line">    \end&#123;array&#125;</span><br><span class="line">\right]</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>

<ul>
<li>显示：</li>
</ul>
<p>  [142536][123456]</p>
<p>其中 <code>cc|c</code> 代表在一个三列矩阵中的第二和第三列之间插入分割线。</p>
<h2 id="字体"><a href="#字体" class="headerlink" title="字体#"></a>字体<a href="https://www.cnblogs.com/1024th/p/11623258.html#1310669968" target="_blank" rel="noopener">#</a></h2><h3 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母#"></a>希腊字母<a href="https://www.cnblogs.com/1024th/p/11623258.html#1282365375" target="_blank" rel="noopener">#</a></h3><p>输入 <code>\小写希腊字母英文全称</code> 和 <code>\首字母大写希腊字母英文全称</code> 来分别输入小写和大写希腊字母。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Alpha \Beta \Gamma \Delta \Epsilon \Zeta \Eta \Theta</span><br></pre></td></tr></table></figure>

<p>ABΓΔEZHΘABΓΔEZHΘ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Iota \Kappa \Lambda \Mu \Nu \Xi \Omicron \Pi</span><br></pre></td></tr></table></figure>

<p>IKΛMNOΞΠIKΛMNOΞΠ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\Rho \Sigma \Tau \Upsilon \Phi \Chi \Psi \Omega</span><br></pre></td></tr></table></figure>

<p>PΣTΥΦXΨΩPΣTΥΦXΨΩ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\alpha \beta \gamma \delta \epsilon \zeta \eta \theta</span><br></pre></td></tr></table></figure>

<p>𝛼𝛽𝛾𝛿𝜖𝜁𝜂𝜃αβγδϵζηθ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\iota \kappa \lambda \mu \nu \omicron \xi \pi</span><br></pre></td></tr></table></figure>

<p>𝜄𝜅𝜆𝜇𝜈o𝜉𝜋ικλμνoξπ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\rho \sigma \tau \upsilon \phi \chi \psi \omega</span><br></pre></td></tr></table></figure>

<p>𝜌𝜎𝜏𝜐𝜙𝜒𝜓𝜔ρστυϕχψω</p>
<p><strong>部分字母有变量专用形式，以 <code>\var-</code> 开头。</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\varepsilon \digamma \varkappa \varpi</span><br></pre></td></tr></table></figure>

<p>𝜀ϝ𝜘𝜛εϝϰϖ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\varrho \varsigma \vartheta \varphi</span><br></pre></td></tr></table></figure>

<p>𝜚𝜍𝜗𝜑ϱςϑφ</p>
<h3 id="希伯来符号"><a href="#希伯来符号" class="headerlink" title="希伯来符号#"></a>希伯来符号<a href="https://www.cnblogs.com/1024th/p/11623258.html#3595635914" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\aleph \beth \gimel \daleth</span><br></pre></td></tr></table></figure>

<p>ℵℶℷℸℵℶℷℸ</p>
<h3 id="部分字体的简称"><a href="#部分字体的简称" class="headerlink" title="部分字体的简称#"></a>部分字体的简称<a href="https://www.cnblogs.com/1024th/p/11623258.html#3594360508" target="_blank" rel="noopener">#</a></h3><p>若要对公式的某一部分字符进行字体转换，可以用 <code>{\字体 {需转换的部分字符}}</code> 命令，其中 <code>\字体</code> 部分可以参照下表选择合适的字体。一般情况下，公式默认为意大利体 𝑖𝑡𝑎𝑙𝑖𝑐italic 。</p>
<table>
<thead>
<tr>
<th align="center">输入</th>
<th align="center">说明</th>
<th align="center">显示</th>
<th align="center">输入</th>
<th align="center">说明</th>
<th align="center">显示</th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center">\rm</td>
<td align="center">罗马体</td>
<td align="center">SampleSample</td>
<td align="center">\cal</td>
<td align="center">花体</td>
<td align="center">SAMPLE</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">\it</td>
<td align="center">意大利体</td>
<td align="center">SampleSample</td>
<td align="center">\Bbb</td>
<td align="center">黑板粗体</td>
<td align="center">𝕊𝔸𝕄ℙ𝕃𝔼SAMPLE</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">\bf</td>
<td align="center">粗体</td>
<td align="center"><strong>𝐒**</strong>𝐚<strong><strong>𝐦</strong></strong>𝐩<strong><strong>𝐥</strong></strong>𝐞**Sample</td>
<td align="center">\mit</td>
<td align="center">数学斜体</td>
<td align="center">𝑆𝐴𝑀𝑃𝐿𝐸SAMPLE</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">\sf</td>
<td align="center">等线体</td>
<td align="center">𝖲𝖺𝗆𝗉𝗅𝖾Sample</td>
<td align="center">\scr</td>
<td align="center">手写体</td>
<td align="center">𝒮𝒜ℳ𝒫ℒℰSAMPLE</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">\tt</td>
<td align="center">打字机体</td>
<td align="center">𝚂𝚊𝚖𝚙𝚕𝚎Sample</td>
<td align="center">\frak</td>
<td align="center">旧德式字体</td>
<td align="center">𝔖𝔞𝔪𝔭𝔩𝔢Sample</td>
<td align="center"></td>
</tr>
</tbody></table>
<h3 id="所有字体"><a href="#所有字体" class="headerlink" title="所有字体#"></a>所有字体<a href="https://www.cnblogs.com/1024th/p/11623258.html#3232965613" target="_blank" rel="noopener">#</a></h3><h4 id="黑板报粗体"><a href="#黑板报粗体" class="headerlink" title="黑板报粗体"></a>黑板报粗体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathbb&#123;ABCDEFGHI&#125;</span><br></pre></td></tr></table></figure>

<p>𝔸𝔹ℂ𝔻𝔼𝔽𝔾ℍ𝕀ABCDEFGHI</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathbb&#123;JKLMNOPQR&#125;</span><br></pre></td></tr></table></figure>

<p>𝕁𝕂𝕃𝕄ℕ𝕆ℙℚℝJKLMNOPQR</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathbb&#123;STUVWXYZ&#125;</span><br></pre></td></tr></table></figure>

<p>𝕊𝕋𝕌𝕍𝕎𝕏𝕐ℤSTUVWXYZ</p>
<h4 id="粗体"><a href="#粗体" class="headerlink" title="粗体"></a>粗体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathbf&#123;ABCDEFGHI&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝐀**</strong>𝐁<strong><strong>𝐂</strong></strong>𝐃<strong><strong>𝐄</strong></strong>𝐅<strong><strong>𝐆</strong></strong>𝐇<strong>**𝐈</strong>ABCDEFGHI</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathbf&#123;JKLMNOPQR&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝐉**</strong>𝐊<strong><strong>𝐋</strong></strong>𝐌<strong><strong>𝐍</strong></strong>𝐎<strong><strong>𝐏</strong></strong>𝐐<strong>**𝐑</strong>JKLMNOPQR</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathbf&#123;STUVWXYZ&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝐒**</strong>𝐓<strong><strong>𝐔</strong></strong>𝐕<strong><strong>𝐖</strong></strong>𝐗<strong><strong>𝐘</strong></strong>𝐙**STUVWXYZ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathbf&#123;abcdefghijklm&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝐚**</strong>𝐛<strong><strong>𝐜</strong></strong>𝐝<strong><strong>𝐞</strong></strong>𝐟<strong><strong>𝐠</strong></strong>𝐡<strong><strong>𝐢</strong></strong>𝐣<strong><strong>𝐤</strong></strong>𝐥<strong>**𝐦</strong>abcdefghijklm</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathbf&#123;nopqrstuvwxyz&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝐧**</strong>𝐨<strong><strong>𝐩</strong></strong>𝐪<strong><strong>𝐫</strong></strong>𝐬<strong><strong>𝐭</strong></strong>𝐮<strong><strong>𝐯</strong></strong>𝐰<strong><strong>𝐱</strong></strong>𝐲<strong>**𝐳</strong>nopqrstuvwxyz</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathbf&#123;0123456789&#125;</span><br></pre></td></tr></table></figure>

<p><strong>0123456789</strong>0123456789</p>
<h4 id="粗体希腊字母"><a href="#粗体希腊字母" class="headerlink" title="粗体希腊字母"></a>粗体希腊字母</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\boldsymbol&#123;\Alpha\Beta\Gamma\Delta\Epsilon\Zeta\Eta\Theta&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝐀**</strong>𝐁<strong><strong>𝚪</strong></strong>𝚫<strong><strong>𝐄</strong></strong>𝐙<strong><strong>𝐇</strong></strong>𝚯**ABΓΔEZHΘ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\boldsymbol&#123;\Iota\Kappa\Lambda\Mu\Nu\Xi\Pi\Rho&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝐈**</strong>𝐊<strong><strong>𝚲</strong></strong>𝐌<strong><strong>𝐍</strong></strong>𝚵<strong><strong>𝚷</strong></strong>𝐏**IKΛMNΞΠP</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\boldsymbol&#123;\Sigma\Tau\Upsilon\Phi\Chi\Psi\Omega&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝚺**</strong>𝐓<strong><strong>𝚼</strong></strong>𝚽<strong><strong>𝐗</strong></strong>𝚿<strong>**𝛀</strong>ΣTΥΦXΨΩ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\boldsymbol&#123;\alpha\beta\gamma\delta\epsilon\zeta\eta\theta&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝜶**</strong>𝜷<strong><strong>𝜸</strong></strong>𝜹<strong><strong>𝝐</strong></strong>𝜻<strong><strong>𝜼</strong></strong>𝜽**αβγδϵζηθ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\boldsymbol&#123;\iota\kappa\lambda\mu\nu\xi\pi\rho&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝜾**</strong>𝜿<strong><strong>𝝀</strong></strong>𝝁<strong><strong>𝝂</strong></strong>𝝃<strong><strong>𝝅</strong></strong>𝝆**ικλμνξπρ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\boldsymbol&#123;\sigma\tau\upsilon\phi\chi\psi\omega&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝝈**</strong>𝝉<strong><strong>𝝊</strong></strong>𝝓<strong><strong>𝝌</strong></strong>𝝍<strong>**𝝎</strong>στυϕχψω</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\boldsymbol&#123;\varepsilon\digamma\varkappa\varpi&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝜺**</strong>ϝ<strong><strong>𝝒</strong></strong>𝝕**εϝϰϖ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\boldsymbol&#123;\varrho\varsigma\vartheta\varphi&#125;</span><br></pre></td></tr></table></figure>

<p><strong>𝝔**</strong>𝝇<strong><strong>𝝑</strong></strong>𝝋**ϱςϑφ</p>
<h4 id="斜体（拉丁字母默认）"><a href="#斜体（拉丁字母默认）" class="headerlink" title="斜体（拉丁字母默认）"></a>斜体（拉丁字母默认）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathit&#123;0123456789&#125;</span><br></pre></td></tr></table></figure>

<p>01234567890123456789</p>
<h4 id="斜体希腊字母（小写字母默认）"><a href="#斜体希腊字母（小写字母默认）" class="headerlink" title="斜体希腊字母（小写字母默认）"></a>斜体希腊字母（小写字母默认）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathit&#123;\Alpha\Beta\Gamma\Delta\Epsilon\Zeta\Eta\Theta&#125;</span><br></pre></td></tr></table></figure>

<p>ABΓΔEZHΘABΓΔEZHΘ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathit&#123;\Iota\Kappa\Lambda\Mu\Nu\Xi\Pi\Rho&#125;</span><br></pre></td></tr></table></figure>

<p>IKΛMNΞΠPIKΛMNΞΠP</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathit&#123;\Sigma\Tau\Upsilon\Phi\Chi\Psi\Omega&#125;</span><br></pre></td></tr></table></figure>

<p>ΣTΥΦXΨΩΣTΥΦXΨΩ</p>
<h4 id="罗马体"><a href="#罗马体" class="headerlink" title="罗马体"></a>罗马体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathrm&#123;ABCDEFGHI&#125;</span><br></pre></td></tr></table></figure>

<p>ABCDEFGHIABCDEFGHI</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathrm&#123;JKLMNOPQR&#125;</span><br></pre></td></tr></table></figure>

<p>JKLMNOPQRJKLMNOPQR</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathrm&#123;STUVWXYZ&#125;</span><br></pre></td></tr></table></figure>

<p>STUVWXYZSTUVWXYZ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathrm&#123;abcdefghijklm&#125;</span><br></pre></td></tr></table></figure>

<p>abcdefghijklmabcdefghijklm</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathrm&#123;nopqrstuvwxyz&#125;</span><br></pre></td></tr></table></figure>

<p>nopqrstuvwxyznopqrstuvwxyz</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathrm&#123;0123456789&#125;</span><br></pre></td></tr></table></figure>

<p>01234567890123456789</p>
<h4 id="无衬线体"><a href="#无衬线体" class="headerlink" title="无衬线体"></a>无衬线体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathsf&#123;ABCDEFGHI&#125;</span><br></pre></td></tr></table></figure>

<p>𝖠𝖡𝖢𝖣𝖤𝖥𝖦𝖧𝖨ABCDEFGHI</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathsf&#123;JKLMNOPQR&#125;</span><br></pre></td></tr></table></figure>

<p>𝖩𝖪𝖫𝖬𝖭𝖮𝖯𝖰𝖱JKLMNOPQR</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathsf&#123;STUVWXYZ&#125;</span><br></pre></td></tr></table></figure>

<p>𝖲𝖳𝖴𝖵𝖶𝖷𝖸𝖹STUVWXYZ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathsf&#123;abcdefghijklm&#125;</span><br></pre></td></tr></table></figure>

<p>𝖺𝖻𝖼𝖽𝖾𝖿𝗀𝗁𝗂𝗃𝗄𝗅𝗆abcdefghijklm</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathsf&#123;nopqrstuvwxyz&#125;</span><br></pre></td></tr></table></figure>

<p>𝗇𝗈𝗉𝗊𝗋𝗌𝗍𝗎𝗏𝗐𝗑𝗒𝗓nopqrstuvwxyz</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathsf&#123;0123456789&#125;</span><br></pre></td></tr></table></figure>

<p>𝟢𝟣𝟤𝟥𝟦𝟧𝟨𝟩𝟪𝟫0123456789</p>
<h4 id="无衬线体希腊字母（仅大写）"><a href="#无衬线体希腊字母（仅大写）" class="headerlink" title="无衬线体希腊字母（仅大写）"></a>无衬线体希腊字母（仅大写）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathsf&#123;\Alpha \Beta \Gamma \Delta \Epsilon \Zeta \Eta \Theta&#125;</span><br></pre></td></tr></table></figure>

<p>ABEZHABΓΔEZHΘ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathsf&#123;\Iota \Kappa \Lambda \Mu \Nu \Xi \Pi \Rho&#125;</span><br></pre></td></tr></table></figure>

<p>IKMNPIKΛMNΞΠP</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathsf&#123;\Sigma \Tau \Upsilon \Phi \Chi \Psi \Omega&#125;</span><br></pre></td></tr></table></figure>

<p>TXΣTΥΦXΨΩ</p>
<h4 id="手写体-花体"><a href="#手写体-花体" class="headerlink" title="手写体 / 花体"></a>手写体 / 花体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathcal&#123;ABCDEFGHI&#125;</span><br></pre></td></tr></table></figure>

<p>ABCDEFGHI</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathcal&#123;JKLMNOPQR&#125;</span><br></pre></td></tr></table></figure>

<p>JKLMNOPQR</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathcal&#123;STUVWXYZ&#125;</span><br></pre></td></tr></table></figure>

<p>STUVWXYZ</p>
<h4 id="Fraktur-体"><a href="#Fraktur-体" class="headerlink" title="Fraktur 体"></a>Fraktur 体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathfrak&#123;ABCDEFGHI&#125;</span><br></pre></td></tr></table></figure>

<p>𝔄𝔅ℭ𝔇𝔈𝔉𝔊ℌℑABCDEFGHI</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathfrak&#123;JKLMNOPQR&#125;</span><br></pre></td></tr></table></figure>

<p>𝔍𝔎𝔏𝔐𝔑𝔒𝔓𝔔ℜJKLMNOPQR</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathfrak&#123;STUVWXYZ&#125;</span><br></pre></td></tr></table></figure>

<p>𝔖𝔗𝔘𝔙𝔚𝔛𝔜ℨSTUVWXYZ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathfrak&#123;abcdefghijklm&#125;</span><br></pre></td></tr></table></figure>

<p>𝔞𝔟𝔠𝔡𝔢𝔣𝔤𝔥𝔦𝔧𝔨𝔩𝔪abcdefghijklm</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathfrak&#123;nopqrstuvwxyz&#125;</span><br></pre></td></tr></table></figure>

<p>𝔫𝔬𝔭𝔮𝔯𝔰𝔱𝔲𝔳𝔴𝔵𝔶𝔷nopqrstuvwxyz</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathfrak&#123;0123456789&#125;</span><br></pre></td></tr></table></figure>

<p>01234567890123456789</p>
<h4 id="小型手写体"><a href="#小型手写体" class="headerlink" title="小型手写体"></a>小型手写体</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\scriptstyle\text&#123;abcdefghijklm&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>abcdefghijklmabcdefghijklm</p>
<h3 id="混合字体"><a href="#混合字体" class="headerlink" title="混合字体#"></a>混合字体<a href="https://www.cnblogs.com/1024th/p/11623258.html#283446434" target="_blank" rel="noopener">#</a></h3><p>特征|语法|渲染效果</p>
<p>斜体字符（忽略空格）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x y z</span><br></pre></td></tr></table></figure>

<p>𝑥𝑦𝑧xyz</p>
<p>非斜体字符</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\text&#123;x y z&#125;</span><br></pre></td></tr></table></figure>

<p>x y zx y z</p>
<p>混合斜体（差）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\text&#123;if&#125; n \text&#123;is even&#125;</span><br></pre></td></tr></table></figure>

<p>if𝑛is evenifnis even</p>
<p>混合斜体（好）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\text&#123;if &#125;n\text&#123; is even&#125;</span><br></pre></td></tr></table></figure>

<p>if 𝑛 is evenif n is even</p>
<p>混合斜体（替代品：<code>~</code> 或者 <code>\</code> 强制空格）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\text&#123;if&#125;~n\ \text&#123;is even&#125;</span><br></pre></td></tr></table></figure>

<p>if 𝑛 is evenif n is even</p>
<h3 id="注释文本"><a href="#注释文本" class="headerlink" title="注释文本#"></a>注释文本<a href="https://www.cnblogs.com/1024th/p/11623258.html#3359783170" target="_blank" rel="noopener">#</a></h3><p>使用 <code>\text {文字}</code> 来添加注释文本（注释文本不会被识别为公式，不用斜体显示）。<code>\text {文字}</code>中仍可以使用 <code>$公式$</code> 插入其它公式。</p>
<ul>
<li>例子：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Copyf(n)&#x3D; \begin&#123;cases&#125;</span><br><span class="line">n&#x2F;2, &amp; \text &#123;if $n$ is even&#125; \\</span><br><span class="line">3n+1, &amp;\text&#123;if $n$ is odd&#125;</span><br><span class="line">\end&#123;cases&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>显示：</li>
</ul>
<p>  𝑓(𝑛)={𝑛/2,3𝑛+1,if 𝑛 is evenif 𝑛 is oddf(n)={n/2,if n is even3n+1,if n is odd</p>
<h2 id="括号"><a href="#括号" class="headerlink" title="括号#"></a>括号<a href="https://www.cnblogs.com/1024th/p/11623258.html#870463815" target="_blank" rel="noopener">#</a></h2><p><code>()</code>、<code>[]</code> 和 <code>|</code> 表示符号本身，使用 <code>\{\}</code> 来表示 <code>{}</code> 。</p>
<p>功能|语法|显示</p>
<p>短括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\frac&#123;1&#125;&#123;2&#125;</span><br></pre></td></tr></table></figure>

<p>(12)(12)</p>
<p>长括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left(\frac&#123;1&#125;&#123;2&#125; \right)</span><br></pre></td></tr></table></figure>

<p>(12)(12)</p>
<p>使用 <code>\left</code> 和 <code>\right</code> 来创建自动匹配高度的 (圆括号)，[方括号] 和 {花括号} 。</p>
<p>功能|语法|显示</p>
<p>圆括号，小括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left( \frac&#123;a&#125;&#123;b&#125; \right)</span><br></pre></td></tr></table></figure>

<p>(𝑎𝑏)(ab)</p>
<p>方括号，中括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left[ \frac&#123;a&#125;&#123;b&#125; \right]</span><br></pre></td></tr></table></figure>

<p>[𝑎𝑏][ab]</p>
<p>花括号，大括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left&#123; \frac&#123;a&#125;&#123;b&#125; \right&#125;</span><br></pre></td></tr></table></figure>

<p>{𝑎𝑏}{ab}</p>
<p>角括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left \langle \frac&#123;a&#125;&#123;b&#125; \right \rangle</span><br></pre></td></tr></table></figure>

<p>⟨𝑎𝑏⟩⟨ab⟩</p>
<p>单竖线，绝对值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left| \frac&#123;a&#125;&#123;b&#125; \right|</span><br></pre></td></tr></table></figure>

<p>∣∣∣𝑎𝑏∣∣∣|ab|</p>
<p>双竖线，范</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left \| \frac&#123;a&#125;&#123;b&#125; \right \|</span><br></pre></td></tr></table></figure>

<p>‖‖‖𝑎𝑏‖‖‖‖ab‖</p>
<p>取整函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left \lfloor \frac&#123;a&#125;&#123;b&#125; \right \rfloor</span><br></pre></td></tr></table></figure>

<p>⌊𝑎𝑏⌋⌊ab⌋</p>
<p>取顶函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left \lceil \frac&#123;c&#125;&#123;d&#125; \right \rceil</span><br></pre></td></tr></table></figure>

<p>⌈𝑐𝑑⌉⌈cd⌉</p>
<p>斜线与反斜线</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left &#x2F; \frac&#123;a&#125;&#123;b&#125; \right \backslash</span><br></pre></td></tr></table></figure>

<p>/𝑎𝑏/ab\</p>
<p>上下箭头</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left \uparrow \frac&#123;a&#125;&#123;b&#125; \right \downarrow</span><br></pre></td></tr></table></figure>

<p>↑⏐⏐⏐⏐⏐𝑎𝑏⏐↓⏐⏐⏐⏐↑ab↓</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left \Uparrow \frac&#123;a&#125;&#123;b&#125; \right \Downarrow</span><br></pre></td></tr></table></figure>

<p>⇑∥∥𝑎𝑏∥⇓∥⇑ab⇓</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left \updownarrow \frac&#123;a&#125;&#123;b&#125; \right \Updownarrow</span><br></pre></td></tr></table></figure>

<p>↑↓⏐⏐𝑎𝑏⇑⇓∥↕ab⇕</p>
<p>混合括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left[ 0,1 \right)</span><br></pre></td></tr></table></figure>

<p>[0,1)[0,1)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left \langle \psi \right |</span><br></pre></td></tr></table></figure>

<p>⟨𝜓∣∣⟨ψ|</p>
<p>如果括号只有一边，要用 <code>\left.</code> 或 <code>\right.</code> 匹配另一边。</p>
<p>单左括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left \&#123;\frac&#123;a&#125;&#123;b&#125; \right.</span><br></pre></td></tr></table></figure>

<p>{𝑎𝑏{ab</p>
<p>单右括号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\left. \frac&#123;a&#125;&#123;b&#125; \right \&#125;</span><br></pre></td></tr></table></figure>

<p>𝑎𝑏}ab}</p>
<p>备注：</p>
<ul>
<li><p>可以使用 <code>\big, \Big, \bigg, \Bigg</code> 控制括号的大小，比如代码</p>
<p><code>\Bigg ( \bigg [ \Big \{ \big \langle \left | \| \frac{a}{b} \| \right | \big \rangle \Big \} \bigg ] \Bigg )</code></p>
<p>显示︰</p>
</li>
</ul>
<p>  ([{⟨∣∣∣‖𝑎𝑏‖∣∣∣⟩}])([{⟨|‖ab‖|⟩}])</p>
<h2 id="空格"><a href="#空格" class="headerlink" title="空格#"></a>空格<a href="https://www.cnblogs.com/1024th/p/11623258.html#1541745342" target="_blank" rel="noopener">#</a></h2><p>注意 TeX 能够自动处理大多数的空格，但是您有时候需要自己来控制。</p>
<p>功能|语法|显示|宽度</p>
<h3 id="2-个-quad-空格"><a href="#2-个-quad-空格" class="headerlink" title="2 个 quad 空格#"></a>2 个 quad 空格<a href="https://www.cnblogs.com/1024th/p/11623258.html#4154246342" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\alpha\qquad\beta</span><br></pre></td></tr></table></figure>

<p>𝛼𝛽αβ</p>
<p>𝑚𝑚mm</p>
<h3 id="quad-空格"><a href="#quad-空格" class="headerlink" title="quad 空格#"></a>quad 空格<a href="https://www.cnblogs.com/1024th/p/11623258.html#2117286342" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\alpha\quad\beta</span><br></pre></td></tr></table></figure>

<p>𝛼𝛽αβ</p>
<p>𝑚m</p>
<h3 id="大空格"><a href="#大空格" class="headerlink" title="大空格#"></a>大空格<a href="https://www.cnblogs.com/1024th/p/11623258.html#2769818215" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\alpha\ \beta</span><br></pre></td></tr></table></figure>

<p>𝛼 𝛽α β</p>
<p>𝑚3m3</p>
<h3 id="中等空格"><a href="#中等空格" class="headerlink" title="中等空格#"></a>中等空格<a href="https://www.cnblogs.com/1024th/p/11623258.html#870040048" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\alpha\;\beta</span><br></pre></td></tr></table></figure>

<p>𝛼𝛽αβ</p>
<p>2𝑚72m7</p>
<h3 id="小空格"><a href="#小空格" class="headerlink" title="小空格#"></a>小空格<a href="https://www.cnblogs.com/1024th/p/11623258.html#92225665" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\alpha\,\beta</span><br></pre></td></tr></table></figure>

<p>𝛼𝛽αβ</p>
<p>𝑚6m6</p>
<h3 id="没有空格"><a href="#没有空格" class="headerlink" title="没有空格#"></a>没有空格<a href="https://www.cnblogs.com/1024th/p/11623258.html#595940327" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\alpha\beta</span><br></pre></td></tr></table></figure>

<p>𝛼𝛽αβ</p>
<p>00</p>
<h3 id="紧贴"><a href="#紧贴" class="headerlink" title="紧贴#"></a>紧贴<a href="https://www.cnblogs.com/1024th/p/11623258.html#1847958470" target="_blank" rel="noopener">#</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\alpha\!\beta</span><br></pre></td></tr></table></figure>

<p>𝛼𝛽αβ</p>
<p>−𝑚6−m6</p>
<h2 id="颜色"><a href="#颜色" class="headerlink" title="颜色#"></a>颜色<a href="https://www.cnblogs.com/1024th/p/11623258.html#991581269" target="_blank" rel="noopener">#</a></h2><h3 id="Cmd-Markdown-公式指导手册里是这样写的："><a href="#Cmd-Markdown-公式指导手册里是这样写的：" class="headerlink" title="Cmd Markdown 公式指导手册里是这样写的：#"></a><a href="https://www.zybuluo.com/codeep/note/163962#七交换图表使用参考" target="_blank" rel="noopener">Cmd Markdown 公式指导手册</a>里是这样写的：<a href="https://www.cnblogs.com/1024th/p/11623258.html#2135710648" target="_blank" rel="noopener">#</a></h3><p>使用 <code>\color{颜色}{文字}</code> 来更改特定的文字颜色。<br>更改文字颜色 <strong>需要浏览器支持</strong> ，如果浏览器不知道你所需的颜色，那么文字将被渲染为黑色。</p>
<p>对于较旧的浏览器（HTML4与CSS2），以下颜色是被支持的：</p>
<table>
<thead>
<tr>
<th align="center">输入</th>
<th align="center">显示</th>
<th align="center">输入</th>
<th align="center">显示</th>
</tr>
</thead>
<tbody><tr>
<td align="center">black</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
<td align="center">grey</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
</tr>
<tr>
<td align="center">silver</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
<td align="center">white</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
</tr>
<tr>
<td align="center">maroon</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
<td align="center">red</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
</tr>
<tr>
<td align="center">yellow</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
<td align="center">lime</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
</tr>
<tr>
<td align="center">olive</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
<td align="center">green</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
</tr>
<tr>
<td align="center">teal</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
<td align="center">auqa</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
</tr>
<tr>
<td align="center">blue</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
<td align="center">navy</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
</tr>
<tr>
<td align="center">purple</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
<td align="center">fuchsia</td>
<td align="center">𝑡𝑒𝑥𝑡text</td>
</tr>
</tbody></table>
<p>对于较新的浏览器（HTML5与CSS3），额外的124种颜色将被支持：</p>
<p>输入 <code>\color { #rgb} {text}</code> 来自定义更多的颜色，其中 <code>#rgb</code> 的 <code>r</code> <code>g</code> <code>b</code> 可输入 <code>0-9</code> 和 <code>a-f</code> 来表示红色、绿色和蓝色的纯度（饱和度）。</p>
<ul>
<li>例子：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;array&#125;&#123;|rrrrrrrr|&#125;\hline</span><br><span class="line">\verb+#000+ &amp; \color&#123; #000&#125;&#123;text&#125; &amp; &amp; &amp;</span><br><span class="line">\verb+#00F+ &amp; \color&#123; #00F&#125;&#123;text&#125; &amp; &amp; \\</span><br><span class="line">&amp; &amp; \verb+#0F0+ &amp; \color&#123; #0F0&#125;&#123;text&#125; &amp;</span><br><span class="line">&amp; &amp; \verb+#0FF+ &amp; \color&#123; #0FF&#125;&#123;text&#125;\\</span><br><span class="line">\verb+#F00+ &amp; \color&#123; #F00&#125;&#123;text&#125; &amp; &amp; &amp;</span><br><span class="line">\verb+#F0F+ &amp; \color&#123; #F0F&#125;&#123;text&#125; &amp; &amp; \\</span><br><span class="line">&amp; &amp; \verb+#FF0+ &amp; \color&#123; #FF0&#125;&#123;text&#125; &amp;</span><br><span class="line">&amp; &amp; \verb+#FFF+ &amp; \color&#123; #FFF&#125;&#123;text&#125;\\</span><br><span class="line">\hline</span><br><span class="line">\end&#123;array&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>显示：</p>
<p>#𝟶𝟶𝟶#𝙵𝟶𝟶𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡#𝟶𝙵𝟶#𝙵𝙵𝟶𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡#𝟶𝟶𝙵#𝙵𝟶𝙵𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡#𝟶𝙵𝙵#𝙵𝙵𝙵𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡#000text#00Ftext#0F0text#0FFtext#F00text#F0Ftext#FF0text#FFFtext</p>
</li>
</ul>
<ul>
<li>例子：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Copy\begin&#123;array&#125;&#123;|rrrrrrrr|&#125;</span><br><span class="line">\hline</span><br><span class="line">\verb+#000+ &amp; \color&#123; #000&#125;&#123;text&#125; &amp; \verb+#005+ &amp; \color&#123; #005&#125;&#123;text&#125; &amp; \verb+#00A+ &amp; \color&#123; #00A&#125;&#123;text&#125; &amp; \verb+#00F+ &amp; \color&#123; #00F&#125;&#123;text&#125;  \\</span><br><span class="line">\verb+#500+ &amp; \color&#123; #500&#125;&#123;text&#125; &amp; \verb+#505+ &amp; \color&#123; #505&#125;&#123;text&#125; &amp; \verb+#50A+ &amp; \color&#123; #50A&#125;&#123;text&#125; &amp; \verb+#50F+ &amp; \color&#123; #50F&#125;&#123;text&#125;  \\</span><br><span class="line">\verb+#A00+ &amp; \color&#123; #A00&#125;&#123;text&#125; &amp; \verb+#A05+ &amp; \color&#123; #A05&#125;&#123;text&#125; &amp; \verb+#A0A+ &amp; \color&#123; #A0A&#125;&#123;text&#125; &amp; \verb+#A0F+ &amp; \color&#123; #A0F&#125;&#123;text&#125;  \\</span><br><span class="line">\verb+#F00+ &amp; \color&#123; #F00&#125;&#123;text&#125; &amp; \verb+#F05+ &amp; \color&#123; #F05&#125;&#123;text&#125; &amp; \verb+#F0A+ &amp; \color&#123; #F0A&#125;&#123;text&#125; &amp; \verb+#F0F+ &amp; \color&#123; #F0F&#125;&#123;text&#125;  \\</span><br><span class="line">\hline</span><br><span class="line">\verb+#080+ &amp; \color&#123; #080&#125;&#123;text&#125; &amp; \verb+#085+ &amp; \color&#123; #085&#125;&#123;text&#125; &amp; \verb+#08A+ &amp; \color&#123; #08A&#125;&#123;text&#125; &amp; \verb+#08F+ &amp; \color&#123; #08F&#125;&#123;text&#125;  \\</span><br><span class="line">\verb+#580+ &amp; \color&#123; #580&#125;&#123;text&#125; &amp; \verb+#585+ &amp; \color&#123; #585&#125;&#123;text&#125; &amp; \verb+#58A+ &amp; \color&#123; #58A&#125;&#123;text&#125; &amp; \verb+#58F+ &amp; \color&#123; #58F&#125;&#123;text&#125;  \\</span><br><span class="line">\verb+#A80+ &amp; \color&#123; #A80&#125;&#123;text&#125; &amp; \verb+#A85+ &amp; \color&#123; #A85&#125;&#123;text&#125; &amp; \verb+#A8A+ &amp; \color&#123; #A8A&#125;&#123;text&#125; &amp; \verb+#A8F+ &amp; \color&#123; #A8F&#125;&#123;text&#125;  \\</span><br><span class="line">\verb+#F80+ &amp; \color&#123; #F80&#125;&#123;text&#125; &amp; \verb+#F85+ &amp; \color&#123; #F85&#125;&#123;text&#125; &amp; \verb+#F8A+ &amp; \color&#123; #F8A&#125;&#123;text&#125; &amp; \verb+#F8F+ &amp; \color&#123; #F8F&#125;&#123;text&#125;  \\</span><br><span class="line">\hline</span><br><span class="line">\verb+#0F0+ &amp; \color&#123; #0F0&#125;&#123;text&#125; &amp; \verb+#0F5+ &amp; \color&#123; #0F5&#125;&#123;text&#125; &amp; \verb+#0FA+ &amp; \color&#123; #0FA&#125;&#123;text&#125; &amp; \verb+#0FF+ &amp; \color&#123; #0FF&#125;&#123;text&#125;  \\</span><br><span class="line">\verb+#5F0+ &amp; \color&#123; #5F0&#125;&#123;text&#125; &amp; \verb+#5F5+ &amp; \color&#123; #5F5&#125;&#123;text&#125; &amp; \verb+#5FA+ &amp; \color&#123; #5FA&#125;&#123;text&#125; &amp; \verb+#5FF+ &amp; \color&#123; #5FF&#125;&#123;text&#125;  \\</span><br><span class="line">\verb+#AF0+ &amp; \color&#123; #AF0&#125;&#123;text&#125; &amp; \verb+#AF5+ &amp; \color&#123; #AF5&#125;&#123;text&#125; &amp; \verb+#AFA+ &amp; \color&#123; #AFA&#125;&#123;text&#125; &amp; \verb+#AFF+ &amp; \color&#123; #AFF&#125;&#123;text&#125;  \\</span><br><span class="line">\verb+#FF0+ &amp; \color&#123; #FF0&#125;&#123;text&#125; &amp; \verb+#FF5+ &amp; \color&#123; #FF5&#125;&#123;text&#125; &amp; \verb+#FFA+ &amp; \color&#123; #FFA&#125;&#123;text&#125; &amp; \verb+#FFF+ &amp; \color&#123; #FFF&#125;&#123;text&#125;  \\</span><br><span class="line">\hline</span><br><span class="line">\end&#123;array&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>显示：</li>
</ul>
<p>  #𝟶𝟶𝟶#𝟻𝟶𝟶#𝙰𝟶𝟶#𝙵𝟶𝟶#𝟶𝟾𝟶#𝟻𝟾𝟶#𝙰𝟾𝟶#𝙵𝟾𝟶#𝟶𝙵𝟶#𝟻𝙵𝟶#𝙰𝙵𝟶#𝙵𝙵𝟶𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡#𝟶𝟶𝟻#𝟻𝟶𝟻#𝙰𝟶𝟻#𝙵𝟶𝟻#𝟶𝟾𝟻#𝟻𝟾𝟻#𝙰𝟾𝟻#𝙵𝟾𝟻#𝟶𝙵𝟻#𝟻𝙵𝟻#𝙰𝙵𝟻#𝙵𝙵𝟻𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡#𝟶𝟶𝙰#𝟻𝟶𝙰#𝙰𝟶𝙰#𝙵𝟶𝙰#𝟶𝟾𝙰#𝟻𝟾𝙰#𝙰𝟾𝙰#𝙵𝟾𝙰#𝟶𝙵𝙰#𝟻𝙵𝙰#𝙰𝙵𝙰#𝙵𝙵𝙰𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡#𝟶𝟶𝙵#𝟻𝟶𝙵#𝙰𝟶𝙵#𝙵𝟶𝙵#𝟶𝟾𝙵#𝟻𝟾𝙵#𝙰𝟾𝙵#𝙵𝟾𝙵#𝟶𝙵𝙵#𝟻𝙵𝙵#𝙰𝙵𝙵#𝙵𝙵𝙵𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡𝑡𝑒𝑥𝑡#000text#005text#00Atext#00Ftext#500text#505text#50Atext#50Ftext#A00text#A05text#A0Atext#A0Ftext#F00text#F05text#F0Atext#F0Ftext#080text#085text#08Atext#08Ftext#580text#585text#58Atext#58Ftext#A80text#A85text#A8Atext#A8Ftext#F80text#F85text#F8Atext#F8Ftext#0F0text#0F5text#0FAtext#0FFtext#5F0text#5F5text#5FAtext#5FFtext#AF0text#AF5text#AFAtext#AFFtext#FF0text#FF5text#FFAtext#FFFtext</p>
<h3 id="维基百科的数学公式教程里是这样写的："><a href="#维基百科的数学公式教程里是这样写的：" class="headerlink" title="维基百科的数学公式教程里是这样写的：#"></a>维基百科的<a href="https://zh.wikipedia.org/wiki/Help:数学公式" target="_blank" rel="noopener">数学公式教程</a>里是这样写的：<a href="https://www.cnblogs.com/1024th/p/11623258.html#1559021796" target="_blank" rel="noopener">#</a></h3><p>语法：<code>{\color{颜色}表达式}</code></p>
<p><strong>作者实测：在部分浏览器中，上面的语法可能是错误的</strong>（只将表达式的第一个字符着色），<code>\color{颜色}{文字}</code>的语法才是正确的。例如：</p>
<p><code>{\color{Red}abc}</code>显示𝑎𝑏𝑐abc<br><code>\color{Red}{abc}</code>显示𝑎𝑏𝑐abc</p>
<p><strong>支持色调表：</strong></p>
<p>ApricotApricot</p>
<p>AquamarineAquamarine</p>
<p>BittersweetBittersweet</p>
<p>BlackBlack</p>
<p>BlueBlue</p>
<p>BlueGreenBlueGreen</p>
<p>BlueVioletBlueViolet</p>
<p>BrickRedBrickRed</p>
<p>BrownBrown</p>
<p>BurntOrangeBurntOrange</p>
<p>CadetBlueCadetBlue</p>
<p>CarnationPinkCarnationPink</p>
<p>CeruleanCerulean</p>
<p>CornflowerBlueCornflowerBlue</p>
<p>CyanCyan</p>
<p>DandelionDandelion</p>
<p>DarkOrchidDarkOrchid</p>
<p>EmeraldEmerald</p>
<p>ForestGreenForestGreen</p>
<p>FuchsiaFuchsia</p>
<p>GoldenrodGoldenrod</p>
<p>GrayGray</p>
<p>GreenGreen</p>
<p>GreenYellowGreenYellow</p>
<p>JungleGreenJungleGreen</p>
<p>LavenderLavender</p>
<p>LimeGreenLimeGreen</p>
<p>MagentaMagenta</p>
<p>MahoganyMahogany</p>
<p>MaroonMaroon</p>
<p>MelonMelon</p>
<p>MidnightBlueMidnightBlue</p>
<p>MulberryMulberry</p>
<p>NavyBlueNavyBlue</p>
<p>OliveGreenOliveGreen</p>
<p>OrangeOrange</p>
<p>OrangeRedOrangeRed</p>
<p>OrchidOrchid</p>
<p>PeachPeach</p>
<p>PeriwinklePeriwinkle</p>
<p>PineGreenPineGreen</p>
<p>PlumPlum</p>
<p>ProcessBlueProcessBlue</p>
<p>PurplePurple</p>
<p>RawSiennaRawSienna</p>
<p>RedRed</p>
<p>RedOrangeRedOrange</p>
<p>RedVioletRedViolet</p>
<p>RhodamineRhodamine</p>
<p>RoyalBlueRoyalBlue</p>
<p>RoyalPurpleRoyalPurple</p>
<p>RubineRedRubineRed</p>
<p>SalmonSalmon</p>
<p>SeaGreenSeaGreen</p>
<p>SepiaSepia</p>
<p>SkyBlueSkyBlue</p>
<p>SpringGreenSpringGreen</p>
<p>TanTan</p>
<p>TealBlueTealBlue</p>
<p>ThistleThistle</p>
<p>TurquoiseTurquoise</p>
<p>VioletViolet</p>
<p>VioletRedVioletRed</p>
<p>WhiteWhite</p>
<p>WildStrawberryWildStrawberry</p>
<p>YellowYellow</p>
<p>YellowGreenYellowGreen</p>
<p>YellowOrangeYellowOrange</p>
<p>＊注︰输入时第一个字母必需以大写输入，如<code>\color{OliveGreen}</code>。</p>
<p>例子</p>
<ul>
<li><p><code> {\color{Blue}x^3}+{\color{Brown}2x} - {\color{OliveGreen}1} </code></p>
<p>𝑥2+2𝑥−1x2+2x−1</p>
</li>
<li><p><code> x_{\color{Maroon}1,2}=\frac{-b\pm\sqrt{{\color{Maroon}b^2-4ac}}}{2a} </code></p>
<p>𝑥1,2=−𝑏±𝑏2−4𝑎𝑐‾‾‾‾‾‾‾‾√2𝑎x1,2=−b±b2−4ac2a</p>
</li>
</ul>
<h2 id="外部链接"><a href="#外部链接" class="headerlink" title="外部链接 #"></a>外部链接 <a href="https://www.cnblogs.com/1024th/p/11623258.html#3292575722" target="_blank" rel="noopener">#</a></h2><ul>
<li>一个介绍 𝑇𝐸𝑋TEX 的 PDF 文档（英文）： <a href="http://www.ctan.org/tex-archive/info/gentle/gentle.pdf" target="_blank" rel="noopener">http://www.ctan.org/tex-archive/info/gentle/gentle.pdf</a></li>
<li>手画符号搜索 𝐿𝐴𝑇𝐸𝑋LATEX 代码: <a href="http://detexify.kirelabs.org/classify.html" target="_blank" rel="noopener">http://detexify.kirelabs.org/classify.html</a></li>
<li><a href="http://www.codecogs.com/latex/eqneditor.php" target="_blank" rel="noopener">LaTeX 在线编辑器</a></li>
<li><a href="http://www.ams.org/tex/amslatex.html" target="_blank" rel="noopener">AMS-LaTeX 指南</a></li>
</ul>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/04/08/R%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E7%BB%98%E5%9B%BE/">
                R语言基础绘图
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-04-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <font size=5>
#R语言基础绘图
这是一期不怎么严谨的CSDN搬运专栏,主要介绍如何用R绘制基本统计图形
##创建图形
###图形的核心:plot()函数
plot()函数是R语言创建图形最基本的函数,plot()是一个泛型函数,真正被调用的函数依赖于对象所属的类

<p>plot函数最基本的参数x,y,分别表示横纵坐标的取值向量<br>参数main指定标题,sub指定副标题,xlab和ylab分别指定x轴和y轴标签<br><img src="https://i.imgur.com/XYeryug.png" alt=""><br>###abline()函数和lines()函数<br>abline()函数可以用于向图中添加线条</p>
<p>例如:在当前图形中添加y=2+1*x描述的直线</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">abline(c(2,1))</span><br></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/xVigTxx.png" alt=""></p>
<p>abline()在编写时特意考虑了参数是回归结果的情形,因此如果参数是回归结果的对象,那么这个函数就会从lmout$coefficients中提取斜率和截距,然后画出这条直线</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">library(&quot;wooldridge&quot;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#96;&#96;&#96;</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;library(&quot;lmtest&quot;)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#96;&#96;&#96;</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;lmout&#x3D;lm(wage1$lwage~wage1$educ)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>abline(lmout)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![](https:&#x2F;&#x2F;i.imgur.com&#x2F;RekAKL4.png)</span><br><span class="line"></span><br><span class="line">lines()函数同样用于向图中添加直线,尽管lines()有很多的参数,但是有两个最基本的参数,分别表示x轴的取值向量和y轴的取值向量.两个参数联合起来表示向当前图形添加的点对(x,y),并在之后依次用线条把它们连接起来</span><br><span class="line"></span><br><span class="line">如果你只想画出线条,而不想将其中的连接点绘制出来,可以将参数type&#x3D;&quot;1&quot;添加到lines()或plot()中</span><br><span class="line"></span><br><span class="line">还可以用plot()中的参数lty来指定线条类型,如指定实线还是虚线</span><br><span class="line">###points()函数</span><br><span class="line">points()函数可以向现有的图形中添加一系列的点对(x,y),每个点都用一种图形元素来表现</span><br><span class="line"></span><br><span class="line">例如:向当前图中添加Exam1和Exam2成绩的散点图,其中每一个点都用&quot;+&quot;来标记</span><br></pre></td></tr></table></figure>
<p>points(testscore$Exam1,testscor$Exam3,pch=”+”)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">###legend()函数</span><br><span class="line">legend()函数用于向拥有多条曲线的图中添加图例</span><br><span class="line">###text()函数</span><br><span class="line">利用text()函数可以在图形的任意位置加上一些文字</span><br></pre></td></tr></table></figure>
<p>text(2.5,4,”abc”)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![](https:&#x2F;&#x2F;i.imgur.com&#x2F;MYtGvpt.png)</span><br><span class="line">这将在图形中点(2.5,4)的位置加上文字&quot;abc&quot;,字符串的中心,将正好位于(2.5,4)</span><br><span class="line">###locator()函数</span><br><span class="line">调用locator()函数,然后在图形中需要的位置点击鼠标,这个函数就会返回你点中之处的坐标.利用locator()函数,可以将文字精确放在你想要的位置.</span><br><span class="line">下面这个命令将会告诉R,你会在图中点击二次.</span><br></pre></td></tr></table></figure>
<p>locator(2)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">下面是一个简单的例子:点击之后,函数会返回一个列表,其元素x,y分别表示所点位置的横纵坐标</span><br></pre></td></tr></table></figure>
<p>hist(c(12,5,13,25,16))</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&#96;&#96;&#96; </span><br><span class="line">locator(2)</span><br></pre></td></tr></table></figure>

<p>$x</p>
<p>[1] 12.06204 17.31315</p>
<p>$y</p>
<p>[1] 1.998410 1.032207<br>##改变图形<br>###改变字符大小:cex<br>cex选项用于放大或缩小图形中的字符,在许多绘图函数中,你都可以将它作为一个参数代入其中.<br>例如:输入以下命令可以实现对”abc”字符的放大输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text(2.5,4,&quot;abc&quot;,cex&#x3D;1.5)</span><br></pre></td></tr></table></figure>
<p>###改变坐标轴的范围:xlim和ylim选项<br>你可能希望x轴或y轴的范围比默认情况更大或更小,要做到这一点,你可以在plot()和points()函数中指定xlim和ylim参数来对坐标轴调整.</p>
<p>如果你要绘制多条曲线,又没有指定xlim或ylim,那么就应该首先绘制最高最宽的那条.否则R只会根据第一条曲线绘制图形,然后将最高的那些在顶部截断<br>###平滑散点:lowess()<br>可以用lowess()对散点拟合一条平滑的非参数回归线</p>
<p>例如:可以实现考试成绩之间的平滑</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot(testscores)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lines(lowess(testscores))</span><br></pre></td></tr></table></figure>

<p><img src="https://i.imgur.com/46wY9Gx.png" alt=""><br>###绘制具有显式表达式的函数<br>如果你想绘制函数g(t)=t+1在0到5之间的图像,可以利用curve()函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curve(x+1,0,5)</span><br></pre></td></tr></table></figure>

<p><img src="https://i.imgur.com/ks76kui.png" alt=""></p>
<p>如果想向图中添加这条曲线,则可以使用add参数:add=”T”<br>###function(x)<br>同样,如果想绘制函数在某区间上的图像,也可以用function(x)说明对函数画图<br>例如想画pnorm函数在(-3,3)的图像</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot(function(x) pnorm(x,lower.tail&#x3D;F), -3, 3)</span><br></pre></td></tr></table></figure>

<p><img src="https://i.imgur.com/k6L2cvw.png" alt=""></p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/30/%E8%B4%B9%E9%9B%AA%E4%BF%A1%E6%81%AF%E7%9F%A9%E9%98%B5/">
                费雪信息矩阵
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-30</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>费雪信息矩阵是用来度量随机变量X所含有的关于自身随机分布函数位置参数$\theta$ 的信息量，最大似然估计中有着重要的度量价值</p>
<p>费雪信息矩阵体现了最大似然估计的参数方差，可以体现似然方法的准确程度，在统计学中有重要的地位，并且在经济学、医学等的相关统计领域应用广泛</p>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>对于一个i.i.d.的数据组$X_1,X_2,…,X_n$存在概率密度函数且服从一个概率分布$f(X,\theta)$, $\theta$ 为描述此分布的参数，利用最大似然估计法，当$X_i$已知，但$\theta$未知，得到使得发生所有$X_i$对应的最可能的 $\theta$值<br>$$<br>L(\textbf{X})=\prod_{i=1}^nf(X_i;\theta)\<br>\hat{\theta}=argmax_{\theta}L(\textbf{X})<br>$$<br>此时 $\theta$ 的估计值 $\hat{\theta}$ 就是使得 $L(\textbf{X})$ 取得最大值的值</p>
<p>对 $L(X)$ 先取对数，再求一阶偏导，得到其一阶偏导数的矩阵，记为$S(\textbf{X};\theta)$ 。事实上，使得$S=0$ 的 $\theta$ 的值代表了MLE的估计值<br>$$<br>S(\textbf{X}; \theta)=\sum_{i=1}^n\frac{\part \log f(X_i;\theta)}{\partial \theta}<br>$$<br>$S$ 维度为$n\times 1$, $n$ 为 $\theta$ 的维度 $(S$ 之后会用得到$)$ </p>
<p>那我们定义费雪信息矩阵 $I(\theta)$ 为 $S(I,\theta)$ 的二阶中心矩,同时又等于为$L(\textbf{X};\theta)$二阶偏导的期望矩阵<br>$$<br>I(\theta)=E[S(\textbf{X};\theta)^2|\theta]<br>=E[\frac{\part \log L(\textbf{X};\theta)}{\partial\theta}\frac{\part \log L(\textbf{X};\theta)}{\partial\theta^T}|\theta]<br>=-E[\frac{\part ^2\log L(\textbf{X};\theta)}{\partial\theta\partial\theta^T}|\theta]<br>$$<br>（第二个等号的证明用到第一个性质$E[S(\textbf{X};\theta)]=0,$ 可自行验证）</p>
<h4 id="举例正态分布"><a href="#举例正态分布" class="headerlink" title="举例正态分布"></a>举例正态分布</h4><p>对于满足正态分布的$n$个 i.i.d. 随机变量<br>$$<br>\log L(\mu,\sigma^2)=-\frac{n}{2}\log (\sigma^2)-\frac{n}{2}\log (2\pi)-\frac{1}{2\sigma^2}\sum_{i=1}^n(X_i-\mu)^2<br>$$<br>不论直接计算二阶偏导的期望矩阵还是计算一阶偏导生成矩阵的期望，都可以得到<br>$$<br>I(\mu,\sigma^2)=\left\lbrack \begin{array}{cc}<br>\frac{n}{\sigma^2 } &amp; 0\<br>0 &amp; \frac{n}{2\sigma^4 }<br>\end{array}\right\rbrack<br>$$</p>
<h4 id="性质以及用途"><a href="#性质以及用途" class="headerlink" title="性质以及用途"></a>性质以及用途</h4><p>在一般情形下<br>$$<br>E[S(\textbf{X};\theta)|\theta]=E[\frac{\part }{\part\theta}\log f(\textbf{X};\theta)|\theta]=\int\frac{\frac{\part}{\part\theta } f(x;\theta)}{f(x;\theta)}f(x;\theta)dx=\frac{\part}{\part\theta}\int f(x;\theta)dx=\frac{\part}{\part\theta}1=0<br>$$<br>因此添加上该零项之后：<br>$$<br>I(\theta)=E[S(\textbf{X};\theta)^2|\theta]-E[S(\textbf{X};\theta)|\theta]^2=Var[S(\textbf{X};\theta)|\theta]<br>$$<br>从而费雪信息矩阵在直观上代表了MLE方程的方差，在一定程度上会与解得的$\hat{\theta}$的方差有关。</p>
<p>下面不予以详细说明。代表方差的性质可以用来估计在某一分布下，不同的 $\textbf{X}$  所得到 $\theta$ 的方差。</p>
<p>事实上，所解得到的 $\hat{\theta}$ 满足如下分布：<br>$$<br>\sqrt{nI(\theta_0)}(\hat{\theta}-\theta_0)\overset{D}{\to} N(0,I_p)<br>$$<br>其中 $\theta_0$ 为参数的真实值，$I_p$ 为单位矩阵，$I(\theta_0)$中元素的值的大小与解得的$\hat{\theta}$的方差负相关</p>
<p>例如刚才的正态分布，</p>
 $$
\left\lbrack \begin{array}{cc}
\frac{n}{\sigma } & 0\\
0 & \frac{n}{\sqrt{2}\sigma^2 }
\end{array}\right\rbrack \left(\left\lbrack \begin{array}{c}
\hat{\mu} \\
\hat{\sigma^2 } 
\end{array}\right\rbrack -\left\lbrack \begin{array}{c}
\mu \\
\sigma^2 
\end{array}\right\rbrack \right)\overset{D}{\to} N\left(0,I_p \right)
$$ 
<p>所以</p>
 $$
\left\lbrack \begin{array}{c}
\hat{\mu} \\
\hat{\sigma^2 } 
\end{array}\right\rbrack \overset{D}{\to} N\left(\left\lbrack \begin{array}{c}
\mu \\
\sigma^2 
\end{array}\right\rbrack ,\left\lbrack \begin{array}{cc}
\frac{n^2 }{\sigma^2 } & 0\\
0 & \frac{n^2 }{{2\sigma }^4 }
\end{array}\right\rbrack ^{-1}\right)
$$ 
<p>那这样根据估计值 $[\hat{\mu},\hat{\sigma}^2]^T$ ，并且用该点处的费雪矩阵近似替换掉真实点处的费雪矩阵，得到对应95%的置信区间</p>
 $$
\left(\left\lbrack \begin{array}{c}
\hat{\mu} \\
\hat{\sigma^2 } 
\end{array}\right\rbrack -\left\lbrack \begin{array}{cc}
\frac{n}{\hat{\sigma} } & 0\\
0 & \frac{n}{\sqrt{2}{\hat{\sigma} }^2 }
\end{array}\right\rbrack ^{-1}\left\lbrack \begin{array}{c}
\Phi^{-1} \left(1-0\ldotp 025\right)\\
\Phi^{-1} \left(1-0\ldotp 025\right)
\end{array}\right\rbrack,\left\lbrack \begin{array}{c}
\hat{\mu} \\
\hat{\sigma^2 } 
\end{array}\right\rbrack +\left\lbrack \begin{array}{cc}
\frac{n}{\hat{\sigma} } & 0\\
0 & \frac{n}{\sqrt{2}{\hat{\sigma} }^2 }
\end{array}\right\rbrack ^{-1}\left\lbrack \begin{array}{c}
\Phi^{-1} \left(1-0\ldotp 025\right)\\
\Phi^{-1} \left(1-0\ldotp 025\right)
\end{array}\right\rbrack\right)
$$ 

<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>费雪矩阵总体而言是相当有帮助的，对于确定估计值的准确性意义重大，而更多的有用性质尚未陈列，大家可以自行搜索了解</p>
<p>参考：复旦侯燕曦老师金融计量学课件</p>
<p>​            维基百科</p>
<p>​            CSDN <a href="https://blog.csdn.net/artifact1/article/details/80731417" target="_blank" rel="noopener">https://blog.csdn.net/artifact1/article/details/80731417</a></p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/08/AlexNet%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/">
                AlexNet详细解读
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="AlexNet详细解读"><a href="#AlexNet详细解读" class="headerlink" title="AlexNet详细解读"></a>AlexNet详细解读</h1><p>  之前在自学计算机视觉与深度学习方向的论文，今天给大家带来的是很经典的一篇文章 ：《ImageNet Classification with Deep Convolutional Neural Networks》。纯粹是自学之后，自己的一点知识总结，如果有什么不对的地方欢迎大家指正。AlexNet的篇文章当中，我们可以主要从五个大方面去讲：ReLU，LPN，Overlapping Pooling，总体架构，减少过度拟合。重点介绍总体结构和减少过度拟合。</p>
<h2 id="1-ReLU-Nonlinearity"><a href="#1-ReLU-Nonlinearity" class="headerlink" title="1. ReLU Nonlinearity"></a>1. ReLU Nonlinearity</h2><p>一般神经元的激活函数会选择sigmoid函数或者tanh函数，然而Alex发现在训练时间的梯度衰减方面，这些非线性饱和函数要比非线性非饱和函数慢很多。在AlexNet中用的非线性非饱和函数是f=max(0,x)，即ReLU。实验结果表明，要将深度网络训练至training error rate达到25%的话，ReLU只需5个epochs的迭代，但tanh单元需要35个epochs的迭代，用ReLU比tanh快6倍。</p>
<h2 id="2-双GPU并行运行"><a href="#2-双GPU并行运行" class="headerlink" title="2. 双GPU并行运行"></a>2. 双GPU并行运行</h2><p>为提高运行速度和提高网络运行规模，作者采用双GPU的设计模式。并且规定GPU只能在特定的层进行通信交流。其实就是每一个GPU负责一半的运算处理。作者的实验数据表示，two-GPU方案会比只用one-GPU跑半个上面大小网络的方案，在准确度上提高了1.7%的top-1和1.2%的top-5。值得注意的是，虽然one-GPU网络规模只有two-GPU的一半，但其实这两个网络其实并非等价的。</p>
<h2 id="3-LRN局部响应归一化"><a href="#3-LRN局部响应归一化" class="headerlink" title="3. LRN局部响应归一化"></a>3. LRN局部响应归一化</h2><p><img src="https://img-blog.csdn.net/20180518200153219" alt="img"></p>
<p>ReLU本来是不需要对输入进行标准化，但本文发现进行局部标准化能提高性能。</p>
<p>其中a代表在feature map中第i个卷积核(x,y)坐标经过了ReLU激活函数的输出，n表示相邻的几个卷积核。N表示这一层总的卷积核数量。k, n, α和β是hyper-parameters，他们的值是在验证集上实验得到的，其中k = 2，n = 5，α = 0.0001，β = 0.75。</p>
<p>这种归一化操作实现了某种形式的横向抑制，这也是受真实神经元的某种行为启发。</p>
<p>卷积核矩阵的排序是随机任意，并且在训练之前就已经决定好顺序。这种LPN形成了一种横向抑制机制。</p>
<h2 id="4-Overlapping-Pooling"><a href="#4-Overlapping-Pooling" class="headerlink" title="4. Overlapping Pooling"></a>4. Overlapping Pooling</h2><p>池层是相同卷积核领域周围神经元的输出。池层被认为是由空间距离s个像素的池单元网格的组成。也可以理解成以大小为步长对前面卷积层的结果进行分块，对块大小为的卷积映射结果做总结，这时有。然而，Alex说还有的情况，也就是带交叠的Pooling，顾名思义这指Pooling单元在总结提取特征的时候，其输入会受到相邻pooling单元的输入影响，也就是提取出来的结果可能是有重复的(对max pooling而言)。而且，实验表示使用 带交叠的Pooling的效果比的传统要好，在top-1和top-5上分别提高了0.4%和0.3%，在训练阶段有避免过拟合的作用。</p>
<h2 id="5-总体结构"><a href="#5-总体结构" class="headerlink" title="5. 总体结构"></a>5. 总体结构</h2><p>如果说前面的ReLU、LRN、Overlapping Pooling是铺垫的话，那么它们一定是为这部分服务的。</p>
<p>因为这才是全文的重点！！！理解这里才是把握住这篇的论文的精华！</p>
<p><img src="https://img-blog.csdn.net/20180518202244353" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/20190222100954397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h4Ym95NjE=,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/1689929-063fb60285b6ed42.png?imageMogr2/auto-orient/strip%7CimageView2/2" alt="img"></p>
<p>首先总体概述下：</p>
<p>  AlexNet为8层结构，其中前5层为卷积层，后面3层为全连接层；学习参数有6千万个，神经元有650,000个<br>  AlexNet在两个GPU上运行；<br>  AlexNet在第2,4,5层均是前一层自己GPU内连接，第3层是与前面两层全连接，全连接是2个GPU全连接；<br>  RPN层第1,2个卷积层后；<br>  Max pooling层在RPN层以及第5个卷积层后。<br>  ReLU在每个卷积层以及全连接层后。<br>  卷积核大小数量：</p>
<p>conv1:96 11<em>11</em>3(个数/长/宽/深度)</p>
<p>conv2:256 5<em>5</em>48</p>
<p>conv3:384 3<em>3</em>256</p>
<p>conv4: 384 3<em>3</em>192</p>
<p>conv5: 256 3<em>3</em>192</p>
<p>ReLU、双GPU运算：提高训练速度。（应用于所有卷积层和全连接层）</p>
<p>重叠pool池化层：提高精度，不容易产生过度拟合。（应用在第一层，第二层，第五层后面）</p>
<p>局部响应归一化层(LRN)：提高精度。（应用在第一层和第二层后面）</p>
<p>Dropout：减少过度拟合。（应用在前两个全连接层）<br>第1层分析：</p>
<p><img src="https://img-blog.csdn.net/20180518203413676" alt="img"><br>第一层输入数据为原始图像的227<em>227</em>3的图像（最开始是224<em>224</em>3，为后续处理方便必须进行调整）,这个图像被11<em>11</em>3（3代表深度，例如RGB的3通道）的卷积核进行卷积运算，卷积核对原始图像的每次卷积都会生成一个新的像素。卷积核的步长为4个像素，朝着横向和纵向这两个方向进行卷积。由此，会生成新的像素；（227-11）/4+1=55个像素(227个像素减去11，正好是54，即生成54个像素，再加上被减去的11也对应生成一个像素)，由于第一层有96个卷积核，所以就会形成55<em>55</em>96个像素层，系统是采用双GPU处理，因此分为2组数据：55<em>55</em>48的像素层数据。</p>
<p>重叠pool池化层：这些像素层还需要经过pool运算（池化运算）的处理，池化运算的尺度由预先设定为3<em>3，运算的步长为2，则池化后的图像的尺寸为：（55-3）/2+1=27。即经过池化处理过的规模为27</em>27*96.</p>
<p>局部响应归一化层(LRN)：最后经过局部响应归一化处理，归一化运算的尺度为5<em>5；第一层卷积层结束后形成的图像层的规模为27</em>27*96.分别由96个卷积核对应生成，这96层数据氛围2组，每组48个像素层，每组在独立的GPU下运算。<br>第2层分析：</p>
<p><img src="https://img-blog.csdn.net/20180518221411890" alt="img"><br>第二层输入数据为第一层输出的27<em>27</em>96的像素层（为方便后续处理，这对每幅像素层进行像素填充），分为2组像素数据，两组像素数据分别在两个不同的GPU中进行运算。每组像素数据被5<em>5</em>48的卷积核进行卷积运算，同理按照第一层的方式进行：（27-5+2<em>2）/1+1=27个像素，一共有256个卷积核，这样也就有了27</em>27*128两组像素层。</p>
<p>重叠pool池化层：同样经过池化运算，池化后的图像尺寸为（27-3）/2+1=13，即池化后像素的规模为2组13<em>13</em>128的像素层。</p>
<p>局部响应归一化层(LRN)：最后经过归一化处理，分别对应2组128个卷积核所运算形成。每组在一个GPU上进行运算。即共256个卷积核，共2个GPU进行运算。<br>第3层分析</p>
<p><img src="https://img-blog.csdn.net/20180518223031687" alt="img"><br>第三层输入数据为第二层输出的两组13<em>13</em>128的像素层（为方便后续处理，这对每幅像素层进行像素填充），分为2组像素数据，两组像素数据分别在两个不同的GPU中进行运算。每组像素数据被3<em>3</em>128的卷积核（两组，一共也就有3<em>3</em>256）进行卷积运算，同理按照第一层的方式进行：（13-3+1<em>2）/1+1=13个像素，一共有384个卷积核，这样也就有了13</em>13*192两组像素层。<br>第4层分析:</p>
<p><img src="https://img-blog.csdn.net/20180518223330629" alt="img"></p>
<p>第四层输入数据为第三层输出的两组13<em>13</em>192的像素层（为方便后续处理，这对每幅像素层进行像素填充），分为2组像素数据，两组像素数据分别在两个不同的GPU中进行运算。每组像素数据被3<em>3</em>192的卷积核进行卷积运算，同理按照第一层的方式进行：（13-3+1<em>2）/1+1=13个像素，一共有384个卷积核，这样也就有了13</em>13*192两组像素层。<br>第5层分析：</p>
<p><img src="https://img-blog.csdn.net/20180518223635261" alt="img"></p>
<p>第五层输入数据为第四层输出的两组13<em>13</em>192的像素层（为方便后续处理，这对每幅像素层进行像素填充），分为2组像素数据，两组像素数据分别在两个不同的GPU中进行运算。每组像素数据被3<em>3</em>192的卷积核进行卷积运算，同理按照第一层的方式进行：（13-3+1<em>2）/1+1=13个像素，一共有256个卷积核，这样也就有了13</em>13*128两组像素层。</p>
<p>重叠pool池化层：进过池化运算，池化后像素的尺寸为（13-3）/2+1=6，即池化后像素的规模变成了两组6<em>6</em>128的像素层，共6<em>6</em>256规模的像素层。<br>第6层分析：</p>
<p><img src="https://img-blog.csdn.net/20180518223855977" alt="img"><br>第6层输入数据的尺寸是6<em>6</em>256，采用6<em>6</em>256尺寸的滤波器对第六层的输入数据进行卷积运算；每个6<em>6</em>256尺寸的滤波器对第六层的输入数据进行卷积运算生成一个运算结果，通过一个神经元输出这个运算结果；共有4096个6<em>6</em>256尺寸的滤波器对输入数据进行卷积，通过4096个神经元的输出运算结果；然后通过ReLU激活函数以及dropout运算输出4096个本层的输出结果值。</p>
<p>很明显在第6层中，采用的滤波器的尺寸（6<em>6</em>256）和待处理的feature map的尺寸（6<em>6</em>256）相同，即滤波器中的每个系数只与feature map中的一个像素值相乘；而采用的滤波器的尺寸和待处理的feature map的尺寸不相同，每个滤波器的系数都会与多个feature map中像素相乘。因此第6层被称为全连接层。<br>第7层分析：</p>
<p><img src="https://img-blog.csdn.net/20180519092620718" alt="img"><br>第6层输出的4096个数据与第7层的4096个神经元进行全连接，然后经由ReLU和Dropout进行处理后生成4096个数据。<br>第8层分析：</p>
<p><img src="https://img-blog.csdn.net/20180519092826659" alt="img"></p>
<p>第7层输入的4096个数据与第8层的1000个神经元进行全连接，经过训练后输出被训练的数值。</p>
<h2 id="6-减少过度拟合"><a href="#6-减少过度拟合" class="headerlink" title="6. 减少过度拟合"></a>6. 减少过度拟合</h2><h3 id="6-1-数据增益"><a href="#6-1-数据增益" class="headerlink" title="6.1 数据增益"></a>6.1 数据增益</h3><p>增强图片数据集最简单和最常用的方法是在不改变图片核心元素（即不改变图片的分类）的前提下对图片进行一定的变换，比如在垂直和水平方向进行一定的唯一，翻转等。</p>
<p>AlexNet用到的第一种数据增益的方法：是原图片大小为256<em>256中随机的提取224</em>224的图片，以及他们水平方向的映像。</p>
<p>第二种数据增益的方法就是在图像中每个像素的R、G、B值上分别加上一个数，用到 方法为PCA。对于图像每个像素，增加以下量 ：</p>
<p><img src="https://img-blog.csdn.net/20180519094519363" alt="img"><br>p是主成分，lamda是特征值，alpha是N(0，0.1)高斯分布中采样得到的随机值。此方案名义上得到自然图像的重要特性，也就是说，目标是不随着光照强度和颜色而改变的。此方法降低top-1错误率1%。<br>6.2 Dropout</p>
<p>结合多个模型的预测值是减少错误的有效方法，但是对于训练时间用好几天的大型神经网络太耗费时间。Dropout是有效的模型集成学习方法，具有0.5的概率讲隐藏神经元设置输出为0。运用了这种机制的神经元不会干扰前向传递也不影响后续操作。因此当有输入的时候，神经网络采样不用的结构，但是这些结构都共享一个权重。这就减少了神经元适应的复杂性。测试时，用0.5的概率随机失活神经元。dropout减少了过拟合，也使收敛迭代次数增加一倍。</p>
<h2 id="7-学习细节"><a href="#7-学习细节" class="headerlink" title="7. 学习细节"></a>7. 学习细节</h2><p>AlexNet训练采用的是随机梯度下降 (stochastic gradient descent)，每批图像大小为128，动力为0.9，权重衰减为0.005,（Alexnet认为权重衰减非常重要，但是没有讲为什么）</p>
<p>对于权重值的更新规则如下：</p>
<p><img src="https://img-blog.csdn.net/2018051909591899" alt="img"><br>其中i是迭代指数，v是动力变量，ε是学习率，是目标关于w、对求值的导数在第i批样例上的平均值。我们用一个均值为0、标准差为0.01的高斯分布初始化了每一层的权重。我们用常数1初始化了第二、第四和第五个卷积层以及全连接隐层的神经元偏差。该初始化通过提供带正输入的ReLU来加速学习的初级阶段。我们在其余层用常数0初始化神经元偏差。<br>  对于所有层都使用了相等的学习率，这是在整个训练过程中手动调整的。我们遵循的启发式是，当验证误差率在当前学习率下不再提高时，就将学习率除以10。学习率初始化为0.01，在终止前降低三次。作者训练该网络时大致将这120万张图像的训练集循环了90次，在两个NVIDIA GTX 580 3GB GPU上花了五到六天。</p>
<h2 id="8-实验结果"><a href="#8-实验结果" class="headerlink" title="8. 实验结果"></a>8. 实验结果</h2><p>ILSVRC2010比赛冠军方法是Sparse coding,这之后(AlexNet前)报道最好方法是SIFT+FVs。CNN方法横空出世，远超传统方法。</p>
<p><img src="https://img-blog.csdn.net/20180519100236278" alt="img"></p>
<p>ILSVRC-2012，Alex参加比赛，获得冠军，远超第二名SIFT+FVs。</p>
<p><img src="https://img-blog.csdn.net/20180519100534494" alt="img"><br>定量分析：</p>
<p><img src="https://img-blog.csdn.net/20180519100835132" alt="img"><br>图3显示了卷积层学到的有频率和方向选择性的卷积核，和颜色斑点(color blob)。GPU 1 (color-agnostic)和GPU 2(color-specific)学习到的卷积核并不一样。不一样的原因是3.5中的受限连接(restricted connectivity)。</p>
<p>图4显示，即使目标偏离中心，也可以被识别出来，比如mite。top-5预测结果是reasonable的，比如leopard的预测的可能结果是其他类型的猫科动物。但是也存在对intended focus的模糊问题，就是网络不知道我们到底想识别图片中的什么物体，比如cherry,分类结果是dalmatian,网络显然关注的是dog。</p>
<p>网络最后4096-d隐藏层产生的是feature activations是另一个重要指标。如果两张图像产生欧氏距离相近的feature activation vectors,那么网络的higher levels就认为他们是相似的。使用此度量，可以实现较好的图像检索。<br>通过欧氏距离计算两个4096维度效率太低，可以使用自动编码压缩向量成二进制码。这比直接在原始像素上使用自动编码效果更好。因为在raw pixels上使用quto-encoder，没用到标签数据，只是检索有相似边缘模式(similar patterns of edges)的图像,却不管他们语义(semantically)上是否相似。</p>
<h2 id="9-探讨"><a href="#9-探讨" class="headerlink" title="9.探讨"></a>9.探讨</h2><p>深度很重要，去掉任一层，性能都会降低。</p>
<p>为了简化实验，没有使用非监督预训练。但是当有足够计算能力扩大网络结构，而没增加相应数据时，非监督预训练可能会有所帮助。</p>
<p>虽然通过增大网络结构和增加训练时长可以改善网络，但是我们与达到人类视觉系统的时空推理能力(infero-temporal pathway of the human visual system)还相距甚远。所以，最终希望能将CNN用到视频序列分析中，视频相对静态图像有很多有用的时间结构信息。</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/08/%E5%8D%B7%E7%A9%8D%E4%B8%AD%E7%9A%84stride%E5%92%8Cpadding/">
                卷積中的stride和padding
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="卷積神經網路-Convolutional-neural-network-CNN-卷積計算中的步伐-stride-和填充-padding"><a href="#卷積神經網路-Convolutional-neural-network-CNN-卷積計算中的步伐-stride-和填充-padding" class="headerlink" title="卷積神經網路(Convolutional neural network, CNN):卷積計算中的步伐(stride)和填充(padding)"></a>卷積神經網路(Convolutional neural network, CNN):卷積計算中的步伐(stride)和填充(padding)</h1><hr>
<p><strong>卷積神經網路(Convolutional neural network, CNN)其他相關連結我也一起列上來*<br>*</strong>NN-2–1 <a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-卷積運算-池化運算-856330c2b703" target="_blank" rel="noopener">卷積神經網路(Convolutional neural network, CNN) — 卷積運算、池化運算</a><br>NN-2–2<a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-cnn運算流程-ecaec240a631" target="_blank" rel="noopener"> 卷積神經網路(Convolutional neural network, CNN) — CNN運算流程</a><br>NN-2–3 <a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-卷積計算的倒傳遞推導與稀疏矩陣觀點來看卷積計算-e82ac16e510f" target="_blank" rel="noopener">卷積神經網路(Convolutional neural network, CNN):卷積計算的倒傳遞推導與稀疏矩陣觀點來看卷積計算</a><br>NN-2–4 <a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-卷積計算中的步伐-stride-和填充-padding-94449e638e82" target="_blank" rel="noopener">卷積神經網路(Convolutional neural network, CNN):卷積計算中的步伐(stride)和填充(padding)</a><br>NN-2–5 <a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-1-1卷積計算在做什麼-7d7ebfe34b8" target="_blank" rel="noopener">卷積神經網路(Convolutional neural network, CNN): 1×1卷積計算在做什麼</a></p>
<hr>
<p><img src="https://miro.medium.com/max/60/1*hjn1l4rN8jwS3vD5pTvUwQ.png?q=20" alt="img"></p>
<p><img src="https://miro.medium.com/max/1278/1*hjn1l4rN8jwS3vD5pTvUwQ.png" alt="img"></p>
<p>一般看到的卷積介紹，大概就像上圖，圖會因為你的kernel map大小做完卷積後變的更小，實際上卷積怎麼執行可以參考我之前寫的:<br><a href="https://medium.com/@chih.sheng.huang821/卷積神經網路-convolutional-neural-network-cnn-卷積運算-池化運算-856330c2b703" target="_blank" rel="noopener">卷積神經網路(Convolutional neural network, CNN) — 卷積運算、池化運算</a></p>
<p>Note: <strong>(2019/01/15增加)</strong>一般卷積網路過程中，除了Input image不稱為Feature map外，中間產生的圖我們都稱之為Feature map，原因很簡單就是這些中間產生的圖都是為了「描繪出該任務所應該產生對應的特徵資料」，這也呼應Yann LeCun, Yoshua Bengio &amp; Geoffrey Hinton寫的<a href="https://www.nature.com/articles/nature14539" target="_blank" rel="noopener">Deep Learning</a>第一句話寫的「Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction」，深度學習過程就是在學資料的特性，所以中間出來的結果都是特徵資料，在影像因為是2D，所以用Feature map來稱呼。</p>
<p>所以一個卷積計算基本上有幾個部份:</p>
<p>\1. 輸入的圖: 假設大小是W × W。<br>\2. Filter (kernel map)大小是 ks × ks<br>\3. Stride: kernel map在移動時的步伐長度 S<br>\4. 輸出的圖大小為 new_height × new_width</p>
<p>上圖的例子<br>\1. 輸入的圖: W × W =10 × 10。<br>\2. Filter (kernel map): ks × ks=3 × 3<br>\3. Stride: S=1<br>\4. 輸出的圖大小為 new_height × new_width = 8 × 8</p>
<blockquote>
<p>上圖的範例產生了2個問題<br>\1. 是不是卷積計算後，卷積後的圖是不是就一定只能變小?<br>\2. 卷積計算是不是一次只能移動一格?</p>
</blockquote>
<p>所以如果你有玩過deep learning的API，卷積計算部份除了基本的input和filter (kernel map)通常還有兩個參數可以調(strides, padding)，這邊舉<a href="https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/conv2d" target="_blank" rel="noopener">tensorflow</a>的例子:<br>tf.nn.conv2d(input, filter, <strong><em>strides\</em></strong>, <strong><em>padding\</em></strong>, use_cudnn_on_gpu=None, data_format=None, name=None)</p>
<p><strong><em>strides\</em></strong>和 <strong><em>padding\</em></strong>這兩個參數就是在解決上面說的兩個問題。</p>
<hr>
<h2 id="是不是卷積計算後，卷積後的圖是不是就一定只能變小"><a href="#是不是卷積計算後，卷積後的圖是不是就一定只能變小" class="headerlink" title="是不是卷積計算後，卷積後的圖是不是就一定只能變小?"></a><strong>是不是卷積計算後，卷積後的圖是不是就一定只能變小?</strong></h2><p><strong>ANS: 用zero padding</strong></p>
<p>這個手法就是看你會消失多少的大小，在輸入的圖部份就給你加上0元素進去，這個手法稱為zero padding，實際作法如下圖。</p>
<p><img src="https://miro.medium.com/max/60/1*9kqLUr7bMEYryGNtAHyL8A.png?q=20" alt="img"></p>
<p><img src="https://miro.medium.com/max/2000/1*9kqLUr7bMEYryGNtAHyL8A.png" alt="img"></p>
<p>此刻的卷積計算如下，這樣卷積後的圖就不會變小了。</p>
<p><img src="https://miro.medium.com/max/60/1*GwxhjA7-FLIRrtl__RkRgg.png?q=20" alt="img"></p>
<p><img src="https://miro.medium.com/max/1522/1*GwxhjA7-FLIRrtl__RkRgg.png" alt="img"></p>
<p>上圖舉的例子是kernel map是3x3，假設kernel map為5x5，此刻在輸入的圖上下左右行和列都各加2行和2列的0，讓圖變成14x14，就可以了。</p>
<hr>
<h2 id="卷積計算是不是一次只能移動一格"><a href="#卷積計算是不是一次只能移動一格" class="headerlink" title="卷積計算是不是一次只能移動一格?"></a><strong>卷積計算是不是一次只能移動一格?</strong></h2><p><strong>ANS: 當然不是，也可以2格3格，但此時卷積後的圖就會變的更小。</strong></p>
<p><img src="https://miro.medium.com/max/60/1*Hy3dNn5siu4_q7jE7yO9eA.png?q=20" alt="img"></p>
<p><img src="https://miro.medium.com/max/1638/1*Hy3dNn5siu4_q7jE7yO9eA.png" alt="img"></p>
<p>在tensorflow，padding那邊給了兩個選項「padding = ‘VALID’」和「padding = ‘SAME’」</p>
<p><strong>padding = ‘VALID’ 等於最一開始敘述的卷積計算，圖根據filter大小和stride大小而變小。</strong></p>
<p>公式如下: new_height = new_width = (W — F + 1) / S （结果向上取整數，假設算出來結果是4.5，取5）</p>
<p>剛剛的例子<br>filter 3x3, stride=1, 卷積後的大小: (10–3+1)/1=8<br>filter 3x3, stride=2, 卷積後的大小: (10–3+1)/2=4</p>
<p><strong>padding = ‘SAME’，會用zero-padding的手法，讓輸入的圖不會受到kernel map的大小影響。</strong></p>
<p>new_height = new_width = W / S （结果向上取整數）</p>
<blockquote>
<p>剛剛的例子，filter 3x3, stride=2, 卷積後的大小: 10/2=5 (這邊我沒有做這張圖，可以自己想像一下，做法如下所述)<br>這邊的作法會先補zero-padding的0元素，然後在作stride=2的卷積，所以實際上是最(10+2)*(10+2)的圖做padding = ‘VALID’的事情，(12–3+1)/2=5。</p>
</blockquote>
<hr>
<h2 id="Padding補充說明-2019-01-15增加此內容"><a href="#Padding補充說明-2019-01-15增加此內容" class="headerlink" title="Padding補充說明 (2019/01/15增加此內容)"></a>Padding補充說明 (2019/01/15增加此內容)</h2><p>上面介紹的公式是針對tensorflow內建的function功能(「padding = ‘VALID’」和「padding = ‘SAME’」)，並不是一般算卷積後算新的feature map長寬的公式。</p>
<p>一般卷積後算新的feature map長寬的公式如下:</p>
<p><img src="https://miro.medium.com/max/60/1*NnC2iZDC0f8NlovHr9gwkg.png?q=20" alt="img"></p>
<p><img src="https://miro.medium.com/max/1238/1*NnC2iZDC0f8NlovHr9gwkg.png" alt="img"></p>
<p>floor(1.1)=1, floor(1.6)=1</p>
<p>這邊跟前面差別在這邊多了一個pad參數。</p>
<p>對應到caffe prototxt卷積的參數會這麼寫，如下(其他模組應該是一樣可以設pad參數)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">convolution_param &#123;</span><br><span class="line"> num_output: 32</span><br><span class="line"> pad: 1</span><br><span class="line"> kernel_size: 3</span><br><span class="line"> stride: 2</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>這代表卷積層filter數設定為32，filter的kernel size是3，步伐stride是2，pad是1。pad=1，表示圖外圈額外加1圈0，假設pad=2，圖外圈額外加2圈0，以此類推。<br>所以kernel size是3的時候，你希望卷積後圖的寬高不要變，pad就要設定為1<br>假設kernel size是5的時候，你希望卷積後圖的寬高不要變，pad就要設定為2<br>假設kernel size是7的時候，你希望卷積後圖的寬高不要變，pad就要設定為3</p>
<p>Note: 因為一般大多只會用到卷積後，Feature map寬高會依據kernel size縮小一點(「padding = ‘VALID’」)或Feature map寬高不變(「padding = ‘SAME’」)，鮮少搞一些特殊的功能，比如1×1卷積還要加pad=1，這樣出來的圖會比原本大一圈，而且這一圈還全為0。<br>而且一般卷積網路都是希望卷積後圖越來越小(整體MACC計算量才會小)，除了segmentation和一些multi-scale object detection等才會用到deconv.或是一些upsample的方法把feature map放大。<br>Tensorflow是提供簡單的api，你就不需要自己去算pad要設多少，直接下strin即可(如下說明)，多方便阿。<br><code>**padding**</code>: A <code>string</code> from: <code>&quot;SAME&quot;, &quot;VALID&quot;</code>. The type of padding algorithm to use.</p>
<h4 id="456"><a href="#456" class="headerlink" title="456"></a>456</h4>
        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/08/Why%20does%20overlapped%20pooling%20help%20reduce%20overfitting%20in%20conv%20nets/">
                Why does overlapped pooling help reduce overfitting in conv nets
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h1 id="Why-does-overlapped-pooling-help-reduce-overfitting-in-conv-nets"><a href="#Why-does-overlapped-pooling-help-reduce-overfitting-in-conv-nets" class="headerlink" title="Why does overlapped pooling help reduce overfitting in conv nets?"></a><a href="https://stats.stackexchange.com/questions/283261/why-does-overlapped-pooling-help-reduce-overfitting-in-conv-nets" target="_blank" rel="noopener">Why does overlapped pooling help reduce overfitting in conv nets?</a></h1><p>I am going to answer this with the pooling example given above with some modifications. Let us say we have three <code>1D</code> features as given below.</p>
<p>[0 0 5 0 0 6 0 0 3 0 0 4 0 0]</p>
<p>[0 0 0 5 0 6 0 0 0 3 0 4 0 0]</p>
<p>[0 0 5 0 0 6 0 0 3 0 4 0 0 0]</p>
<p>When pooled using <code>z=2</code> and <code>s=2</code>, all 3 features lead to the same result as obtained above, that is</p>
<p>[0, 5, 6, 0, 3, 4, 0]</p>
<p>However when we use <code>z=3</code> and <code>s=2</code>, we get the following results respectively</p>
<p>[5, 5, 6, 3, 3, 4, 0]</p>
<p>[0, 5, 6, 0, 3, 4, 0]</p>
<p>[5, 5, 6, 3, 4, 4, 0]</p>
<p>Therefore, with overlapping pooling, we get three different results as opposed to one result when do not use overlapping. This is due to information loss when <code>z=s</code> which in this case leads to <strong>reduction</strong> in the amount of data available to train the network, i.e from 3 examples to 1 example. The shrinkage in the data size makes the training model overfit.</p>

        </div>
    

</div>
            
                
<div class="post">

    <div class="post-header index">
        <h1 class="title">
            <a href="/2020/03/08/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5summary/">
                对称矩阵summary
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-03-08</span>
            
            
            
        </div>
    </div>

    
        <div class="content">
            <h2 id="机器学习-线性代数基础-5-1-最重要的矩阵：对称矩阵"><a href="#机器学习-线性代数基础-5-1-最重要的矩阵：对称矩阵" class="headerlink" title="机器学习 线性代数基础 | 5.1 最重要的矩阵：对称矩阵"></a>机器学习 线性代数基础 | 5.1 最重要的矩阵：对称矩阵</h2><h3 id="5-1-最重要的矩阵：对称矩阵"><a href="#5-1-最重要的矩阵：对称矩阵" class="headerlink" title="5.1  最重要的矩阵：对称矩阵"></a><strong>5.1  最重要的矩阵：对称矩阵</strong></h3><p>在对数据进行降维与压缩的运算处理过程中，有一类矩阵扮演了极其重要的角色，那就是对称矩阵。在线性代数的理论与实践中，我们将对称矩阵称之为“最重要的”矩阵丝毫不显夸张。</p>
<p>对称矩阵除了“自身与转置后的结果相等”这个最浅显、基本的性质外，还拥有许多重要的高级特性。在对角化的运算讨论中，我们会发现实数对称矩阵一定能够对角化，并且能够得到一组标准正交的特征向量。同时，任意一个矩阵A同他自身的转置矩阵<img src="./pics/640-20200308114054559.png" alt="img">)相乘都能得到一个对称矩阵，我们在本小节中就将重点关注<img src="./pics/640-20200308114054525.png" alt="img">这类对称矩阵并细致的讨论他的特征值所具有的重要性质，这些基础知识将会为后续的高级主题打下坚实的基础，希望大家不要错过。</p>
<h3 id="5-1-1-对称矩阵基本特性回顾"><a href="#5-1-1-对称矩阵基本特性回顾" class="headerlink" title="5.1.1 对称矩阵基本特性回顾"></a><strong>5.1.1 对称矩阵基本特性回顾</strong></h3><p>首先，我们简要的回顾一下在之前的章节中所介绍过的关于对称矩阵的一些重要基本特性：</p>
<p>如果一个矩阵<strong><em>S\</em></strong>的所有数据项都满足<img src="pics/00831rSTgy1gcmdogc0l1j30290100gb.jpg" alt="img">)的相等关系，那么这个矩阵就被称作是一个对称矩阵。通俗的说，一个对称矩阵通过转置操作得到的结果仍然是他自身，即满足：<img src="./pics/640-20200308114054634.png" alt="img">的运算要求。我们从这里面还可以推断出对阵矩阵<strong><em>S\</em></strong>所蕴含的一个前提条件：他必须是一个方阵。</p>
<p>我们还讲过，有一种获取对称矩阵的简单方法：一个矩阵乘以自己的转置矩阵，即<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">，其所得到的运算结果必然是一个对称矩阵，关于这个结论的证明方法也非常简单，我们简单看一下：</p>
<p><img src="./pics/640-20200308114054518.png" alt="img"></p>
<p>这个等式满足关于矩阵对称的基本定义。</p>
<h3 id="5-1-2-实对称矩阵一定可以对角化"><a href="#5-1-2-实对称矩阵一定可以对角化" class="headerlink" title="5.1.2 实对称矩阵一定可以对角化"></a><strong>5.1.2 实对称矩阵一定可以对角化</strong></h3><p>我们在这里只讨论实数范围内的对称矩阵问题。</p>
<p>在上一章的内容里我们讲过，对于一个任意的方阵，如果他的特征值两两不同，那么特征值所对应的特征向量彼此之间满足线性无关，这个方阵可以被对角化。如果方阵有相同的特征值，他很可能存在线性相关的特征向量，那么如果发生了这种情况，该方阵就不能够被对角化了。</p>
<p>但是，这种情况在对称矩阵身上是不会发生的。请大家牢牢记住：对于任意一个实数对称矩阵而言，他都一定可以被对角化。换句话说，对于一个对称矩阵，无论他的特征值是否重复，他的特征向量都一定满足线性无关。</p>
<p>在这里，具体的证明过程我们不展开，大家有兴趣可以查阅相关的资料。</p>
<h3 id="5-1-3-特征向量标准正交"><a href="#5-1-3-特征向量标准正交" class="headerlink" title="5.1.3 特征向量标准正交"></a><strong>5.1.3 特征向量标准正交</strong></h3><p>任意一个实对称矩阵都可以获得一组标准正交的特征向量。这可以说是对称矩阵里我认为最好的一个性质了，在这里我们用一个简单的方法来描述一下这个性质以及他的推导证明过程。</p>
<p>首先，实对称矩阵<strong><em>S\</em></strong>一定能够被对角化，可以被写成<img src="pics/00831rSTgy1gcmdpfcpkzj303400r0k4.jpg" alt="img">)的形式，其中对角矩阵<img src="./pics/640-20200308114054570.png" alt="img">的各元素一定均由实数构成，并且最为关键的一点是任何一个对称矩阵分解得到的特征向量矩阵都可以是标准正交矩阵。</p>
<p>为什么这么说呢，我们可以简单的看一个等式推导过程：</p>
<p>首先对矩阵<strong><em>S\</em></strong>进行矩阵分解，得到：<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcgVflSTtES2ykOQlJrnVrBlC1wicJwJvtL2icFw9wTqATkeOiaqp6VO9TQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)。由于矩阵<strong><em>S\</em></strong>是一个对称矩阵，满足<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcku45axLrw3RqbBGj7p4Sklv5zVdpUZducSF1clbQWjV6vM5kibMHwng/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的关系，于是有：</p>
<p><img src="./pics/640-20200308114054580.png" alt="img">。</p>
<p>那么，想要使得上面的等式相等，我们就需要满足对应位置上的元素相等，即：<img src="./pics/640-20200308114054619.png" alt="img">)，对此我们再进一步，就可以将其整理成<img src="./pics/640-20200308114054594.png" alt="img">)的漂亮形式。这恰恰说明了，我们此时获取的特征向量之间是满足标准正交关系的，我们可以将<strong><em>X\</em></strong>换记作正交矩阵的符号<strong><em>Q\</em></strong>，同时结合<img src="./pics/640-20200308114054611.png" alt="img">)这个基本特性，我们就可以把实对称矩阵的对角化过程变换成更好的形式，写作：<img src="./pics/640-20200308114054622.png" alt="img">。</p>
<h3 id="5-1-4-对称矩阵的分解形式"><a href="#5-1-4-对称矩阵的分解形式" class="headerlink" title="5.1.4 对称矩阵的分解形式"></a><strong>5.1.4 对称矩阵的分解形式</strong></h3><p>将对称矩阵<strong><em>S\</em></strong>分解成标准正交的特征向量只是其中的一种形式而已，由定义式<img src="./pics/640-20200308114054647.png" alt="img">我们可以得知，显然，特征向量是一个方向上的向量集合，不一定非得满足长度为1的要求，但是我们仍然可以通过直觉感受到一个事实，那就是一旦把特征向量都设置为单位向量，那么会在实践的过程中收获很多简化和美好。这个在后面的几节内容里，我们会不断的感受到由此带来的巨大好处。</p>
<p>此时，我们知道了对称矩阵<strong><em>S\</em></strong>一定可以得到由一组标准正交特征向量所构成的特征矩阵<strong><em>Q\</em></strong>。即，矩阵<strong><em>Q\</em></strong>可以表示成：<img src="./pics/640-20200308114054672.png" alt="img">的形式， 我们进一步将等式<img src="./pics/640-20200308114054717.png" alt="img">)进行展开，可以得到<img src="./pics/640-20200308114054672-3638854.png" alt="img">的完整相乘形式。</p>
<p>这个式子是非常重要的，接下来我们进一步将其做展开运算，将矩阵<strong><em>S\</em></strong>写成一组矩阵相加的形式，你就会发现他的精彩之处：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcIicn5aDl8aIcicXx3GmjsUdVsMU17nuy7VibWQwMRChia7T5icG5s428ywA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">。</p>
<p>在这一组标准正交向量当中，每一个<img src="./pics/640-20200308114054679.png" alt="img">相乘所得到的结果项都是一个秩为1并且与矩阵<strong><em>S\</em></strong>维数相等的方阵。同时他还满足方阵与方阵之间相乘的结果为0这个性质，也可以广义的理解为方阵之间满足“正交”。</p>
<p>最终，任意一个n阶对称矩阵<strong><em>S\</em></strong>都可以分解成n个秩1方阵乘以各自权重系数<img src="./pics/640-20200308114054752.png" alt="img">然后相加的结果。</p>
<h3 id="5-1-5-与的秩"><a href="#5-1-5-与的秩" class="headerlink" title="5.1.5 )与的秩"></a><strong>5.1.5 <img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)与<img src="./pics/640-20200308114054807.png" alt="img">的秩</strong></h3><p>在本书前面的章节中，我们介绍过这样一个结论，对于任意一个m×n形状的矩阵<strong><em>A\</em></strong>，他的列向量中线性无关向量的个数等于其行向量中线性无关向量的个数。</p>
<p>换句话说，也就是任意矩阵的行秩等于列秩，即满足：<img src="./pics/640-20200308114054733.png" alt="img">。这个结论可以从线性方程组消元化简的角度去思考，这样大家就会很容易明白了。</p>
<p>我们再看看矩阵<strong><em>A\</em></strong>和<img src="./pics/640-20200308114054749.png" alt="img">的秩之间的关系：</p>
<p>我们从零空间的角度入手去理解这个问题。即，如果方程<strong><em>Ax=0\</em></strong>和方程<img src="./pics/640-20200308114054804.png" alt="img">)是同解方程，那么他们就拥有相同的零空间，由于<strong><em>A\</em></strong>和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">这两个矩阵的列的个数相等，都为 n，因此，就可以推断出他们的列空间的维数相同，均为：<strong><em>n***</em></strong>−N(A)***，换句话说，也就能够推出二者的秩相等。</p>
<p>好的，那就让我们按照这个思路来推进：</p>
<p>首先，如果满足方程<strong><em>Ax=0\</em></strong>成立，方程两边同时乘以转置矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJclDFCYpPPQ3aOcCwEUarLP1zr9gDw0AmJCx8DnMDmPhrnjakbRjZmew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)，很明显，等式<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJce8ZA2jrNnvjXVwL1jIZEmZuicG8bFA3lDFcn6fWPZ3HtMj8thic78yfg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)同样能够成立。因此，我们可以说如果<strong><em>x\</em></strong>是方程<strong><em>Ax=0\</em></strong>的解，则能够推得出<strong><em>x\</em></strong>也一定是方程<img src="./pics/640-20200308114054765.png" alt="img">的解。</p>
<p>那么反过来呢，如果方程<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcY6ujibyA4J1pRMTkZ3G5iboRe1F2sDOpjgOY62eaZricJPHgWdu8K84xg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)成立，我们将方程两边同时乘以向量<img src="./pics/640-20200308114054775.png" alt="img">)，即方程<img src="./pics/640-20200308114054790.png" alt="img">)当然也一定能够成立，我们对这个等式稍微整理一下，就可以得到<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcM8OiaD6C5ESaG3OMR4jHUTWLGdkibkn38R7sY2wQFyQVgDd85vcZvT2A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)这个更加简洁的形式，从中可以看出一定能够满足<strong><em>Ax=0\</em></strong>成立。此时，我们可以说如果<strong><em>x\</em></strong>是方程<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcY6ujibyA4J1pRMTkZ3G5iboRe1F2sDOpjgOY62eaZricJPHgWdu8K84xg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的解，那么他一定也是方程<strong><em>Ax=0\</em></strong>的解。</p>
<p>于是，这个问题我们就说清楚了：方程<strong><img src="./pics/640-20200308114054817.png" alt="img"></strong>和方程<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJce8ZA2jrNnvjXVwL1jIZEmZuicG8bFA3lDFcn6fWPZ3HtMj8thic78yfg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)是一对同解的方程，矩阵<strong><em>A\</em></strong>和矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)这两个矩阵拥有相同的零空间，因此我们就解释清楚了矩阵<strong><em>A\</em></strong>和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">秩相等的问题。</p>
<p>那么同样的，我们由此不难发现也一定有矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJclDFCYpPPQ3aOcCwEUarLP1zr9gDw0AmJCx8DnMDmPhrnjakbRjZmew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的秩相等。那么这下好了，在<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcp02jRb44qpVmWLe2xdmcsHpSnMASoB0OcwibSF07f1pYSuBGOicCNXWQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">这个相等关系的纽带连接下，我们就有了以下这个结论：</p>
<p><img src="./pics/640-20200308114054843.png" alt="img"></p>
<p>从等式中可以看出，他们的秩都是相等的。</p>
<h3 id="5-1-6-对称矩阵的正定性描述"><a href="#5-1-6-对称矩阵的正定性描述" class="headerlink" title="5.1.6 对称矩阵的正定性描述"></a><strong>5.1.6</strong> <strong><img src="./pics/640-20200308114054862.png" alt="img">对称矩阵的正定性描述</strong></h3><p>最后，我们来聚焦一下对称矩阵特征值的问题，我们先介绍一组概念：如果一个矩阵的所有特征值都为正，我们称他是“正定的”矩阵，如果均为非负（即，最小的特征值为0），相当于结论上稍稍弱了一些，我们称之为“半正定的”矩阵，如果他含有负的特征值，那么显然，他是非正定的。</p>
<p>那么换句话说，对于一个对称矩阵而言，从特征值的正负性角度来看的话，他一定是正定、半正定或非正定的其中一种。</p>
<p>就正定性而言，一般的对称矩阵其实没有太多的特殊性，但是由任意矩阵<strong><em>A\</em></strong>乘以他的转置矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJclDFCYpPPQ3aOcCwEUarLP1zr9gDw0AmJCx8DnMDmPhrnjakbRjZmew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)得到的对称矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">，则具备非常好的特殊性质。即，他的特征值一定是非负的，换句话说，他至少是半正定的。</p>
<p>我们简单的说明一下为什么。</p>
<p>我们还是从特征向量的定义式子<img src="./pics/640-20200308114054884.png" alt="img">)入手进行分析，我们将等式两边同时乘以向量<img src="./pics/640-20200308114054964.png" alt="img">)，得到<img src="./pics/640-20200308114054893.png" alt="img">)这个新等式，由于特征向量必须非零，所以必然存在有<img src="./pics/640-20200308114054982.png" alt="img">)的不等关系。换句话说，此时等式<img src="./pics/640-20200308114054906.png" alt="img">)左侧的正负性就决定了右侧<img src="./pics/640-20200308114054922.png" alt="img">的正负性。</p>
<p>那么问题就来了，如果要满足正定性（或半正定性）的要求，那么就一定要满足所有的<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)都为正（或非负）的要求，等价于<img src="./pics/640-20200308114054981.png" alt="img">)的计算结果恒为正（或非负），这在<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcjhCQv699nEYqG44B4VdoAU7TLed5GMALZrPDoCJvbjWbvltKykicl7A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的条件下能够保证成立么？我们将其代入到等式中发现，这个是可以保证成立的：</p>
<p><img src="./pics/640-20200308114054933.png" alt="img">，</p>
<p>此时，如果矩阵<strong><em>A\</em></strong>的各列满足线性无关，由于向量<strong><em>x\</em></strong>是非零的，因此就能够保证所有的<strong><em>Ax***</em></strong>≠0***都成立，那么就有<img src="./pics/640-20200308114054948.png" alt="img">)恒成立。此时，对称矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)所有的特征值都满足<img src="./pics/640-20200308114055045.png" alt="img">，因此矩阵是正定的。</p>
<p>如果矩阵<strong><em>A\</em></strong>的各列线性相关，那么也就是说有x≠0而<strong><em>Ax=0\</em></strong>的情况存在，此时就只能保证<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcibgic2DWqRPVbR5Za6Eb2PBND3LENoDoiauoARYMicJ3aZmhH4M1dgxGBg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)（存在等于零的可能性），对称矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)就存在值为0的特征值<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">。因此，此时的矩阵是半正定的。</p>
<p>那么此时就可以继续挖掘出结论：实对称矩阵中非零特征值的个数等于该矩阵的秩。这个结论非常明显：因为矩阵<strong><em>A\</em></strong>与相似对角化后的矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcFPgH3uA0h6V41ujDm4EJjXUcCXicneKCwqOwDEvicIxxlxQIqzQ0ODJA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)拥有相同的特征值，同时由于相似性可知：这两个矩阵的秩相等。而<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcFPgH3uA0h6V41ujDm4EJjXUcCXicneKCwqOwDEvicIxxlxQIqzQ0ODJA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">最容易看出非零特征值的个数和秩的相等关系，从而结论得证。</p>
<p>我们总结一下，对称矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的所有特征值都满足非负性，特别的，如果矩阵<strong><em>A\</em></strong>的列向量满足线性无关，则该矩阵是一个正定矩阵，其特征值均为正。</p>
<h3 id="5-1-7-与的特征值"><a href="#5-1-7-与的特征值" class="headerlink" title="5.1.7 )与的特征值"></a><strong>5.1.7 <img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJchJt4fLISBkOfHRgMia7okcSjkrvXME32jxXkwUm5nHkZPmQWbSEHfibg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)与<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的特征值</strong></h3><p>最后，我们来看看<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)这两个对称矩阵的特征值满足什么样的关系。我告诉大家，这个问题的结论非常完美：<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">拥有完全一样的非零特征值。</p>
<p>我们从两个方向入手进行证明：说明如果<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)是矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值，那么他也是矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJchJt4fLISBkOfHRgMia7okcSjkrvXME32jxXkwUm5nHkZPmQWbSEHfibg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值；反过来，如果<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)是矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值，那么他同样也是矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的特征值。</p>
<p>我们假设矩阵<strong><em>A\</em></strong>的维度是m×n，矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的一个非零特征值是<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)，对应的特征向量是<strong><em>x\</em></strong>，那么依据定义有：<img src="./pics/640-20200308114055217.png" alt="img">)，我们将等式两边同时乘以矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJclDFCYpPPQ3aOcCwEUarLP1zr9gDw0AmJCx8DnMDmPhrnjakbRjZmew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)，即满足：<img src="./pics/640-20200308114055172.png" alt="img">)的相等关系，我们稍作整理就可以得到一个漂亮的等式：<img src="./pics/640-20200308114055198.png" alt="img">)，于是我们看出，矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值仍然是<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)，对应的特征向量为<img src="./pics/640-20200308114055256.png" alt="img">。</p>
<p>那么反过来呢，证明过程也是非常简单的，已知矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcn8SKOn31jOL8QZQC9ib1QKSM8lah9JuQA3hDwmfKZWgiageLlL5W4kdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和对应的特征向量<strong><em>y\</em></strong>，依据定义有：<img src="./pics/640-20200308114055221.png" alt="img">)满足等式成立，两边同时乘以矩阵<strong><em>A\</em></strong>，可以得到：<img src="./pics/640-20200308114055261.png" alt="img">)的相等关系，也是对其稍作整理，就有：<img src="./pics/640-20200308114055304.png" alt="img">)，这个过程同样说明了，如果<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJc6vwIsmHUPDLckTd4K3mJeHBv30YkCnUSofkhibVFnT7J5bPMmEZwWUQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)是<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)的特征值，那么他也一定是<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的特征值。</p>
<p>这里，我们就给大家解释清了：<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">这两个对称矩阵拥有完全相同的非负特征值。</p>
<h3 id="5-1-8-对称矩阵的性质总结"><a href="#5-1-8-对称矩阵的性质总结" class="headerlink" title="5.1.8 对称矩阵的性质总结"></a><strong>5.1.8 对称矩阵的性质总结</strong></h3><p>在这一节里，我们讲解了对称矩阵的诸多重要性质和漂亮结论。他们不是零散的概念，而是可以构成一个知识网络。我在本节的最后给大家串联一下这些知识点，大家共同思考一下里面的内在关联：</p>
<p>对于任意的一个m×n形状的矩阵A，有如下性质：</p>
<p>● 矩阵A和转置矩阵<img src="./pics/640-20200308114055284.jpeg" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJclDFCYpPPQ3aOcCwEUarLP1zr9gDw0AmJCx8DnMDmPhrnjakbRjZmew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)相乘的结果<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">都是对称矩阵；</p>
<p>● 矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">都能够被对角化，且都可以通过矩阵分解，获得一组标准正交的特征向量；</p>
<p>● 矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJchJt4fLISBkOfHRgMia7okcSjkrvXME32jxXkwUm5nHkZPmQWbSEHfibg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)分别是n阶和m阶的方阵，一般情况下他们的维度都是不等的，但是他们的秩却一定满足相等关系，即满足：<img src="./pics/640-20200308114055425.png" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">的相等关系；</p>
<p>● 对于矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">而言，他的特征值一定都是非负的，特别的，如果矩阵A的列向量满足线性无关，那么他的特征值全部为正，即为正定矩阵；</p>
<p>● 矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcdOXGiaU6cAWlGoRia6HEt1zGhY4zXh8wEHxzhWwEaEZ8Ajic8ibSUaWqBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)和矩阵<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcaXiaA0icTnQt8pEDnRfwwTY261gwL1x9HvgFUJWHiaZpdp9sWZIsPBQLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">)<img src="https://mmbiz.qpic.cn/mmbiz_png/1y1ObuUF34yTW25WCkMeqfiaC2KmfQgJcr8DULn2icdRficEXf8vGINhNQLgDzOEXhmBuGKq36xCDCvePbibEEF0Ww/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1" alt="img">拥有完全相同的非零特征值，非零特征值的个数与矩阵A的秩相等。</p>
<p>熟悉、掌握这五个重要结论，将会为本章后面几节的内容扫清最大的数学障碍，帮助大家更好的掌握相关的高级内容。</p>

        </div>
    

</div>
            
        </section>
    </div>
</div>



    <div class="row">
        <div class="col-sm-12">
            <div class="wrap-pagination">
                <a class="disabled" href="/">
                    <i class="fa fa-chevron-left" aria-hidden="true"></i>
                </a>
                <a class="" href="/page/2/">
                    <i class="fa fa-chevron-right" aria-hidden="true"></i>
                </a>
            </div>
        </div>
    </div>




</div>

<!-- Footer -->
<div class="push"></div>

<footer class="footer-content">
    <div class="container">
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 footer-about">
                <h2>About</h2>
                <p>
                    This theme was developed by <a href="https://github.com/klugjo" target="_blank" rel="noopener">Jonathan Klughertz</a>. The source code is available on Github. Create Websites. Make Magic.
                </p>
            </div>
            
    <div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 recent-posts">
        <h2>Recent Posts</h2>
        <ul>
            
            <li>
                <a class="footer-post" href="/2020/04/17/2DPE_pics/clip/">2DPE_pics/clip</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2020/04/17/#%20%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1(Human%20Pose%20Estimation)%E7%BB%8F%E5%85%B8%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/"># 人体姿态估计(Human Pose Estim</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2020/04/17/%E9%9B%B6%E6%AC%A1%E5%AD%A6%E4%B9%A0%EF%BC%88Zero-Shot%20Learning%EF%BC%89%E5%85%A5%E9%97%A8/">零次学习（Zero-Shot Learning）入</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2020/04/13/LaTeX%E5%85%AC%E5%BC%8F%E6%89%8B%E5%86%8C(%E5%85%A8%E7%BD%91%E6%9C%80%E5%85%A8)/">LaTeX公式手册(全网最全)</a>
            </li>
            
        </ul>
    </div>



            
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <ul class="list-inline footer-social-icons">
                    
                    <li class="list-inline-item">
                        <a href="https://github.com/klugjo/hexo-theme-alpha-dust" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-github"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://twitter.com/?lang=en" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-twitter"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://www.facebook.com/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-facebook"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://www.instagram.com/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-instagram"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://dribbble.com/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-dribbble"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://plus.google.com/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-google-plus"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://www.behance.net/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-behance"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://500px.com/" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-500px"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="mailto:test@example.com">
                            <span class="footer-icon-container">
                                <i class="fa fa-envelope-o"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="\#">
                            <span class="footer-icon-container">
                                <i class="fa fa-rss"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <div class="footer-copyright">
                    @Untitled. All right reserved | Design & Hexo <a href="http://www.codeblocq.com/" target="_blank" rel="noopener">Jonathan Klughertz</a>
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- After footer scripts -->

<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Tween Max -->
<script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.5/TweenMax.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Custom JavaScript -->

<script src="/js/main.js"></script>


<!-- Disqus Comments -->



</body>

</html>